%
% PROJECT: <ETD> Electronic Thesis and Dissertation Initiative
%   TITLE: LaTeX report template for ETDs in LaTeX
% 

% Instructions: Remove the data from this document and replace it with your own,
% keeping the style and formatting information intact.  More instructions
% appear on the Web site listed above.

\documentclass[12pt,dvips]{report}

\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.5in}
\setlength{\evensidemargin}{0in}
\setlength{\oddsidemargin}{0in}
\setlength{\topmargin}{0in}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0.1in}

% PG
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

% Uncomment for double-spaced document.
\renewcommand{\baselinestretch}{1}

% \usepackage{epsf}

\usepackage[noend]{algorithmic}        % for algorithm descriptions
\usepackage[section]{algorithm}        % number algorithms within each section
\usepackage [inoutnumbered,vlined,algo2e]{algorithm2e}

\usepackage {paralist}
%\usepackage {subfigure}
\usepackage {multicol}
\usepackage {amsfonts}
\usepackage {amsmath}
\usepackage {amsthm}
\usepackage {multirow}
\usepackage {paralist}
%\usepackage{mathptm}
\usepackage{url}
\usepackage{amssymb}
\usepackage{subfigure}
\usepackage{comment}
\usepackage{tabularx}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{appendix}
\usepackage{float}
\usepackage{makeidx}
\usepackage[refpage]{nomencl}
\makenomenclature

\floatstyle{boxed}
\newfloat{program}{htb}{prg}
\floatname{program}{Code listing}

\usepackage{listings}

\lstset{
language=C,                		% choose the language of the code
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
numbers=left,                   % where to put the line-numbers
numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
stepnumber=1,                   % the step between two line-numbers. If it's 1 each line will be numbered
numbersep=5pt,                  % how far the line-numbers are from the code
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
frame=single,	                % adds a frame around the code
tabsize=4,		                % sets default tabsize to 2 spaces
captionpos=b,                   % sets the caption-position to bottom
breaklines=true,                % sets automatic line breaking
breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
}

\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{defn}{Definition}
\newtheorem{clm}{Claim}
\newtheorem{prop}{Property}
\newtheorem{cond}{Condition}
\newtheorem{assum}{Assumption}

\begin{document}

\thispagestyle{empty}
\pagenumbering{roman}
\begin{center}

% TITLE
{\Large 
HyflowCPP : Distributed Transaction Memory framework for C++
}

\vfill

Sudhanshu Mishra

\vfill

Thesis submitted to the Faculty of the \\
Virginia Polytechnic Institute and State University \\
in partial fulfillment of the requirements for the degree of

\vfill

Master of Science \\
in \\
Computer Engineering

\vfill

Binoy Ravindran, Chair \\
Robert P. Broadwater \\
Mark Jones

\vfill

Nov 30, 2010 \\
Blacksburg, Virginia

\vfill

Keywords: Distributed Transaction Memory, Transactional Framework, C++
\\
Copyright 2012, Sudhanshu Mishra

\end{center}

\pagebreak

\thispagestyle{empty}
\begin{center}

{\large
HyflowCPP : Distributed Transaction Memory framework for C++
}

\vfill

Sudhanshu Mishra

\vfill

(ABSTRACT)

\vfill

\end{center}

We consider the problem of scheduling real-time tasks on a multiprocessor system. Our primary focus is scheduling on multiprocessor systems where the total task utilization demand, $U$, is greater than 
$m$, the number of processors on a multiprocessor system---i.e., the total available processing capacity of the system. When $U > m$, the system is said to be overloaded; otherwise, the system is said to be underloaded.

While significant literature exists on multiprocessor real-time scheduling during underloads, little is known about scheduling during overloads, in particular, in the presence of task dependencies---e.g., due to synchronization constraints. We consider real-time tasks that are subject to time/utility function (or TUF) time constraints, which allow task urgency to be expressed independently of task importance---e.g., the most urgent task being the least important. The urgency/importance decoupling allowed by TUFs is especially important during overloads, when not all tasks can be optimally completed. We consider the timeliness optimization objective of maximizing the total accrued utility and the number of deadlines satisfied during overloads, while ensuring task mutual exclusion constraints and freedom from deadlocks. This problem is NP-hard. We develop a class of polynomial-time heuristic algorithms, called the \textit{Global Utility Accrual} (or GUA) class of algorithms. 

The algorithms construct a directed acyclic graph representation of the task dependency relationship, and build a global multiprocessor schedule of the \textit{zero in-degree} tasks to heuristically maximize the total accrued utility and ensure mutual exclusion. Potential deadlocks are detected through a cycle-detection algorithm, and resolved by aborting a task in the deadlock cycle. The GUA class of algorithms include two algorithms, namely, the \textit{Non-Greedy Global Utility Accrual} (or NG-GUA) and \textit{Greedy Global Utility Accrual} (or G-GUA) algorithms. NG-GUA and G-GUA differ in the way schedules are constructed towards meeting all task deadlines, when possible to do so. We establish several properties of the algorithms including conditions under which all task deadlines are met, satisfaction of mutual exclusion constraints, and deadlock-freedom. 

We create a Linux-based real-time kernel called ChronOS for multiprocessors. ChronOS is extended from  the \texttt{PREEMPT\_RT} real-time Linux patch, which provides optimized interrupt service latencies and real-time locking primitives. ChronOS provides a scheduling framework for the implementation of a broad range of real-time scheduling algorithms, including utility accrual, non-utility accrual, global, and partitioned scheduling algorithms.

We implement the GUA class of algorithms and their competitors in ChronOS and conduct experimental studies. The competitors include G-EDF, G-NP-EDF, G-FIFO, gMUA, P-EDF and P-DASA. Our study reveals that the GUA class of algorithms accrue higher utility and satisfy greater number of deadlines than the deadline-based scheduling algorithms by as much as 750\% and 600\%, respectively. In addition, we observe that G-GUA accrues higher utility than NG-GUA during overloads by as much as 25\% while NG-GUA satisfies greater number of deadlines than G-GUA by as much as 5\% during underloads.

\vfill

% GRANT INFORMATION

This work was partially supported by the US National Science Foundation.

\pagebreak

% Dedication and Acknowledgments are both optional
\chapter*{Dedication}

\begin{center}
I dedicate this thesis to my family. 

\textit{Without their support this would not have been possible}.
\end{center}

\chapter*{Acknowledgments}

I would like to thank my advisor, Dr. Binoy Ravindran, for his 
help and guidance on both technical and personal 
topics. It has been an honor to work under him and I am highly indebted
to him for his trust in me.

I would also like to thank Dr. Robert Broadwater and Dr. Mark Jones,
for serving on my committee and providing their valuable feedback
and direction. In addition, I would like to thank all of my colleagues
at the Systems Software Research lab. I would particularly like to thank
Alex Turcu, Mohd. Saad and Aditya Dhoke for their support and encouragement.
It was a pleasure to work with them and perform interesting research in area 
of Distributed Transactional Memory.

Finally, I would like to thank my family and friends for all the
love and support they have given me, without which this thesis would 
not have been possible.

All figures in thesis are the work of the author, unless specified otherwise.

\tableofcontents
\pagebreak

\listoffigures
\pagebreak

\listofalgorithms
\pagebreak

\listoftables
\pagebreak

\printnomenclature
\pagebreak

\pagenumbering{arabic}
\pagestyle{myheadings}


\chapter{Introduction}\label{chap:intro}
\markright{Sudhanshu Mishra \hfill Chapter~\ref{chap:intro}.
Introduction
\hfill}

Recently, there has been a shift in the computer industry from increasing clock rates to designing multi-core and hyper-threading architectures in a quest to produce faster computers~\cite{sutterlunch}. Motivated by heat and power issues, most chip manufacturers have chosen the route of increasing system and chip level parallelism in preference to increasing clock rates in order to satisfy the need for improving performance. This trend extends to embedded systems~\cite{embeddedmulti} as well as to traditional computing systems. Consequently, the design of multiprocessor\footnote{We will use multiprocessor and multi-core interchangeably in the rest of the thesis unless explicitly stated otherwise.} 
real-time scheduling algorithms has become important in order to allow real-time applications to take advantage of these emerging architectures.

Scheduling of real-time multiprocessor systems has received increased attention recently~\cite{Carpenter04acategorization}. However, most of these works target ``underloaded" systems---i.e., systems where the total application task utilization demand, $U$, is always less than the total available processing capacity of the system, which is $m$ for an $m$-processor system. Majority of the research focus in multiprocessor real-time systems is on developing scheduling algorithms and understanding their \textit{schedulability utilization bounds}---i.e., task utilization bounds below which all task deadlines are  met. The premise of this approach is that it is possible to determine the worst-case execution-time behaviors of applications (e.g., task arrival behaviors, task worst-case execution times) and thereby determine the total task utilization demands. Once the task utilization demand is known, task schedulability---i.e., the ability to meet all task deadlines---can be ensured off-line by selecting the appropriate scheduling algorithm with a higher utilization bound.

For some applications (e.g.,~\cite{Wishper,Clark_anadaptive,multimedia}), it is difficult to determine worst-case  execution-time behaviors \textit{a priori}, as they are subject to run-time exigencies, such as execution time overruns and unpredictable thread arrival patterns, causing transient and permanent overloads. When overloads occur, often, such applications desire graceful timeliness degradation---e.g., meeting as many deadlines of high importance tasks as possible, irrespective of task urgency. 

\section{Timeliness Model}

The state-of-the-real-time practice is to handle application time constraints using the concept of \textit{priorities}. This approach is the basis for the vast majority of real-time OS, language, and middleware standards including POSIX~\cite{posix}, Real-time CORBA~\cite{omg0901}, Ada 95~\cite{ada95}, and RTSJ~\cite{rtsj-book}. 
%%BR: reorder the standard list to match OS standard first, followed by those in languages, and then middleware
However, using priorities have inherent shortcomings, which include:
\begin{enumerate}
\item The process of assigning time constraints to priorities is generally difficult, and sometimes intractable. Often, there is significant loss of information during this process which makes it difficult to dependably satisfy time constraints.

\item Real-time systems usually comprise of various sub-systems. In order to assign priorities to express urgency, it is necessary to know the entire system and its various sub-systems, along with the knowledge of the global assignment of priorities for the entire system. Such knowledge can sometimes be difficult to obtain due to organizational boundaries.

\item The urgency and importance of a real-time task can be orthogonal---e.g., the most important task can be the most urgent; the most important task can be the least urgent, etc. However, a priority cannot express both. This causes serious difficulties during overload situations, when not all task deadlines can be met, and applications desire to differentially allocate resources in the order of decreasing task importance, irrespective of task urgency---e.g., most important task first; second-most important task second, and so on.
\end{enumerate}

One solution that overcomes these shortcomings is to provide system developers with abstractions for directly specifying time constraints (instead of mapping time constraints to priorities) and using those time constraint specifications to manage resources (instead of indirectly managing resources through the priority artifact). This is the basis for the traditional real-time theory~\cite{RTbook, liu-book}. In that theory, time constraints (which are largely limited to deadlines) are mapped to fixed priorities in algorithms such as Rate Monotonic Scheduling (RMS)~\cite{liu73scheduling}\nomenclature{RMS}{Rate Monotonic Scheduling algorithm} and Deadline Monotonic Scheduling (DMS)~\cite{liu73scheduling}\nomenclature{DMS}{Deadline Monotonic Scheduling}, or are mapped to dynamic priorities as in Least Laxity First (LLF)~\cite{mok83-llf}\nomenclature{LLF}{Least Laxity First}, or are directly used for scheduling as in Earliest Deadline First (EDF)~\cite{horn-edf}\nomenclature{EDF}{Earliest Deadline First}. 

However, deadline and deadline-based scheduling suffer from some drawbacks. A deadline of a task can be expressed in two forms. First, as a binary-valued expression which evaluates to the deadline being met or not met; and second, a linear-valued expression for the penalty of lateness. However, the penalty of being late per unit time is constant irrespective of how late the task actually is. Thus, deadlines per se cannot be used to distinguish between task urgency and task importance, which is a limitation during overloads.  Furthermore, classical deadline-based scheduling algorithms (e.g., EDF) suffer from the \textit{domino} effect~\cite{loc86} during overloads. This is because, these algorithms always favor tasks with an earlier deadline, irrespective of how close such tasks are towards missing their deadlines. This results in those tasks missing their deadlines, and also causing others, which are now delayed, to miss their deadlines. 

Timeliness optimality criteria that can be specified using deadlines fall into the following categories:
\begin{inparaenum}[(i)]
\item the criterion of meeting all deadlines;
\item criteria that are based on number of missed deadlines---e.g., minimize the number of deadline misses; upper bound the number of deadlines missed; and
\item the criteria expressed using lateness---e.g., minimize the maximum lateness; upper bound the lateness.
\end{inparaenum} 

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./eps/tuf-intro}
  \caption{Example TUF time constraints. (a) MITRE Airborne Warning and Control System (AWACS) \textit{association} TUF~\cite{Clark_anadaptive};
	(b-c) GD/CMU air defense \textit{plot correlation}, \textit{track maintenance}, and \textit{missle control} TUFs~\cite{archons88}; 
	(d) step TUFs}
  \label{fig:tuf-intro}
\end{figure}

The shortcomings of deadlines and deadline-based scheduling are overcome in the Time/Utility Function (TUF) model\nomenclature{TUF}{Time/Utility Functions}, first introduced in~\cite{TUFjensen85time}. A TUF specifies the utility obtained by the completion of a task, as a function of that task's completion time. Figure~\ref{fig:tuf-intro} shows some example TUFs. Figure~\ref{fig:tuf-intro}(a)-(c) show time constraints of some applications in the defense domain~\cite{Clark_anadaptive,archons88}. A TUF decouples importance and urgency, with the urgency measured as a deadline on the X-axis, and importance measured as a utility (or value) on the Y-axis.  The classical deadline is a special case of a TUF: a binary-valued, downward ``step" TUF. Figure~\ref{fig:tuf-intro}(d) shows an example. 

When task time constraints are expressed using TUFs, the scheduling optimality criteria are often based on accrued utility---e.g., maximizing the sum of the tasks' attained utilities. Such criteria are called \textit{Utility Accrual} (or UA)\nomenclature{UA}{Utility Accrual} criteria and scheduling algorithms that optimize such criteria are called UA scheduling algorithms (e.g.,~\cite{DASA,loc86}).
%%BR: Cite all past UA algms. See the paper "On Recent Advances ..." ISORC 2005.

UA scheduling algorithms that maximize total accrued utility under downward ``step" TUFs, default to EDF during underloads, since EDF satisfies all deadlines during underloads. As a result, these algorithms obtain optimal total accrued utility during underloads. During overloads, UA scheduling algorithms favor tasks from whom greater utility can be accrued (as that generally tends to maximize the total accrued utility), irrespective of task urgency. This behavior of UA scheduling algorithms is called ``best-effort" --- i.e., the algorithms strive their best to feasibly complete as many high importance tasks as possible (where task importance is explicitly described using TUFs).\footnote{Note that the term ``best-effort" as used in the networking context is intended to mean ``least-effort."} Note that the optimal timeliness behavior of EDF is a special case of UA-scheduling. 

A number of UA algorithms have been designed in the past. These cover a wide range of problem spaces: from processor scheduling~\cite{loc86, DASA, cho-thesis06, Li-Thesis, Li04, Li06, cho10};
to memory management and garbage collection~\cite{cho09-gc, cho07-gc, Feizabadi05-gc};
to non-blocking synchronization~\cite{cho-thesis06, cho_lock_free, cho_wait_free2};
to energy management~\cite{wu-thesis, Wu07, Balli07, Wu06};
to packet scheduling~\cite{gene-thesis, gene04}; and
to network routing~\cite{karthik-thesis, karthick06, Ramaswamy02};
They also cover step TUFs~\cite{DASA};
to non-step TUFs~\cite{cho-thesis06, cho_lock_free, cho_wait_free2, gene-thesis, wu-thesis, karthik-thesis, Ramaswamy02};
to abitrarily-shaped TUFs~\cite{Li-Thesis}.


\section{Multiprocessor Real-Time Scheduling}

One unique aspect of multiprocessor real-time scheduling is the
degree of run-time migration that is allowed for job instances of a
task across processors (at scheduling events). Example migration
models include:
\begin{inparaenum}[(1)]
\item \textit{full migration}, where jobs are allowed to arbitrarily migrate across processors during their execution.
This usually implies a global scheduling strategy, where a single
shared scheduling queue is maintained for all processors and a
processor-wide scheduling decision is made by a single (global)
scheduling algorithm;
\item \textit{no migration}, where tasks are statically (off-line) partitioned and allocated to
processors. At run-time, job instances of tasks are scheduled on
their respective processors by processors' local scheduling
algorithm, like single processor scheduling; and
\item \textit{restricted migration}, where some form of migration is allowed---e.g., at job
boundaries.
\end{inparaenum}

The partitioned scheduling paradigm has several advantages over
the global approach. First, once tasks are allocated to
processors, the multiprocessor real-time scheduling problem
becomes a set of single processor real-time scheduling problems,
one for each processor, which has been well-studied and for which
optimal algorithms exist. Second, not migrating tasks at run-time
means reduced run-time overhead as opposed to migrating tasks that
may suffer cache misses on the newly assigned processor. If the task set is fixed and known a priori, the partitioned approach provides appropriate solutions~\cite{GEDF}.

The global scheduling paradigm also has advantages over the
partitioned approach. First, if tasks can join and leave the system
at run-time, then it may be necessary to reallocate tasks to
processors in the partitioned approach~\cite{GEDF}. Second, the
partitioned approach cannot produce optimal real-time schedules
--- one that meets all task deadlines when task utilization demand does not
exceed the total processor capacity --- for periodic task
sets~\cite{shab03}, since the partitioning problem is analogous to
the bin-packing problem which is known to be NP-hard in the strong
sense. Third, in some embedded processor architectures with no
cache and simpler structures, the overhead of migration has a
lower impact on the performance~\cite{GEDF}. Finally, global
scheduling can theoretically contribute to an increased
understanding of the properties and behaviors of real-time
scheduling algorithms for multiprocessors.(See~\cite{ha06} for a
detailed discussion on this).

Carpenter \textit{et al.}~\cite{Carpenter04acategorization} have catalogued
multiprocessor real-time scheduling algorithms considering the
degree of job migration and the complexity of priority mechanisms
employed. The latter includes classes such as
\begin{inparaenum}[(1)] \item \textit{static}, where task priorities never change, e.g., rate-monotonic (RM); \item
\textit{dynamic but fixed within a job}, where job priorities are
fixed, e.g., earliest-deadline-first (EDF); and \item
\textit{fully-dynamic}, where job priorities are dynamic.
\end{inparaenum}

The Pfair class of algorithms~\cite{pfair1} that allow full
migration and fully dynamic priorities have been shown to be
theoretically optimal---i.e., they achieve a schedulable
utilization bound (below which all tasks meet their deadlines)
that equals the total capacity of all processors. However, Pfair
algorithms incur significant run-time overhead due to their
quantum-based scheduling approach~\cite{devi_tardiness,shab03}. Under Pfair,
tasks can be decomposed into several small uniform segments, which
are then scheduled, causing frequent scheduling and migration.

%%PG: Ask BR for these eps files
\begin{figure}[htbp]%
\centering 
    \subfigure[]{
        \label{fig:edf_example_a}
%        \hspace{-0.6cm}%
        \includegraphics[scale=1]{./eps/edf1.eps}
    }\hspace{40pt}
    \subfigure[]{%
        \label{fig:edf_example_b}
%        \hspace{-0.7cm}%
        \includegraphics[scale=1]{./eps/edf2.eps}
    }
\caption{Sample EDF schedule on two processors -- (a) that cannot be scheduled; and (b) that can be scheduled.}
\label{fig:edf_example}
\end{figure}

Thus, scheduling algorithms other than Pfair---e.g., global-EDF~\cite{GEDF, Baruah-gnpedf, anderson_pedf} have also been intensively
studied though their schedulable utilization bounds are lower.
Figure~\ref{fig:edf_example_a} shows an example task set that
global-EDF cannot feasibly schedule. In Figure~\ref{fig:edf_example_a}, task $T_1$ will miss
its deadline when the system is given two processors. However, for the same task-set,
there exists a schedule that meets all task deadlines, as shown in Figure~\ref{fig:edf_example_b}.

There have also been efforts on designing optimal multiprocessor real-time scheduling algorithms that are not based on time quantum, unlike Pfair.  Examples include the Largest Local Remaining Execution Time (or LLREF) algorithm\nomenclature{LLREF}{Largest Local Remaining Execution time First scheduling algorithm} and its derivatives~\cite{cho_llref, chen08, Funaoka08}.

Interestingly, all of these works exclude any run-time exigencies and consequent transient/permanent overloads---i.e., they presume that it is possible to determine the worst-case execution-time behaviors of applications (e.g., task arrival behaviors, task worst-case execution times), determine the total task utilization demands, and thus conduct off-line task schedulability, as mentioned before. Thus, the need for graceful timeliness degradation and best-effort timing assurances are outside their scope.

In~\cite{Lakshmanan09}, Lakshmanan \textit{et al.} provide a classification of multiprocessor scheduling algorithms based on their schedulability bounds and we summarize the classification in Figure~\ref{fig:schedbounds}. In the global scheduling space, (at the time of writing this thesis), PFair and LLREF are the only known optimal multiprocessor scheduling algorithms that are able to meet all deadlines and have the optimal utilization bound of 100\% (i.e., $U = m$)~\cite{pfair1}. The dynamic priority algorithms that include deadline-based algorithms, such as G-EDF, and UA-based algorithms that default to G-EDF, such as gMUA, have the higher utilization bound of 50\%~\cite{Baker05, cho-thesis06} (i.e., $U \approx m/2$). On the other hand, fixed priority algorithms, such as RMS, have a utilization bound of 33\%~\cite{Andersson01} (i.e., $U  \approx 3m/8$). In the partitioned scheduling space, both the dynamic priority algorithms, such as P-EDF and the fixed priority algorithms like P-DMS, have a utilization bound of 50\%~\cite{lopez04} (i.e., $U  \approx m/2$). However, in~\cite{Lakshmanan09}, a version of P-DMS called PDMS-HPTS-DS, that uses high priority task-splitting (HPTS) with decreasing order of size (DS) is shown to have a utilization bound of 65\%.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=.75]{./eps/sched-bounds}
  \caption{Schedulability bounds of multiprocessor scheduling algorithms from~\cite{Lakshmanan09}.}
  \label{fig:schedbounds}
\end{figure}

%%BR: I suggest that you add a new paragraph here that summarizes the schedulability bounds of all global and partitioned schedulers here (in terms of m bounds, etc., like in the Introduction section of Anderson's papers), and also providing a table like the one from CMU's. If you go with the CMU paper's table, be sure to cite the paper in the caption of the table for correct attribution.

\section{Multiprocessor Real-Time Scheduling During Overloads}

Almost all of the past work on overload real-time scheduling~\cite{loc86, DASA, cho-thesis06, Li-Thesis, Li04, Li06, cho10}, has focused on single processor systems, with very few exceptions. The only multiprocessor overload real-time scheduling algorithms that we are aware of (at the time of writing this thesis) include the Multiprocessor On-Line Competitive Algorithm (or MOCA)~\cite{MOCA}\nomenclature{MOCA}{Multiprocessor On-Line Competitive Algorithm} and Global Multiprocessor Utility Accrual (or gMUA)~\cite{cho-thesis06}\nomenclature{gMUA}{Global Multiprocessor Utility Accrual} algorithms.

In~\cite{MOCA}, the authors determine the inherent upper bound on the best competitive ratio, in terms of accrued utility, that can be achieved by an online scheduler. They present a scheduling algorithm, MOCA, with a competitive ratio within a constant factor of the best competitive ratio found. MOCA divides the processors in a system into several ``bands", each band being assigned a certain utility density. MOCA attempts to schedule an incoming task on a band that corresponds to its utility. If it is not possible to do so, the task is moved down the bands until one is found that can schedule it. As a result of this design, if a large number of low utility tasks arrive, they will quickly exhaust the lower bands of the system. This scenario may cause incoming low utility tasks to be rejected even though bands associated with higher utilities are idle. 

gMUA is a global, best-effort real-time scheduling algorithm for multiprocessors. Like its single-processor counterparts~\cite{loc86, DASA, cho-thesis06, Li-Thesis, Li04, Li06, cho10}, during underloads (i.e., $U \leq m$), gMUA defaults to global-EDF, and thus meets all deadlines (and accrues optimal total utility) up to a utilization bound of $m/2$. Also, like its single-processor counterparts, during overloads, the algorithm constructs a global multiprocessor schedule, favoring tasks from whom greater utility can be accrued, irrespective of task urgency, yielding graceful timeliness degradation and best-effort timeliness behavior. 

Both MOCA and gMUA exclude task dependencies--i.e., they exclude task synchronization constraints (e.g., due to mutual exclusion) or precedence constraints.

\section{Research Contributions}

Thus, we observe a clear gap in the literature: how to schedule real-time tasks on multiprocessors that are subject to run-time uncertainties causing transient and permanent overloads, and task dependencies,  such that optimal total utility can be accrued when possible and best-effort timeliness behavior, otherwise? 

This problem is NP-hard because its one-processor version is shown to be NP-hard~\cite{DASA}. We solve this problem in the thesis by developing a class of polynomial-time heuristic algorithms, called the \textit{Global Utility Accrual} (or GUA) class of algorithms. The algorithms construct a directed acyclic graph representation of the task dependency relationship, and build a global multiprocessor schedule of the \textit{zero in-degree} tasks to ensure mutual exclusion. Potential deadlocks are detected through a cycle-detection algorithm, and resolved by aborting a task in the deadlock cycle. We use the heuristics of the Potential Utility Density (or PUD)\nomenclature{PUD}{Potential Utility Density}, which was defined by Clark in~\cite{DASA}\nomenclature{DASA}{Dependent Activity Scheduling Algorithm}, to heuristically maximize the total accrued utility.

The GUA class of algorithms include two algorithms, namely, the \textit{Non-Greedy Global Utility Accrual}\nomenclature{NG-GUA}{Non-Greedy Global Utility Accrual} (or NG-GUA) and \textit{Greedy Global Utility Accrual}\nomenclature{G-GUA}{Greedy Global Utility Accrual} (or G-GUA) algorithms. NG-GUA and G-GUA differ in the way schedules are constructed towards meeting all task deadlines, when possible to do so. While NG-GUA constructs a global schedule that defaults to G-EDF's schedulability bound, G-GUA does not default to any algorithm. However, both NG-GUA and G-GUA try to maximize the total accrued utility. The greediness in the name of these algorithms describes the tendency of the algorithms to accrue as much total utility as possible. As the names suggest, G-GUA is more greedy for utility accrual when compared to NG-GUA. We establish several properties of the algorithms including conditions under which all task deadlines are met, satisfaction of mutual exclusion constraints, and deadlock-freedom. We also establish the asymptotic cost of both the algorithms.

We create a Linux-based real-time kernel called ChronOS for multiprocessors. ChronOS is extended from the \texttt{PREEMPT\_RT} real-time Linux patch~\cite{preempt_rt}, which provides optimized interrupt service latencies and real-time locking primitives. ChronOS provides a scheduling framework for the implementation of a broad range of real-time scheduling algorithms, including utility accrual, non-utility accrual, global, and partitioned scheduling algorithms. ChronOS provides a modular approach for development of the scheduling algorithms which can be implemented as kernel modules using the provided scheduler plugins.

We implement the GUA class of algorithms and their competitors in ChronOS and conduct experimental studies. The competitors include: EDF, G-EDF, G-NP-EDF, G-FIFO, gMUA, G-FIFO-PIP, G-NP-EDF-PIP, P-EDF and P-DASA. Our study reveals the following results:
\begin{asparaenum}[(1)]
	\item In the absence of dependencies, the GUA class of algorithms accrue higher 
	utility and satisfy greater number of deadlines than the deadline-based algorithms 
	(G-EDF, G-NP-EDF) by as much as 750\% and 600\%, respectively.
	\item In the absence of dependencies, the GUA class of algorithms accrue higher
	utility and satisfy greater number of deadlines compared to the partitioned algorithms
	by as much as 90\% and 75\%, respectively for P-DASA; and 450\% and 600\%,
	respectively for P-EDF.
	\item As gMUA defaults to NG-GUA without dependencies, the performance of NG-GUA
	and gMUA is similar.
	\item However, G-GUA outperforms NG-GUA and gMUA by accruing 25\% more utility, 
	while both NG-GUA and gMUA satisfy 5\% more deadlines during underloads than G-GUA.
	
	\item In the presence of dependencies, both NG-GUA and G-GUA accrue higher utility and
	satisfy greater number of deadlines than G-NP-EDF-PIP by as much as 250\% and 150\%, respectively.
\end{asparaenum}

To summarize, the research contributions of the thesis include:
\begin{enumerate}
	\item the GUA class of multiprocessor real-time scheduling algorithms that allow tasks to be subject to run-time uncertainties, overloads, and dependencies, and yield optimal total utility when possible and best-effort timeliness behavior otherwise --- the first such multiprocessor real-time scheduling algorithms to do so.
	\item the ChronOS multiprocessor real-time Linux kernel that provides optimized interrupt service latencies and real-time locking primitives (by virtue of \texttt{PREEMPT\_RT} patch) and a scheduling framework that allows the implementation of a broad range of real-time scheduling algorithms, including utility accrual, non-utility accrual, global, and partitioned scheduling algorithms -- the first such multiprocessor real-time Linux kernel.
\end{enumerate}

\section{Thesis Organization}

The rest of the thesis is organized as follows: Chapter~\ref{chap:related-work} overviews past and related work in the multiprocessor real-time scheduling space, and contrasts them with the thesis's problem space. Chapter~\ref{chap:models-and-objective} describes our models and scheduling objective. Chapter~\ref{chap:algorithm} presents the GUA class of algorithms, including G-GUA and NG-GUA. The algorithm rationale, design, pseudo-code description, and algorithm properties are described in this chapter.

Chapter~\ref{chap:chronos} describes the ChronOS real-time Linux. We report our experimental studies in Chapter~\ref{chap:exp_res}. Finally, we conclude the thesis in Chapter~\ref{chap:conclusion}.


%%BR: STOPPED HERE. 6/12, 5:52PM.


%%%%% Using BR's introduction - END %%%%





\chapter{Related Work}\label{chap:related-work}
\markright{Piyush Garyali \hfill Chapter~\ref{chap:related-work}.
Related Work
\hfill}

In this chapter we survey the past and related work focusing on the problem of scheduling on multiprocessors. The work can be classified into two categories ---
\begin{inparaenum}[(i)]
\item classification based on the degree of run-time migration; and 
\item classification based on the utilization load.
\end{inparaenum}
We discuss these in Sections~\ref{sec:task-migration} and~\ref{sec:util-load}, respectively.

\section{Classification Based on Degree of Task Migration} \label{sec:task-migration}
Carpenter \textit{et al.}~\cite{Carpenter04acategorization} have classified the scheduling algorithms based on the degree of run-time migration, considering three categories:
\begin{inparaenum}[(i)]
	\item no migration;
	\item restricted migration;
	\item and full migration. 
\end{inparaenum}

\textit{No migration} refers to the approach of partitioned scheduling. In this approach, tasks are assigned to processors using an off-line assignment algorithm and each processor runs an instance of an independent single processor algorithm. Partitioned Earliest Deadline First (P-EDF)\nomenclature{P-EDF}{Partitioned Earliest Deadline First scheduling algorithm}~\cite{anderson_pedf} is one example that uses the optimal uniprocessor scheduling algorithm EDF. As the partitioned approach involves partitioning the tasks among processors, it can be shown to be equivalent to the NP-Hard bin-packing problem. The tasks are usually partitioned using polynomial time heuristic algorithms such as, first-fit, worst-fit and best-fit. In~\cite{baruah-part-06}, Baruah \textit{et al.} present an optimized first-fit partitioning algorithm. The key idea of the algorithm is to assign tasks to processor bins such that the tasks assigned to the processors create a feasible schedule. %The algorithm, however, only deals with underload scheduling. If the tasks in the given task-set result in a overload condition, the algorithm declares that the task-set cannot be partitioned.

In the \textit{restricted migration} category, jobs are executed entirely on a single processor but they are allowed to migrate on job boundaries -- with different jobs of the same task allowed to execute on different processors. Each job's runtime context needs to be maintained only on a single processor. However, the task-level context is allowed to be migrated. In~\cite{anderson_pedf}, for a restricted migration model, where migration is allowed only at job boundaries, Anderson \textit{et al.} present an EDF-based partitioning scheme and scheduling algorithm that ensures bounded tardiness.

The \textit{full migration} algorithms are the global algorithms that place no restriction upon interprocessor migration. The key idea of global scheduling is to maintain a single ready queue that has all the tasks released in the system which are eligible to be scheduled. The global queue is maintained according to some scheduling discipline and tasks are dispatched from this queue to any free processor. 

Most of the global scheduling algorithms default to a single processor optimal algorithm such as Earliest Deadline First (EDF), or Rate Monotonic (RMS) algorithm. G-EDF~\cite{GEDF} (\textit{Global Earliest Deadline First}) orders the global queue based on the earliest deadline first order and the tasks are assigned to processors accordingly. However, once a scheduling event is triggered on one processor, a new schedule is created for which all tasks executing on other processors need to be preempted. In~\cite{Baruah-gnpedf}, Baruah derives the feasibility conditions for the non-preemptive version of G-EDF called the G-NP-EDF (\textit{Global non-preemptive EDF}). In~\cite{devi_tardiness}, Devi \textit{et al.} derive the tardiness bounds for G-EDF and G-NP-EDF.

In~\cite{pfair1,pfair2} Baruah \textit{et al.} present a different global scheduling approach, called PFair~\cite{pfair1} (\textit{Proportionate Fair})\nomenclature{PFair}{Proportionate Fair Scheduling Algorithm} scheduling, which divides a task into quantum sized ``sub-tasks" that are treated as the scheduleable entities. Each ``sub-task" must execute within a ``window" of time slots, where the last ``window" is the deadline of the task. This approach has been shown to realize full system utilization and hence Pfair-based algorithms are optimal during underloads ($U \le m$)~\cite{pfair1,pfair2}. A particularly efficient version of Pfair scheduling, PD$^2$, was developed in~\cite{pfair_anderson} and its scalability was showcased in~\cite{scalabilitypfair}. However, Pfair algorithms incur significant scheduling overheads due to their quantum-based scheduling approach as shown in~\cite{devi_tardiness}. Although, Pfair is optimal during underloads, its behavior during overloads follows an EDF-like pattern. This is because Pfair continues to use the notion of earliest deadline, even at the ``sub-task" level. In~\cite{cho_llref} Cho \textit{et al.} describe the LLREF scheduling algorithm. LLREF is a optimal real-time scheduling algorithm for multiprocessors which is not based on time quanta. 

%The algorithm is based on the fluid scheduling model and the fairness notion.

\section{Classification Based on Utilization Load}\label{sec:util-load}

Scheduling algorithms can also be classified based on those that assume the total utilization $U \le m$, where $m$ is the number of CPUs\nomenclature{CPU}{Central Processing Unit} and those that assume $U$ to be arbitrary. The former condition is referred to as \textit{underload} while the later is referred to as \textit{overload}. For multiprocessor systems, it has been shown that partitioned and non-Pfair global scheduling have similar schedulability bounds~\cite{Carpenter04acategorization} and that these bounds are significantly below full system utilization. Algorithms that are not specifically designed to address overloads can suffer an unacceptable amount of degradation when they occur~\cite{uniprocessor_overloads,MOCA}. What is needed is a set of algorithms that are designed with overload scheduling specifically in mind. This would allow these algorithms to successfully schedule as many high importance tasks as possible during overloads.

On single processor systems, Utility Accrual algorithms, such as DASA~\cite{DASA} and LBESA~\cite{loc86}, that maximize accrued utility for downward ``step" TUFs default to EDF during underloads, since EDF satisfies all deadlines during underloads, consequently maximizing possible accrued utility. During overloads, they favor more important activities, irrespective of urgency. Thus, deadline scheduling's optimal timeliness behavior is a special case of utility accrual scheduling for single processor systems.

For a multiprocessor system, gMUA~\cite{cho-thesis06} and MOCA~\cite{MOCA} scheduling algorithms provide best-effort utility accrual during overloads. gMUA defaults to global-EDF, a non-optimal scheduling algorithm, during underloads. During overloads, gMUA tries to maximize accrued utility. MOCA, on the other hand, divides the processors into ``bands" where each band is assigned a certain utility density. MOCA attempts to schedule an incoming task on a band that corresponds to its utility. If it is not possible to execute the task on its utility band, MOCA moves the task down the bands until one is found that can schedule it. As a result of this design, if a large number of low utility tasks arrive, they will quickly exhaust the lower bands of the system and this scenario may cause incoming low utility tasks to be rejected even though bands associated with higher utilities are idle.

Both gMUA and MOCA suffer from lack of support for resources, such as locks, and their behavior in the presence of dependencies has not been studied.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./eps/compare}
  \caption{Characterization of scheduling algorithms during underloads ($U \le m$) and overloads ($U > m$) 
  based on ability to meet all deadlines and bounded best-effort real-time time interval.}
  \label{fig:compare}
\end{figure}

\section{Summary}

Figure~\ref{fig:compare} gives a summary of the classification discussed in this chapter. We observe the following:
\begin{enumerate}
	\item During underloads (for $U \le m$) only Pfair (PD$^2$) and LLREF scheduling algorithms can meet all deadlines. This is primarily because these algorithms have been proven to be optimal during underloads.
	\item During underloads, G-EDF, G-NP-EDF and P-EDF scheduling algorithms can only meet their deadlines upto $U \approx m/2$.
	\item During underloads, an optimal best-effort behavior can be seen in Pfair(PD$^2$) and LLREF. This is due to the fact that they are optimal during underloads.
	\item During overloads, none of the scheduling algorithm can meet their deadlines.
	\item During overloads, none of the scheduling algorithms provide a best-effort bound on the real-time interval.
	\item There are no scheduling algorithms that provide best-effort behavior during overloads in the presence of dependencies.
\end{enumerate}

There is a clear gap in the past work, that establishes a need for best-effort utility accrual real-time scheduling algorithms for multiprocessors, that provides best-effort behavior during overloads for dependent tasks. We bridge this gap by designing the NG-GUA and G-GUA scheduling algorithms which we discuss in detail in the subsequent chapters.


\chapter{Models and Objective}\label{chap:models-and-objective}
\markright{Piyush Garyali \hfill Chapter~\ref{chap:models-and-objective}.
Models and Objective
\hfill}

\section{Thread Model}
We consider the programming model where each task, $T_i$, can have a periodic or an aperiodic execution. Each such invocation of the task, $T_i$, is referred to as phase $J_i$. Each phase has an estimated best-faith\footnote{This is an estimate of execution time, not an upper bound, and may be violated at runtime} execution time $e_i$ and a deadline $d_i$. No specific task arrival pattern is assumed.

Tasks can be implemented using threads on an operating system. There are two models that can be used. A single thread can be created that represents the task and all its phases. At the end of the task's period, the thread goes to sleep and wakes up at the next period. Hence, each phase of the task can be executed on the same thread with a call to a function such as \texttt{sleep\_until\_next\_period()} between phase invocations. We call this the ``thread-is-a-task" model. On the other hand, an individual thread could represent each phase of a task. Hence, at the invocation of each phase of a given task, a separate thread is fired. We call this the ``thread-is-a-phase" model.

\section{Timeliness Model}
We specify the time constraint of each task using a Time/Utility Function (TUF)~\cite{TUFjensen85time}. A TUF allows us to decouple the urgency of a task from its importance. This decoupling is a key property allowed by TUFs since the urgency of a phase may be orthogonal to its importance. A task $T_i$'s TUF is denoted as $U_i \left(t \right)$. A classical deadline is unit-valued---i.e., $U_i(t) = \{1,0\}$, since importance is not considered. Downward step TUFs generalize classical deadlines where $U_i(t) = \{\{m\},0\}$. We focus on downward step TUFs, and denote the maximum, constant utility of a TUF $U_i \left(t \right)$, simply as $U_i$. 

Each TUF has an initial time $I_i$, which is the earliest time for which the TUF is defined, and a termination time $X_i$, which, for the special case of downward ``step" TUFs we consider, is its discontinuity point. Equations~\ref{eq:tuf}a-b describe the mathematical representation of a downward ``step" TUF.

\begin{subequations}
	\label{eq:tuf}
	\begin{align}
		U_i \left( t \right) > 0,\forall t \in \left[ {I_i ,X_i } \right], \forall i \\
		U_i \left( t \right) = 0,\forall t \notin \left[ {I_i ,X_i} \right], \forall i
	\end{align}
\end{subequations}


\section{Resource Model}
A resource $R_j$ has a critical section length, $C_j$. The length of the critical section can be variable. Any phases $J_i$ can request a resource $R_j$ and enter critical sections by invoking APIs such as \texttt{ResRequest()}. Until the request for $R_j$ is granted, the phase is said to be \texttt{blocked} on the resource. Once $R_j$ is granted to $J_i$, we refer to $J_i$ as the \texttt{Owner} of the resource. $J_i$ invokes \texttt{ResRelease()}\footnote{These sample APIs have been used for the sake of explanation of the concept} to complete the critical section. There is no restriction on the number of phases that may request a resource. However, a phase can only be blocked on a single resource which is being owned by another phase. We refer to this as the single-unit resource model.

\section{Processor Model}
We consider a multiprocessor/multi-core architecture with $M$ cores/processors. In the rest of the thesis, cores and processors will be used interchangeably unless explicitly stated otherwise.

\section{Abort Model}

We consider the model in which any phase that has blown its deadline can be aborted by the system. The phase is sent an abort signal which is handled by the phase using an \texttt{abort\_handler}. The handler is used by the phase to release any resources that it may have requested or owned.  

\section{Scheduling Objective}

As mentioned earlier, the problem of scheduling real-time tasks on multiprocessors that are subject to run-time uncertainties causing transient and permanent overloads, is NP-Hard.

Our primary objective is to design a class of polynomial-time heuristic\footnote{Another approach of solving this problem is by designing approximate algorithms. We chose the heuristics route because it is easier to design a heuristic algorithm as compared to an approximation. Also, the insights provided by a heuristic algorithm can be useful in the design of approximate algorithms.} algorithms that provide best-effort utility accrual during overloads in the presence of dependencies (such as locks) on a multiprocessor system. The algorithms should yield optimal total utility when possible and best-effort timeliness behavior otherwise.

\chapter{The GUA Class of Real-Time Scheduling Algorithms}\label{chap:algorithm}
\markright{Piyush Garyali \hfill Chapter~\ref{chap:algorithm}.
The GUA Class of Real-Time Scheduling Algorithms
\hfill}

In this chapter we present the \textit{Global Utility Accrual} (GUA) class of algorithms. We discuss two algorithms in detail --- \textit{Non-Greedy Global Utility Accrual} (NG-GUA) and \textit{Greedy Global Utility Accrual} (G-GUA). The non-greedy variant defaults to \textit{Global Earliest Deadline First} scheduling algorithm with \textit{Priority Inheritance Protocol} (G-EDF-PIP) during underloads, while maximizing the total accrued utility during overloads. On the other hand, the greedy algorithm uses the concept of Global Value Density (GVD) to maximize accrued utility during both underloads as well as overloads.

%\section{Algorithms for Global Scheduling}

\section{Ensuring Mutual Exclusion}\label{sec:algo:me}

%The GUA class of algorithms present a set of heuristics for scheduling jobs on a multiprocessor systems in the presence of dependencies.

When resources, such as locks, are used, it is important to ensure mutual exclusion. Consider Figure~\ref{fig:chain} which shows a dependency chain consisting of nine phases and three resources. Phases $T_1$ and $T_2$ require resource $R_1$, which is owned by $T_4$. Phases $T_4$ and $T_5$ require resource $R_2$, which is owned by phase $T_6$. Phase $T_3$ requires resource $R_3$, which is owned by phase $T_7$. Phases $T_8$ and $T_9$ do not require any resources and are independent. In order to ensure mutual exclusion, we can only schedule phases that do not have a dependency on other phases.

We construct a global precedence graph, which is a directed acyclic graph (DAG\nomenclature{DAG}{Directed Acyclic Graph}), of the phases with the nodes representing the phases and the edges representing the resources being requested. Figure~\ref{fig:dag} gives the graph representation of the dependency chain shown in Figure~\ref{fig:chain}. Phase $T_6$ owns resource $R_2$, which is being requested by phases $T_4$ and $T_5$ and therefore they are dependent on phase $T_6$. This is represented in the graph as an edge $R_2$ from $T_6$ directed towards phases $T_4$ and $T_5$. In a similar fashion, phase $T_4$ currently owns resource $R_1$, which is being requested by phases $T_1$ and $T_2$. Hence, we see an edge from phase $T_4$ towards phases $T_1$ and $T_2$. Similarly, we have an edge from phase $T_7$ to $T_3$, which requires resource $R_3$ that is being owned by phase $T_7$. Phases $T_8$ and $T_9$ do not have any resources requested and hence are represented as independent nodes.

\begin{figure} [!t]
  \centering
   \includegraphics[scale=1.3]{./eps/dc}
  \caption{A phase and resource dependency chain with nine phases and three resources}
  \label{fig:chain}
\end{figure}

All the nodes in the given DAG that do not have any edges from any other node are referred to as \textit{zero in-degree} phases. In order to construct a schedule that respects mutual exclusion, we consider only the \textit{zero in-degree} phases, as these represent phases that are not dependent on any other phase.

\section{Maximizing Accrued Utility}\label{algo:max-ua}

In order to define a measure for the benefit that a given phases' completion can bring to the total accrued utility of the system, we use the concept of Potential Utility Density (or PUD), which was first defined by Clark in~\cite{DASA}. PUD is defined as the ratio of the remaining execution time of a phase at time $t$ to the utility of the phase defined by the TUF at time $t$, i.e., $U(t)$. The PUD of a phase is a dynamic value as it depends on the remaining execution time of a phase and hence at any given time it denotes the ``return on investment" that can be gained for each unit of processing time assigned to that particular phase.

Clark defines and uses PUD in DASA~\cite{DASA} when considering phases that are dependent on each other. Clark considers the PUD of the entire group involved in a dependency relationship and uses the concept as an indicator of the urgency to execute a phase that blocks other phases; and also as a measure of the total benefit that the system will accrue if the entire dependency chain is executed while respecting mutual exclusion. However, as DASA is a uniprocessor scheduling algorithm, only a single phase can be executed at any given time $t$.

\begin{figure} [htpb]
  \centering
   \includegraphics[scale=1.3]{./eps/dag}
  \caption{Directed Acyclic Graph (DAG) for the dependency chain shown in Fig~\ref{fig:chain}. The nodes with a
  zero in-degree are eligible for final schedule in order to preserve mutual exclusion.}
  \label{fig:dag}
\end{figure}

The problem with multiprocessor scheduling is, that it is possible for a scheduler to schedule a phase and one or more of its dependents on two or more processors concurrently. This does not benefit the total system utility accrual given the fact that the phase blocked on a resource is going to waste its CPU cycles. In order to prevent this, we use the DAG to find the set of \textit{zero in-degree} phases that do not have any dependency relationship among each other and hence can be executed concurrently on any given $M$ processors (as discussed in Section~\ref{sec:algo:me}).

However, given a set of $N$ \textit{zero in-degree} phases, we require a method to select the $M$ phases that, when executed on the $M$ processors, would maximize the total accrued utility of the system. For this we define the term \textit{Global Value Density} (or GVD\nomenclature{GVD}{Global Value Density}). To avoid any confusion with the PUD of a phase, we define the term \textit{Local Value Density} (or LVD\nomenclature{LVD}{Local Value Density}) which is equal to the PUD of a given phase and is used instead of PUD in the rest of the thesis. GVD is computed only for the \textit{zero in-degree} phases and it is defined as the sum of the LVD's of individual phases that are in a dependency relation with the given zero in-degree phase.

Consider Figure~\ref{fig:compute-gvd}. We compute the GVD for phases $T_6$, $T_8$ and $T_9$ as these represent the current set of \textit{zero in-degree} phases. The GVD for $T_6$ is computed as: \texttt{GVD($T_6$) = GVD($T_4$) + GVD($T_5$) + LVD($T_6$)}. This is equivalent to: \texttt{GVD($T_6$) = LVD($T_6$) + LVD($T_4$) + LVD($T_5$) + LVD($T_1$) + LVD($T_2$)}. The GVD for $T_8$ and $T_9$ is equivalent to their respective LVDs as these phases do not have dependents.

\begin{figure} [htpb]
  \centering
  \includegraphics[scale=1.3]{./eps/compute-gvd}
  \caption{Computing the global value density for a graph}
  \label{fig:compute-gvd}
\end{figure}

\section{Deadlock Detection and Resolution}\label{algo:dead}

A deadlock can occur if a phase $T_1$, which owns a resource $R_1$, makes a request for another resource $R_2$, which is being owned by a phase currently blocked on a resource $R_i$ in the dependency chain of $T_1$. Figure~\ref{fig:dcdead} gives an example of a deadlock. Phase $T_4$ requires resource $R_2$ which is currently owned by phase $T_3$. Phase $T_3$ requires resource $R_3$ which is owned by phase $T_2$. However, phase $T_2$ is currently blocked on resource $R_1$ which is owned by $T_4$. Hence the deadlock.

\begin{figure} [htpb]
  \centering
  \includegraphics[scale=1.2]{./eps/dc-dead}  
  \caption{A phase and resource dependency chain with a deadlock condition.}
  \label{fig:dcdead}
\end{figure}

A deadlock can be detected during the construction of the DAG. For the given set of phases that are ready for being scheduled, the construction of the DAG involves traversing the list of ready phases and creating a graph that establishes an edge relationship between nodes. For each phase $T_i$, we use API calls such as \texttt{ResRequested($T_i$)} and \texttt{Owner($R_i$)} to find the parent node in the DAG. We compute the relationship between all the dependent nodes in the chain. While the dependency chain is being computed, a list $\sigma_i$ is created with a reference to the nodes in the dependency chain of $T_i$ such that at every step in the construction of the DAG, we check $\sigma_i$ to verify if the node has already been inserted into the DAG. If the node is already in $\sigma_i$, it establishes the presence of a deadlock.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1.2]{./eps/dag-dead}  
  \caption{Deadlock detection and resolution.}
  \label{fig:dagdead}
\end{figure}

Fig~\ref{fig:dagdead} shows the process of DAG construction for the dependency chain of Figure~\ref{fig:dcdead}. We see that there is deadlock between phases $T_6 \rightarrow T_2 \rightarrow T_4 \rightarrow T_6$. At this point we need to remove one of the phases from the deadlocked loop to resolve the deadlock. We remove the \textit{Least Local Value Density} (or Least-LVD) phase amongst the phases that are currently in a deadlock. The rationale behind this approach is to ensure that we only abort a phase that provides the least utility to the total system accrued utility.

Aborting a phase involves marking the phase for immediate completion by sending it a signal. The phase can catch this signal and invoke its \texttt{abort\_handler} to perform a cleanup; releasing resources such as locks. 

\section{Assigning Zero In-degree Phases to Processors}\label{findproc}

In order to assign the \textit{zero in-degree} phases to the processors, we use the concept of the ``least sum of total phase remaining execution time" on each processor, which was first described by Cho in~\cite{cho-thesis06}.
%We use another heuristic for assigning the \textit{zero in-degree} phases to processors. We assign a phase $J$ to the processor which has the least sum of total phase remaining execution times assigned to it. This method was first used by Cho \textit{et al}. in the design of the gMUA scheduling algorithms in~\cite{cho-thesis06}.

Let us assume a set of \textit{zero in-degree} phases along with their respective remaining execution times: $\{T_1:10\}, \{T_2:12\}, \{T_3:5\}, \{T_4:15\}$. Let us consider a multiprocessor system with $M=2$. Initially, the sum of the remaining execution times for phases on each processor is set to zero: $\{p_1:0\}, \{p_2:0\}$. This is because no phase has been currently assigned to the processors. Now, $T_1$ can be assigned either to $p_1$ or $p_2$. Let us assume that $T_1$ is assigned to $p_1$. $T_1$'s remaining phase execution cost gets added to $p_1$. We have, $\{p_1:10\}, \{p_2:0\}$. $T_2$ gets assigned to $p_2$ and we get, $\{p_1:10\}, \{p_2:12\}$. At this point, $T_3$ needs to be assigned to the processors that has the least sum of total phase remaining execution time, which is $p_1$. The process continues until all the phases have been assigned to processors.

\section{Data Structures and Auxiliary Functions}\label{sec:ds-aux}

Before describing the algorithms in detail we list the member variables that can be added to the phase data structure to describe the timeliness model and the DAG representation of the resource model.

\subsection{Data Structure for Timeliness Model}

The following member variables can be used to define the timeliness model for each phase:

\pagebreak

\begin{description}
	\item[\texttt{J.ExecCost}] \hfill \\
		The good faith execution cost of phase $J$.

	\item[\texttt{J.Deadline}] \hfill \\
		The deadline of phase $J$.

	\item[\texttt{J.RemExec}] \hfill \\
		The remaining execution time of a phase $J$. This represents the time that is
		left of the phase's execution cost. The value can be updated every time the
		phase is preempted by the scheduler or just before the new schedule is created.
		This value is used for the calculation of the Value Density for the phase.

	\item[\texttt{J.Utility}] \hfill \\
		The utility of the phase $J$ as represented by its TUF.

	\item[\texttt{J.LocalValDen}] \hfill \\
		The Local Value Density (LVD) of a phase $J$. The LVD is calcuated as $\frac{J.Utility}{J.RemExec}$.
\end{description}


\subsection{Data Structure for Resource Model}

The following member variables can be used to define the resource model for each phase represented as a DAG:

\begin{description}
	\item[\texttt{J.AggUtil}] \hfill \\
		The aggregate utility of a phase $J$. This is used for the calculation of
		the Global Value Density.

	\item[\texttt{J.AggExec}] \hfill \\
		The aggregate remaining execution time of a phase $J$. This is used for the
		calculation of the Global Value Density.

	\item[\texttt{J.GlobalValDen}] \hfill \\
		The Global Value Density (GVD) of a phase $J$. GVD is calculated as $\frac{\Sigma J.AggUtil}{\Sigma J.AggExec}$
 		for phase $J$ and all its dependents.
 		
	\item[\texttt{J.PIPDeadLn}] \hfill \\
		 The PIP\nomenclature{PIP}{Priority Inheritance Protocol} deadline of a zero in-degree phase $J$
		 is equal to the deadline of the phase in $J$'s dependency chain that has the earliest deadline.
		 The PIP deadline is only calculated for zero in-degree phases. If a zero in-degree phase $J$ does
		 not have any dependents, the PIP deadline is equal to \texttt{J.Deadline}.
 		
	\item[\texttt{J.InDegree}] \hfill \\
		The total number of links that come into a phase $J$ in the DAG. The in-degree of a phase 
		$J$ can not be more than one.

	\item[\texttt{J.OutDegree}] \hfill \\
		The total number of links that go out of a phase in the DAG. A phase $J$ can have a value
		of zero or more for the out-degree.

	\item[\texttt{J.ResourceReq}] \hfill \\
		The reference to the resource that has been requested by a phase $J$.

	\item[\texttt{J.NeighborList}] \hfill \\
		The reference to the first dependent child node of a phase $J$ in the DAG. 

	\item[\texttt{J.NextNeighbor}] \hfill \\
		The reference to the next dependent child node of a phase $J$ in the DAG.

	\item[\texttt{J.Parent}] \hfill \\
		The reference to the phase which owns the resource that the phase $J$ has requested.
		Figure~\ref{fig:dagdatast} illustrates how the DAG can be represented using 
		\texttt{J.NeighborList}, \texttt{J.NextNeighbor} and \texttt{J.Parent}.
\end{description}

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1.2]{./eps/dag-data-structure}  
  \caption{Data structure representation of the DAG}
  \label{fig:dagdatast}
\end{figure}


\subsection{Auxiliary Functions}\label{sec:aux-funcs}

In this section, we define the auxiliary functions that are used by the NG-GUA and G-GUA scheduling algorithms. These methods perform small functions which are implementation independent.

\begin{description}
	\item[\texttt{InsertList($J, \sigma$)}] \hfill \\
		Insert the phase $J$ into the list $\sigma$. 

	\item[\texttt{RemoveList($U, \sigma$)}] \hfill \\
		Remove phase $J$ from the list $\sigma$.
	
	\item[\texttt{ComputeGVD($\sigma_{in}$)}] \hfill \\	
		For the given list of zero in-degree phases in $\sigma_{in}$,
		compute the global value density, which is calculated as $\frac{\Sigma J.AggUtil}{\Sigma J.AggExec}$
		for phase $J$ and its dependents represented as child nodes of the zero in-degree phase in the graph.
		
	\item[ \texttt{SortByGVD($\sigma_{in}$)}] \hfill \\
		Sort the list $\sigma_{in}$ by the decreasing
 		global value density and return the new ordered list in $\sigma_{out}$.
 		
 	\item[\texttt{SortByDeadLn($\sigma_{in}$)}] \hfill \\
		Sort the list $\sigma_{in}$ by the decreasing
 		deadline (EDF order) and return the new ordered list in $\sigma_{out}$.

	\item[\texttt{HeadOf($\sigma$)}] \hfill \\
		Return the phase $J$ which is at the head of the list $\sigma$.
		
	\item[\texttt{InsDeadLnPos($J, \sigma$)}] \hfill \\
		Insert phase $J$ in the list $\sigma$ at its deadline position.

	\item[\texttt{FindZIDPhases($\sigma_t$)}] \hfill \\
		Return the list $\sigma_z$ of zero in-degree phases in $\sigma_t$.

	\item[\texttt{FindPIPDeadLn($\sigma_z$)}] \hfill \\
		For each zero in-degree phase $J \in \sigma_z$, assign the PIP deadline for $J$
 		equal to the deadline of the phase which has the earliest deadline amongst the dependents of $J$. If $J$ does 
 		not have any dependents, the PIP deadline of $J$ equals its deadline.

	\item[\texttt{RemoveLeastLVD($\sigma$)}] \hfill \\
		Remove the phase with the least LVD from $\sigma$.
		
	\item[\texttt{RemoveLeastGVD($\sigma$)}] \hfill \\
		Remove the phase with the least GVD from $\sigma$.		
		
	\item[\texttt{IsPresent($J, \sigma$)}] \hfill \\
		Return \texttt{true} if the phase $J$ is present in list $\sigma$, else return \texttt{false}.
			
	\item[\texttt{IsFeasible($\sigma$)}] \hfill \\
		 Return \texttt{true} if the given schedule in list $\sigma$ is feasible. For $\sigma$ to be
		 feasible, the predicted completion time of each phase in $\sigma$ must never exceed its deadline.
	
	\item[\texttt{IsEmpty($\sigma$)}] \hfill \\
		Return \texttt{true} if the list $\sigma$ is empty, else return \texttt{false}.

	\item[\texttt{InsertEdge($J, DepJ$)}] \hfill \\
		Insert an edge between $DepJ$ and $J$.

	\item[\texttt{RemoveEdge($J$)}]	\hfill \\
		Remove all in-degree and out-degree edges of $J$.
	
	\item[\texttt{Owner($R$)}]	\hfill \\
		Return the phase $J$ that holds resource $R$. If there is no phase that holds resource $R$, return \texttt{NULL}.
	
	\item[\texttt{ResRequested($J$)}]	\hfill \\
		Return the resource $R$ requested by phase $J$.

	\item[\texttt{FindProcessor()}] \hfill \\
		Return the processor $p$ which has the least sum of total phase execution cost.
		
	\item[\texttt{FindProcessor(cpu\_mask)}] \hfill \\
		This version of \texttt{FindProcessor()} takes an argument called \texttt{cpu\_mask}, which is a list of 
		processors that have been checked before and need to be masked (avoided) while selecting the processor
		with the least sum of total phase execution cost. If all the processors on the system are included in 
		the mask, the function returns \texttt{NULL}.

	\item[\texttt{AddCpuToMask(p, cpu\_mask)}] \hfill \\
		Add processor $p$ to the \texttt{cpu\_mask}. The \texttt{cpu\_mask} can be a bit array where each bit 
		corresponds to each online processor, in which case, set the bit corresponding to $p$.

	\item[\texttt{FindLeastLVD($J$)}] \hfill \\
		For the given phase $J$'s dependency chain, find the phase with the least Local Value Density (LVD).

	\item[\texttt{UpdateCpuEC($p, J, b$)}] \hfill \\
		If $b$ is true, add the execution cost of $J$ to the total phase
 		execution count for processor $p$, else subtract the execution cost of
 		$J$ from the total phase execution count.
 		
	\item[\texttt{AbortPhase($J$)}] \hfill \\
		Send an aborting signal to the phase $J$.
 				
	\item[\texttt{IsPhaseAborted($J$)}] \hfill \\
		Return \texttt{true} if the phase $J$ has been marked to be aborted.
		
\end{description}

\subsection{Creation of DAG with Detection/Resolution of Deadlocks}

In this section, we give the details of the auxiliary function used to create the DAG along with detection and resolution of deadlocks. In Algorithm~\ref{alg:DAGandDead}, we describe the pseudo-code for \texttt{CreateDAGwithDRD($\sigma_T$)} that uses the list of phases, $\sigma_T$, which are ready and eligible to be scheduled. For the rest of the thesis, we will refer to the phase that has requested a resource as a \textit{child} while the phase that owns the resource being requested as a \textit{parent}.

In lines 8-26, the algorithm iterates over the list, $\sigma_T$, and for each phase, $J$, checks if a \textit{parent} node exists. If there exists a \textit{parent} (line 13), the algorithm adds an edge from the \textit{parent} to the \textit{child} node (line 15). The main objective of the algorithm is to construct the complete dependency chain for a given phase. In lines 20-21, the algorithm sets the current \textit{parent} node as the new \textit{child} and checks if it has requested a resource. The steps are repeated for all the phases in the dependency chain of $J$.

\restylealgo{boxed}\linesnumbered
\renewcommand{\baselinestretch}{1.0}
\restylealgo{ruled} \incmargin{1em}
\SetAlFnt{\footnotesize}
\begin{algorithm2e}[!t]
\begin{footnotesize}
    \Setnlsty{textbf}{}{:}
    \caption{Creation of DAG with detection/resolution of deadlocks}
    \label{alg:DAGandDead}
    \textbf{Procedure: CreateDAGwithDRD ($\sigma_T$)} \\
    ~\\
    \textbf{Input: $\sigma_T$}  ~~~~~~~~~~~~~// List of released phases \\
    \textbf{Vars: $S, J, V, next$} ~~// Phase pointers \\
    \textbf{Vars: $\sigma_J$} ~~~~~~~~~~~~~~// Phase $J$'s list of dependents\\
    ~\\
   	$next = \phi$\;
    \For {each phase $J$ in $\sigma_T$} {
     	$\sigma_{J} = \phi$ \;
     	$J.LocalValDen = \frac{J.utility}{J.RemExec}$\;
     	~\\
      	\texttt{InsertList($J, \sigma_J$)}\;
     	$next =$ \texttt{Owner(\texttt{ResRequested($J$)})}\;
 		\While {$next \neq \phi$} {
			\texttt{InsertEdge($J, next$)} \;
			\If {\texttt{IsPhaseAborted($next$)}} {
				\texttt{break}\;
			}
			\If { \texttt{IsPresent($next,\sigma_J)$} = \texttt{false} } {
				\texttt{InsertList($next, \sigma_J$)}\;
				$J = next$\;
		     	$next =$ \texttt{Owner(\texttt{ResRequested($next$)})}\;
			}
			\Else {
				$V =$ \texttt{FindLeastLVD($next$)}\;
				\texttt{AbortPhase($V$)}\;
				\texttt{RemoveEdge($V$)}\;
				\texttt{break}\;
			}
		}
%		\If {$J.InDegree$ == $0$} {
%			$J.GlobalPUD = \frac{J.AggUtil}{J.AggExec}$\;
%		}
	}
\end{footnotesize}
\end{algorithm2e}

To perform deadlock detection, for each phase, $J$, whose dependency chain is being analyzed, we create a temporary list $\sigma_J$ (line 9) and insert all the dependencies for phase $J$ into $\sigma_J$ (line 12). Before adding an edge between a \textit{child} and a \textit{parent}, we first check if the \textit{parent} node is already present in $\sigma_J$ (line 18). The existence of the phase in $\sigma_J$ means that the phase has already been added to the graph. This implies that we have detected a circular dependency and hence a deadlock. To resolve the deadlock, we need to find the least local value density phase in $\sigma_J$, abort the phase and remove it from the graph (lines 23-26).

Once the DAG has been created, we need to compute the Global Value Density for the \textit{zero in-degree} phases. Finding the \textit{zero in-degree} phases involves iterating over the list of released phases $\sigma_T$ and creating another list $\sigma_z$ of phases which have \texttt{J.InDegree} equal to zero. For each of the \textit{zero in-degree} phases, the global value density (or GVD) needs to be computed. The GVD of a \textit{zero in-degree} phase $J$ is given as $\frac{J.AggUtility}{J.AggRemExec}$ where \texttt{J.AggUtility} is the aggregate utility of $J$ and all its child nodes in the graph and \texttt{J.AggRemExec} is the aggregate remaining execution time of $J$ and all its child nodes in the graph. The \texttt{ComputeGVD($\sigma$)} auxiliary function describes one of the methods of computing GVD. As an optimization, the computation of the aggregate utility and the aggregate remaining execution time for \textit{zero in-degree} phases can be coupled with the \texttt{InsertEdge()} or the \texttt{FindZIDPhases()} auxiliary functions.

%\section{GUA Class of Algorithms}

\section{Non-greedy Global Utility Accrual (NG-GUA)}\label{sec:nggua}

Algorithm~\ref{alg:NGGUA} describes the pseudo-code for the Non-Greedy Global Utility Accrual (NG-GUA) algorithm. The pseudo-code uses auxiliary functions that have been discussed earlier in Section~\ref{sec:aux-funcs}.

In line 5, for a given list of phases $\sigma_T$ that are ready to be scheduled, we compute the global precedence graph (DAG) and detect/resolve deadlocks. This is done by calling \texttt{ComputeDAGwithDRD()}. 

In line 6, after the DAG has been created, we find the list $\sigma_{z}$ of all the zero in-degree phases. A zero in-degree phase does not depend on any other phase in the system.

In line 7, for all the phases in $\sigma_{z}$, we compute the global value density. This is done using the \texttt{ComputeGVD()} function.

In order to ensure that NG-GUA defaults to G-EDF-PIP behavior (in the presence of dependencies), we compute the PIP deadlines for each of the zero in-degree phases. The PIP deadline of a zero in-degree phase $J_z$ can be found as the earliest deadline of a phase $J_i$ which is dependent on the given zero in-degree phase $J_z$ in the graph. In the absence of dependencies, the PIP deadline of $J_z$ is the same as the given deadline of $J_z$.

In lines 8-9, we compute the PIP deadline for all the zero in-degree phases and sort them based on those deadlines. The sorted list is stored in $\sigma_d$. The key idea here is to sort the zero in-degree phases by the deadlines of the phases which have the earliest deadline but are currently blocked on a resource that is being held by the zero in-degree phases.

In lines 11-13, we use the method defined in Section~\ref{findproc} to find the processor with the least sum of total remaining execution cost and start assigning the phases to the individual processor lists $\sigma_p$.

\restylealgo{boxed}\linesnumbered
\renewcommand{\baselinestretch}{1.0}
\restylealgo{ruled} %\incmargin{1em}
\SetAlFnt{\footnotesize}
\begin{algorithm2e}[!t]	
    \Setnlsty{textbf}{}{:}
    \caption{NG-GUA: Non-greedy Global Utility Accrual}
    \label{alg:NGGUA}
     \textbf{Input: $\sigma_T$} ~~~~~~~~// List of released phases\\
     \textbf{Vars: $\sigma_1 \cdots \sigma_M$} ~// Per processor ready queues for M  processors \\
     \textbf{Vars: $\sigma_{z}$} ~~~~~~~~~~// Zero in-degree phase list \\
	~\\
	\texttt{ComputeDAGwithDRD($\sigma_T$)}\;		
	$\sigma_{z}\leftarrow$ \texttt{FindZIDPhases($\sigma_T$)}\;
	\texttt{ComputeGVD($\sigma_z$)}\;	
	$\sigma_{z}\leftarrow$ \texttt{FindPIPDeadLn($\sigma_{z}$)}\;
	$\sigma_{d}\leftarrow$ \texttt{SortByPIPDeadLn($\sigma_{z}$)}\;
	~\\
	\For {each phase $J$ in $\sigma_{d}$} {
		$p\leftarrow$ \texttt{FindProcessor()}\;
		\texttt{InsertList(J, $\sigma_p$)}\;
	}
	
	\For {each processor \texttt{p}}{
		\While{\texttt{IsFeasible($\sigma_p$) = false}} {
			\texttt{RemoveLeastGVD($\sigma_{p}$)}\;
		}
	}
	\For {each \texttt{$p$} processor's schedule $\sigma_p$ in $M$} {
		$Job_p\leftarrow$ \texttt{HeadOf($\sigma_p$)} \;
	}

    \textbf{return} \{ $Job_1, \cdots , Job_M $ \}\;
\end{algorithm2e}    

In lines 14-16, we check the individual processors lists $\sigma_p$ for schedule feasibility. This is done using the \texttt{IsFeasible()} function which returns true, if the given schedule in list $\sigma_p$ is feasible. For a schedule to be \textit{feasible}, the predicted completion time for each phase in $\sigma_p$ must never exceed its deadline. 

If the schedule is not feasible, the system is in an overload with $U > M$. During overloads, we need to attempt to maximize the total utility of the system by allowing phases that have a higher value density to be executed. In line 16, we find the phase in $\sigma_p$ that has the least GVD, remove it from $\sigma_p$ and check the schedule again for feasibility. Lines 15-16 are executed until we find a feasible schedule.

The reason for using GVD while removing the phase during an infeasible schedule is to ensure that we respect the dependency chain. It is possible that the zero in-degree phase having the highest GVD, has the least LVD. In such a case, using LVD to remove a phase would not be a correct representation of the dependency chain and hence would degrade the overall performance during overloads.

In lines 17-19, the head of the final feasible schedule $\sigma_p$ for each processor $p$ is dispatched on that processor.

Algorithm~\ref{alg:NGGUA} is referred to as non-greedy because it defaults to a deadline order rather than a value density order along with support for priority inheritance protocol, thus following a G-EDF-PIP \nomenclature{G-EDF}{Global Earliest Deadline First scheduling algorithm} behavior during underloads and maximizing total accrued utility during overloads.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./eps/nggua-example}
  \caption{Sample schedule for NG-GUA}
  \label{fig:nggua-sample-sched}
\end{figure}

Figure~\ref{fig:nggua-sample-sched} shows a sample schedule for NG-GUA. $T_1$, $T_2$, $T_3$, $T_4$, $T_5$, and $T_6$ represent real-time phases in the global queue. We assume that the subscripts on each phase represent the relative deadlines. So, $T_1$ has an earlier deadline than $T_6$. The precedence graph shows the relationship of phases with each other. $T_4$, $T_5$, and $T_6$ represent the zero in-degree phases. We find the PIP deadlines for these phases. For zero in-degree phase $T_4$, $T_1$ has the earliest deadline. Similarly, for phase $T_6$, $T_3$ has the earliest deadline. We sort the phases based on the PIP deadlines. Assuming the system is underloaded, the assignment of all the phases to the processors would result in a feasible schedule. $T_4$ and $T_6$ are the most eligible phases and they are assigned to processors CPU$_0$ and CPU$_1$, respectively. 

Let us assume that $T_4$ finishes before $T_6$. As a result, a scheduling event is generated on CPU$_1$, which sends an \texttt{IPI} to all the processors in the system and enters the scheduler\footnote{The details on the \texttt{IPI} are discussed in detail in Chapter~\ref{chap:chronos}}. CPU$_0$ receives the \texttt{IPI} and enters the scheduler. However, as CPU$_1$ is already in the scheduler, CPU$_0$ blocks. CPU$_1$ prepares the global schedule. $T_6$, $T_5$, and $T_2$ represent the zero in-degree phases (as $T_4$ has finished execution). We find the PIP deadlines and sort the phases based on those deadlines. $T_2$ and $T_6$ are now the most eligible phases and they are assigned to the processors. As $T_6$ was running on CPU$_0$ before the scheduling event was generated, we assign $T_6$ to CPU$_0$ to preserve cache-coherence. The assigned tasks are mapped to the processors. The processors pull the assigned tasks and start executing them.

During overloads, after the phases have been sorted based on PIP deadlines, they are assigned to the processors with the least sum of remaining phase execution cost. For each of the processors, schedule feasibility is checked. During overloads, some (or all) of the processors might show infeasible schedules. At that time, for each of processors which have an infeasible schedule, we remove the phase with the least GVD (and continue doing this till the schedule is feasible). If there are no dependencies, all the phases are treated as zero in-degree and the PIP deadlines for all those phases are equivalent to the actual deadlines of the phases. Hence, the same mechanism follows.

\section{Greedy Global Utility Accrual (G-GUA)}

Algorithm~\ref{alg:GGUA} describes the pseudo-code for the Greedy Global Utility Accrual (G-GUA) scheduling algorithm. The pseudo-code uses auxiliary functions that have been discussed earlier in Section~\ref{sec:aux-funcs}.

Lines 8-10 are similar to the NG-GUA algorithm, described in Section~\ref{sec:nggua}. We compute the DAG, find the list of zero in-degree phases and compute the GVD for all the zero in-degree phases in $\sigma_z$. As G-GUA does not default to G-EDF-PIP, we do not need to find the PIP deadlines. 

\restylealgo{boxed}\linesnumbered
\renewcommand{\baselinestretch}{1.0}
\restylealgo{ruled} %\incmargin{2em}
 %\SetAlFnt{\scriptsize}
\begin{algorithm2e}[!t]	
    \Setnlsty{textbf}{}{:}
    \caption{G-GUA: Greedy Global Utility Accrual}
    \label{alg:GGUA}
     \textbf{Input: $T$} ~~~~~~~~// List of released phases\\
     \textbf{Vars: $\sigma_1 \cdots \sigma_M$} // Per processor ready queues for M  processors\\
     \textbf{Vars: $\sigma_{z}$} ~~~~~~~~~// Zero in-degree phase list\\
     \textbf{Vars: \texttt{cpu\_mask}} ~~~~~// Mask of all processors on which feasibility check of a given phase failed \\
     \textbf{Vars: \texttt{not\_fes}} ~// Flag to check if the feasibility check failed for a given phase\\
~~~~~~~~~~~~~~~~~~~~~~// on last processor it was assigned to \\
     
	~\\
	\texttt{ComputeDAGwithDRD($T$)}\;		
	$\sigma_{z}\leftarrow$ \texttt{FindZIDPhases($T$)}\;
	\texttt{ComputeGVD($\sigma_z$)}\;
	$\sigma_{d}\leftarrow$ \texttt{SortByGVD($\sigma_{z}$)}\;
	~\\
	\For {each phase $J$ in $\sigma_{d}$} {
		\texttt{cpu\_mask = 0}\;
		\texttt{not\_fes = true}\;
		~\\
		\While{\texttt{not\_fes == true}} {
			$p\leftarrow$ \texttt{FindProcessor()}\;
			\If{\texttt{p == NULL}} {
				\texttt{break}\;
			}
			\texttt{InsDeadLnPos(J, $\sigma_p$)}\;
			\texttt{UpdateCpuEC(p, J, true)}\;
			~\\	
			\If{\texttt{IsFeasible($\sigma_p$) == false}} {
				\texttt{RemoveList(J, $\sigma_p$)}\;
				\texttt{UpdateCpuEC(p, J, false)}\;
				\texttt{not\_fes = true}\;
				\texttt{AddCpuToMask(p, cpu\_mask)\;}
			} \Else{
				\texttt{not\_fes = false}\;
			}
		}
	}
	\For {each \texttt{$p$} processor's schedule $\sigma_p$ in $M$} {
		$Job_p\leftarrow$ \texttt{HeadOf($\sigma_p$)} \;
	}
    \textbf{return} \{ $Job_1, \cdots , Job_m $ \}\;
\end{algorithm2e}

G-GUA differs from NG-GUA in two ways ---
\begin{inparaenum}[(i)]
	\item the zero in-degree phases are sorted by GVD instead of the PIP deadlines (line 11), and
	\item instead of assigning phases to all the processors and then running the feasibility check, G-GUA follows a much more greedier approach to accrue total utility.
\end{inparaenum}

For all individual GVD sorted zero in-degree phases in $\sigma_d$ (lines 13-30), G-GUA assigns the phase to a processor which has the least sum of total remaining execution cost and checks for feasibility of schedule on that processor. If the schedule is feasible, only then does G-GUA move to the next phase in $\sigma_d$. However, if the schedule is not feasible after the phase was added to the first processor it was assigned to, G-GUA removes it from that processor and tries the same phase on all the other available processors. This is done to ensure that a phase is tried on all processors before being rejected. This behavior is greedy as it tries to ensure that a high GVD phase is not rejected and thus provides greater accrued utility.

G-GUA uses two variables called \texttt{cpu\_mask} and \texttt{not\_fes}. These are used to make sure that a phase which was not feasible on the first processor it was assigned to, is tried on all the available processors. For every phase, the \texttt{cpu\_mask} is initially set to zero (line 14). If a phase is not feasible on a processor, it is removed from that processor (line 25) and the processor is added to the \texttt{cpu\_mask} (line 28). The \texttt{cpu\_mask} is used by \texttt{FindProcessor()} to find the processors that have the least sum of total remaining execution cost avoiding (masking) the processors which have been already checked (line 18).

In lines 24-30, G-GUA checks if the current phase added to a processor makes a feasible schedule. If it does, G-GUA moves to the next phase by setting the \texttt{not\_fes} flag to \texttt{false}. If the schedule is not feasible, lines 25-28 remove the phase from the processor and add the processor to the \texttt{cpu\_mask}. The \texttt{not\_fes} continues to be true, due to which the loop 17-30 is activated again. The \texttt{FindProcessor} is called with the \texttt{cpu\_mask} which either returns a new processor (line 18), or returns \texttt{NULL} if the phase has been tried on all the processors (lines 19-20). In that case, the phase is rejected and the next phase is considered in line 13.

In lines 31-32, the head of the final feasible schedule ($\sigma_p$) for each processor $p$ is taken and dispatched to the individual processor for scheduling.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./eps/ggua-example}
  \caption{Sample schedule for G-GUA}
  \label{fig:ggua-sample-sched}
\end{figure}

Figure~\ref{fig:ggua-sample-sched} shows a sample schedule for 	G-GUA. $T_1$, $T_2$, $T_3$, $T_4$, $T_5$, $T_6$, $T_7$, $T_8$, and $T_9$ represent real-time phases in the global queue. We assume that the subscripts on each phase represent the relative deadlines while as the superscript represents the LVD. The precedence graph shows the relationship of phases with each other. $T_4$, $T_7$, and $T_6$ represent the zero in-degree phases. For all of the zero in-degree phases we compute the GVD. We find that $T_4$ has the highest GVD of $22$ and $T_7$ has the least GVD of $10$. We sort the phases based on the decreasing values of GVD. At this point, we take each phase, assign it to a processor with the least sum of total phase remaining execution cost and check for schedule feasibility. During underloads, the schedules would be feasible on all processors. As a result, $T_4$ and $T_6$ are found to be the most eligible phases and assigned to processors CPU$_0$ and CPU$_1$, respectively. 

Let us assume that $T_4$ finishes before $T_6$. As a result, a scheduling event is generated on CPU$_1$, which sends an \texttt{IPI} to all the processors in the system and enters the scheduler\footnote{The details on the \texttt{IPI} are discussed in detail in Chapter~\ref{chap:chronos}}. CPU$_0$ receives the \texttt{IPI} and enters the scheduler. However, as CPU$_1$ is already in the scheduler, CPU$_0$ blocks. CPU$_1$ prepares the global schedule. As phase $T_4$ has finished execution, $T_8$, $T_2$, $T_6$, and $T_7$ represent the new zero in-degree phases. We compute the GVD for the phases. $T_8$ has the least GVD. We follow the same mechanism as discussed earlier and find that $T_6$ and $T_7$ are the most eligible phases. 

During overloads, while the phases are being assigned to processors with the least sum of phase remaining execution cost, addition of a phase might result in an infeasible schedule on a given processor. At that point, the phase is tried on the other processors before being rejected. This ensures greedy behavior. If there are no dependencies, all the phases are treated as zero in-degree and the GVD for all those phases is equivalent to their LVD. Hence, the same mechanism follows.


\section{Algorithm Properties}\label{sec:algorithm-properties}

From now onwards in this thesis, ``underload" is defined to exist when thread utilization demand satisfies one of the G-EDF schedulability conditions in~\cite{GEDF}, while ``overload" is defined to exist when thread utilization demand exceeds the global EDF schedulability conditions in~\cite{GEDF}\footnote{As EDF is optimal on a uniprocessor, underload is defined when task utilization $U \le 1$ and an overload when $U > 1$. However, for multiprocessors, G-EDF is not optimal and can meet deadlines for $U \approx m/2$, for $m$ processors. Hence, underload is defined equivalent to the utilization bounds of G-EDF.}.


We define some of the properties of G-GUA and NG-GUA.

%% Changed to 1 as the overall number of pages have increased
\renewcommand{\baselinestretch}{1.0}
\begin{thm} 
NG-GUA, with no dependencies, defaults to global-EDF scheduling during underloads. 
\end{thm}

\begin{proof}
Global-EDF sorts the ready phases in deadline order and then dispatches the head of this queue to available processors. NG-GUA mimics this behavior by first sorting the ready phases in deadline order and then dispatching them to processors that have the least sum of remaining phase execution cost. The processor $p$ with the least sum of remaining execution cost would be the first processor to be available in the system. Therefore, the top of the ready queue would be assigned to processor $p$ in global-EDF and we assign the phase to $p$ in NG-GUA as well. Hence, NG-GUA mimics the scheduling semantics of global-EDF during underloads.
\end{proof}

\begin{thm} 
NG-GUA, with dependencies, defaults to global-EDF with PIP scheduling during underloads. 
\end{thm}

\begin{proof}
Global-EDF with PIP sorts the ready phases in deadline order. It then checks if the phase $J_a$ at the head of the queue is blocked by another phase $J_b$. Instead of executing $J_a$, G-EDF does a priority inheritance by allowing $J_b$ to be executed instead. NG-GUA mimics this behavior by finding out the PIP deadline of all the zero in-degree phases (line 8) and sorting the zero in-degree phases based on the PIP deadlines (line 9). This ensures that the phase $J_b$ which is now at the head of the queue after the sort, is a zero in-degree phase which is blocking another phase $J_a$, that has the earliest deadline in the system. Hence NG-GUA mimics the scheduling semantics of global-EDF with PIP scheduling during underloads, in the presence of dependencies.
\end{proof}

\begin{thm}
The gMUA scheduling algorithm is a special case of NG-GUA scheduling algorithms
\end{thm}

\begin{proof}
At every scheduling event, gMUA~\cite{cho-thesis06} takes the phases that have been released in the system and are ready for execution and sorts them based on their deadlines. gMUA assigns the deadline sorted phases to processor queues. Each phase is assigned to a processor which has the least sum to total remaining execution cost. Once the phases have been assigned, gMUA runs the schedule feasibility check on individual processors queues. If the phases assigned to a processor result in an infeasible schedule, gMUA removes the phase with the least value density, until the schedule is feasible. Finally, the head of each of the processor queue is considered as the final schedule.

This behavior is similar to NG-GUA without dependencies. In the absence of any dependency relationship between phases, line 5 of NG-GUA treats all the phases as \textit{zero in-degree} nodes in the graph. Thus in line 6, all the phases that were initially in the ready queue are eligible for the final schedule. As there are no dependencies, the PIP deadline of each phase is equal to its own deadline. Hence, in line 9, the \texttt{SortByPIPDeadLn()} function sorts the phases based on their actual deadlines. In lines 11-13, NG-GUA uses \texttt{FindProcessor()} function to assign phases to processors that have the least sum to total remaining execution cost. In lines 14-16 NG-GUA, runs a schedule feasibility check on individual processor queues and in case of an infeasible schedule, removes the phases with the least GVD. However, as there are no dependencies, the GVD of a phase is equal to its LVD.

Thus, gMUA is a special case of NG-GUA.

\end{proof}

\begin{thm}During overloads, NG-GUA attempts to accrue as much utility as possible by attempting to maximize the utility accrued at each scheduling step.
\end{thm}

\begin{proof}NG-GUA, in lines 8-9, first constructs a global deadline ordered schedule. Once the entire schedule is constructed, the algorithm goes over the system to check for feasibility (lines 14-16), and removes the least GVD phase if the schedule is not feasible.
Thus, during overloads, when phases first begin to miss deadlines, NG-GUA begins to shed phases in inverse proportion to their utility density. This method allows the algorithm to gracefully degrade in the presence of overloads by eliminating the threads that would be least beneficial to the system in terms of accrued utility. The algorithm therefore attempts to minimize the loss in accrued utility, or, equivalently, to maximize the remaining accrued utility, at each scheduling step.
\end{proof}

\begin{thm}Both algorithms ensure mutual exclusion.
\end{thm}

\begin{proof}In order to ensure mutual exclusion, it should not be possible for two or more phases that have critical sections, which access the same variables, to execute at the same time. Phases that access the same variables in their critical sections protect these sections using the same locks. The algorithms detect this dependency while constructing the DAG. Since both algorithms only execute \textit{zero in-degree} phases, they ensure that a phase and its dependents do not execute at the same time, thus ensuring that mutual exclusion is guaranteed.
\end{proof}

\begin{thm}For both algorithms considered, an application always makes progress, i.e., executes application specific code, if there is work offered and the application is not deadlocked.
\end{thm}

\begin{proof}Both algorithms are based on the concept of \textit{zero in-degree} phases. Given a DAG, line 5 in NG-GUA and line 8 in G-GUA, select a set of phases that do not depend on any other phases. These phases are then sorted according to deadline or GVD order and dispatched to the appropriate processor. If the application still has work offered, and it is not deadlocked, there will always be at least one \textit{zero in-degree} node in the DAG. The phase represented by this node is dispatched to one of the processors in the system, thus making progress in accordance with application logic.
\end{proof}

\begin{prop}\label{prop:Length}In~\cite{ArtOfMpP}, Theorem 16.3.1 shows that when the schedule length is used as a criteria, a greedy scheduling algorithm that schedules the \textit{zero in-degree} nodes in a DAG produces a schedule that is within a factor of two from being optimal. Further, for a multi-threaded application with $P$ threads, work $T_1$ and critical path length $T_\infty$, the length of the schedule is bounded by

$$\frac{T_1}{P_A}+\frac{T_\infty(P-1)}{P_A}$$

where $P_A$ is defined as the average number of threads executed at each scheduling interval.
\end{prop}

\begin{thm} Property~\ref{prop:Length} applies for both NG-GUA and G-GUA.
\end{thm}

\begin{proof} The ``greedy" nature discussed in~\cite{ArtOfMpP} refers to the ability of an algorithm to schedule as many ready phases as possible. More specifically, an algorithm is considered ``greedy" in the context of~\cite{ArtOfMpP} if the number of threads scheduled at each step is the minimum of the number of available processors and the number of threads that are ready to be executed.

Both G-GUA and NG-GUA have this property, since they both select the \textit{zero in-degree} nodes in a DAG and schedule the threads they represent on the available processors -- note that these are the phases that are ready for immediate execution. The main difference between them and the general greedy algorithm discussed in~\cite{ArtOfMpP} is that they sort the \textit{zero in-degree} phases according to some real-time criteria (whether deadlines or GVD) and select the first $n$ phases from this ordered list for immediate dispatching (where $n$ is the number of available processors). Therefore, NG-GUA and G-GUA are in the class of algorithms discussed in~\cite{ArtOfMpP} and the theorem follows.
\end{proof}

\begin{thm} For $m$ processors and $n$ phases, the asymptotic cost of NG-GUA is $O(mn \log n)$.
\end{thm}

\begin{proof} In line 5 we take the list of released phases and compute the dependency relationship for each phase, which has a cost of $O(n)$. In line 6 we find the zero in-degree phases from the DAG, which can be completed in $O(1)$. For computing the GVD, the worst case cost is $O(n)$, assuming all the $n$ phases in the ready queue are zero in-degree. This is possible if there are no dependencies. 

In line 8 we find the PIP deadline for all the zero in-degree phases, which has a cost of $O(n)$. In line 9 we sort the phases by the PIP deadline. The worst-case execution cost of the most efficient sorting methods is $O(n \log n)$. Lines 11-16 have a cost of $O(n)$, so with $m$ processors, the overall cost is $O(mn)$.

Hence, the total asymptotic cost of NG-GUA is: $O(n) + O(1) + O(n) + O(n) + O(n \log n) + O(mn) = O(mn\log n)$.
\end{proof}

\begin{thm} For $m$ processors and $n$ phases, the asymptotic cost of G-GUA is $O(mn \log n)$.
\end{thm}

\begin{proof} In line 8 we take the list of released phases and compute the dependency relationship for each phase, which has a cost of $O(n)$. In line 9 we find the zero in-degree phases from the DAG, which can be completed in $O(1)$. For computing the GVD, the worst case cost is $O(n)$, assuming all the $n$ phases in the ready queue are zero in-degree. This is possible if there are no dependencies. 

In line 11 we sort the phases by the GVD. The worst-case execution cost of the most efficient sorting methods is $O(n \log n)$. Lines 17-30 can be repeated for $m$ processors, with a cost of $O(m)$. Lines 13-30 are computed for $n$ phases, with a total cost of $O(mn)$.

Hence, the total worst-case asymptotic cost of G-GUA is: $O(n) + O(1) + O(n) + O(n \log n) + O(mn) = O(mn \log n)$.
\end{proof}

\chapter{ChronOS Real-Time Linux}\label{chap:chronos}
\markright{Piyush Garyali \hfill Chapter~\ref{chap:chronos}.
ChronOS Real-Time Linux
\hfill}

\section{Background}\label{sec:chronos-background}

In order to implement and evaluate our scheduling algorithms we developed ChronOS~\cite{chronos_url}, which provides real-time extensions to the Linux kernel. ChronOS is derived from the $2.6.31.12$ version of the Linux kernel and uses Ingo Molnar's \texttt{PREEMPT\_RT} real-time patch~\cite{preempt_rt} which enables complete preemption in Linux and improves interrupt latencies. The patch is released under GPLv2~\cite{gpl}\nomenclature{GPLv2}{GNU Public License version 2.0}\nomenclature{GNU}{Gnu is Not Unix} and makes it suitable for academic research. ChronOS provides a set of APIs and a scheduler plugin infrastructure that can be used to implement and evaluate various single-processor and multiprocessor scheduling algorithms. 

The two main objectives of implementing ChronOS are ---
\begin{inparaenum}[(i)]
\item to provide a first-class abstraction of Distributed Threads; and
\item to provide a real-time scheduling framework.
\end{inparaenum}
The Distributable Thread (also know as DT\nomenclature{DT}{Distributed Thread}) programming abstraction first appeared in the Alpha OS~\cite{alpha} and subsequently in Mach 3.0~\cite{mach30}, MK7.3~\cite{mk98}, Real-Time CORBA 2.0~\cite{omg0901}, and the emerging Distributed Real-Time Specification for Java (DRTSJ)~\cite{jw02}. A Distributable Thread is a single thread of execution with a globally unique identity that transparently extends and retracts through local and remote objects. A real-time Distributed Thread carries along its timing constraints (deadline, TUF, worst-case execution cost) as it makes remote invocations and travels through multiple nodes. On each node, the local instance of the Distributed Thread is scheduled with these timing constraints\footnote{The DTs will not be discussed in detail as the topic is outside the scope of this thesis.}. 

The rest of the chapter outlines the architecture of ChronOS and the modifications that we have made to the Linux kernel to achieve the real-time behavior. We primarily focus on the scheduling infrastructure concentrating on the design and implementation of multiprocessor scheduling algorithms.

\section{Architecture}\label{sec:chronos-architecture}

\begin{figure} [!t]
  \centering
  \includegraphics[scale=1.2]{./eps/Chronos-arch}
  \caption{ChronOS architecture}
  \label{fig:chronos-arch}
\end{figure}

Figure~\ref{fig:chronos-arch} shows the overall architecture of ChronOS real-time Linux. ChronOS is derived from the Linux kernel and we rely on all the kernel primitives for basic operating system objectives such as process and memory management, timers, interrupts, drivers, file-system, and networking. As shown in Figure~\ref{fig:chronos-arch}, Linux provides the basic foundation of ChronOS. 

We extend the Linux \texttt{O(1)} scheduler and implement the ChronOS real-time scheduler where various single-processor scheduling algorithms, such as \texttt{EDF}, \texttt{DASA}, \texttt{LBESA}, \texttt{HVDF}\nomenclature{HVDF}{Highest Value Density First scheduling algorithm}, \texttt{RMA} and multiprocessor algorithms, such as \texttt{G-EDF}, \texttt{G-NP-EDF}\nomenclature{G-NP-EDF}{Global Non-Preemptive Earliest Deadline First scheduling algorithm}, \texttt{G-FIFO}\nomenclature{G-FIFO}{Global First In First Out scheduling algorithm}, \texttt{NG-GUA}, \texttt{G-GUA} have been implemented. At the same level, the Distributed Thread manager is implemented which provides first-class kernel level abstraction for Distributed Threads. Various Distributed Thread related algorithms, such as \texttt{TPR}\nomenclature{TPR}{Thread Polling with bounded Recovery}, \texttt{D-TPR}\nomenclature{D-TPR}{Distributed Thread Polling with bounded Recovery}, \texttt{HUA}\nomenclature{HUA}{Handler-assured Utility Accrual scheduling algorithm}, \texttt{CUA}\nomenclature{CUA}{Consensus-based Utility Accrual scheduling algorithm}, \texttt{ACUA}\nomenclature{ACUA}{Asynchronous Consensus-based Utility Accrual scheduling algorithm}~\cite{sherif10} have been implemented.

The Distributed Thread manager and the scheduling framework extensions are exposed to the user-space through system calls. ChronOS adds a set of new system calls to Linux that are used to enable the DT and scheduling extensions. At the user-space level, a middleware API\nomenclature{API}{Application Programming Interface} abstraction layer is provided that maps the system calls to the user-space. ChronOS provides the application developer the freedom to write real-time applications directly using the middleware APIs without using any of the Distributed Thread services or to create a distributed applications using DTs without using any of the real-time functionality.

\subsection{\texttt{PREEMPT\_RT} Real-Time Patch}

The stock Linux kernel provides soft real-time capabilities, such as the POSIX\nomenclature{POSIX}{Portable Operating System Interface [for Unix]} primitives and the ability to set priorities. The kernel provides two real-time scheduling policies - \texttt{SCHED\_FIFO} and \texttt{SCHED\_RR} and a ``nice" based scheduling policy called \texttt{SCHED\_NORMAL}. In \texttt{SCHED\_FIFO} %Add reference here
processes are given CPU for as long as they want, until the arrival of a higher priority task. This is primarily a POSIX-specified feature. \texttt{SCHED\_RR}, on the other hand, schedules processes of the same priority in a round robin fashion. This is done while favoring higher priority tasks. The ChronOS real-time scheduler uses the \texttt{SCHED\_FIFO} as the underlying base scheduling algorithm and builds up the scheduling framework on that. The scheduler is described in detail in the subsequent sections. 

In order to bring in real-time semantics to the kernel, it is required to have a preemptable kernel. The stock Linux kernel does not allow ``complete" kernel preemption. However, in order to implement scheduling algorithms such as \texttt{G-EDF} or \texttt{G-GUA}, it is necessary to be able to preempt the kernel. To achieve this we use the \texttt{PREEMPT\_RT} patch. The patch enables complete kernel preemption along with a generic clock event layer with high resolution support, thus providing hard real-time capabilities in the Linux kernel.

With the \texttt{PREEMPT\_RT} patch most parts of the kernel, except for a few small regions (which are inherently unpreemptible, such as the task scheduler), can be preempted. In order to achieve complete preemption the following changes were made to the Linux kernel.

\begin{enumerate}
% PG confirm with MD about waitqueues
\item All the in-kernel locking primitives, such as spinlocks have been re-implemented using rtmutexes. As a result, all critical sections that are protected with \texttt{spinlock\_t} or \texttt{rwlock\_t} are preemptable. However, the patch still enables the creation of non-preemptable sections in the kernel, if that is required.
\item Priority Inheritance has been implemented for all in-kernel spinlocks and semaphores.
\item All interrupt handlers in the kernel have been converted into kernel threads. All the soft interrupt handlers are treated in the kernel thread context (i.e., they have a \texttt{struct task\_struct} associated) such that they can be treated as threads with higher priority and scheduled accordingly. However, it is still possible to register an IRQ\nomenclature{IRQ}{Interrupt Request} in the kernel context.
\item The existing Linux timer APIs have been converted into separate infrastructure for high resolution kernel timers, including those for timeouts, which enable the use of user-space POSIX timers with high resolution.
\end{enumerate}

Overall, the \texttt{PREEMPT\_RT} patch improves the interrupt latencies and provides a completely preemptable kernel.


\section{ChronOS Real-Time Scheduler}\label{sec:chronos-rt-sched}

Since version 2.6, the Linux kernel features an \texttt{0(1)} scheduler~\cite{love-book}. Every scheduling algorithm provided in the default Linux kernel (\texttt{SCHED\_NORMAL}, \texttt{SCHED\_FIFO}, \texttt{SCHED\_RR}) completes in constant-time, regardless of the number of processes in the system that are in the running state. The \texttt{O(1)} scheduler also implements SMP\nomenclature{SMP}{Symmetrical Multiprocessor System} scalability where each processor has its own locking and individual run-queues. The scheduler also implements SMP affinity which enables processes to be assigned to a specific CPU.
%% PG - add rlove book refernence

\subsection{Priority Bit-map and Run-queues}

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1.2]{./eps/linux-prio-rq}
  \caption{Linux real-time priority bitmap and run-queues}
  \label{fig:linux-prio}
\end{figure}

In order to achieve an \texttt{O(1)} scheduler, Linux implements a bit-map for each priority. There are $140$ priority levels. $[0 \hdots 99]$ are referred to as real-time priorities while $[100 \hdots 140]$ are called ``nice" priorities. In the kernel-space, ``$0$" is the highest real-time priority while ``$99$" is the least (which is opposite to that in the user-space). Figure~\ref{fig:linux-prio} shows the section of the priority bit-map which maps to the real-time priorities inside the kernel. As shown in the figure, each priority has a run-queue of active tasks on the system. The default scheduling algorithm used in Linux is \texttt{SCHED\_NORMAL} in which the amount of CPU that each process consumes, and the latency that it will get, is determined by the ``nice" values, which are calculated by the kernel over time in an interactive fashion looking at the consumption patterns of processes in the system. The kernel starts from the highest priority bit in the bit-map, looks for tasks at that priority level and executes them before going to the next level. The key idea is to give preference to higher priority tasks.

The ChronOS scheduler extends the Linux \texttt{O(1)} scheduler. However, to differentiate between normal tasks and real-time tasks created by the ChronOS middle-ware, we add additional parameters to the \texttt{struct task\_struct} to specify the real-time properties of a task, such as the task's worst case execution cost, deadline, period and TUFs. The ChronOS real-time tasks are tagged so that they stand out in the run-queue. In order to facilitate working on the real-time tasks, for every priority level in the bit-map we create another queue called the ChronOS real-time run-queue (\texttt{CRT-RQ})\nomenclature{CRT-RQ}{ChronOS Real-Time Run-Queue} which holds a reference to the real-time tasks in the Linux run-queue. This is illustrated in Fig~\ref{fig:chronos-prio}. As shown in the figure, the tasks in the \texttt{CRT-RQ} are references of the real-time tasks in the default Linux run-queue.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./eps/chronos-prio-rq}
  \caption{ChronOS real-time priority run-queue for a given real-time priority}
  \label{fig:chronos-prio}
\end{figure}

The working of the \texttt{CRT-RQ} is similar to the Linux run-queue. When a task enters the system, it is added to the run-queue corresponding to its priority. If the new task is tagged as a ChronOS real-time task, a reference to the task is also added in the \texttt{CRT-RQ} for the specific priority level. When the ChronOS scheduler is enabled, it looks at the \texttt{CRT-RQ}, orders the run-queue based on the scheduling algorithm selected, and picks up the first task at the head of \texttt{CRT-RQ}. When the ChronOS scheduler picks up a real-time task, it is removed from both the default Linux run-queue and the \texttt{CRT-RQ}.

\subsection{Scheduling Real-Time Tasks}

A real-time application in ChronOS needs to specify the start and end of a real-time segment. A real-time segment is defined as a portion of the thread, which needs to be executed with real-time time constraints. This can be done using the following system calls provided by ChronOS. The detailed description of the system calls is provided in Appendix~\ref{appendix-cos-sys}.

\begin{description}
	\item[\texttt{begin\_rt\_seg()}] \hfill \\
		This system call is used to indicate the start of a real-time scheduling segment
		and also to provide the real-time timing constraints for a given task.
	
	\item[\texttt{end\_rt\_seg()}] \hfill \\
		This system call is used to indicate the end of a real-time scheduling segment.
	
	\item[\texttt{set\_scheduler()}] \hfill \\
		This system call is used to enable a scheduling algorithm.
\end{description}

The real-time scheduler is invoked at various scheduling events. A scheduling event is defined as a trigger that forces the system into a scheduling cycle resulting in a call to the scheduler where a new task is picked based on the scheduling algorithms. In ChronOS we define the following scheduling events.

\begin{description}
	\item[\textbf{A task entering the system}] \hfill \\
		When a new task is added to the system, the scheduler is invoked. At that time, the scheduling
		algorithm looks at the \texttt{CRT-RQ}, orders the queue and picks the task at the head of the queue
		for scheduling.
		
	\item[\textbf{A task leaving the system}] \hfill \\
		When a task finishes its scheduling segment and leaves the system, the scheduler is invoked. The
		scheduling algorithm looks at the \texttt{CRT-RQ}, orders the queues and picks the task at the head of
		the queue for scheduling.
		
	\item[\textbf{A resource being requested}] \hfill \\
		When a task requests for a resource, ChronOS tags the task as \texttt{RESOURCE\_REQUESTED} and invokes
		the scheduler. This is done to let the scheduling algorithm look at the dependency chain
		based on the resource requested and pick the task that is best suited for execution. 
	
	\item[\textbf{A resource being released}] \hfill \\
		When a task releases a resource, ChronOS invokes the scheduler in order to allow a new task to be picked
		which might be blocking on the resource that was just released. The decision to choose the new task
		is done by the scheduling algorithm.
\end{description}

Using the \texttt{set\_scheduler()} system call, a scheduling algorithm can be selected. All scheduling algorithms are created as Linux modules in ChronOS which provides the flexibility to add or remove any scheduling algorithm from a running kernel without restarting the system. The scheduling algorithms are implemented in a modular fashion using a set of functions that we refer to as the ``scheduler plugin". Once a scheduler is selected for a set of processors, all the real-time tasks that are added to the system on those processors are scheduled using the the selected scheduling algorithm. The scheduler plugin is described in detail in the subsequent section.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./eps/single-core-sched}
  \caption{ChronOS scheduling approach on a single-processor system}
  \label{fig:single-core-sched}
\end{figure}

Figure~\ref{fig:single-core-sched} illustrates an example of scheduling on a single processor machine. As the scheduling algorithms are written as modules in ChronOS, they can be loaded into a running kernel using \texttt{modprobe}, which registers the scheduling algorithms, adding them to the list of available schedulers in ChronOS. In Figure~\ref{fig:single-core-sched}, the call to \texttt{set\_scheduler()} system call is made from the real-time application to select \texttt{EDF} as the real-time scheduler. ChronOS checks if \texttt{EDF} kernel module is available. If the scheduler is found, ChronOS loads the plugin and makes it the default ChronOS local scheduler for running real-time tasks. All the real-time tasks are now added to the \texttt{CRT-RQ}. At every scheduling event, the ChronOS scheduler invokes \texttt{sched\_edf()}, which sorts the \texttt{CRT-RQ} in Earliest Deadline First order. The head of the queue now represents the earliest deadline task which is pulled by the ChronOS local scheduler and given to the Linux \texttt{O(1)} scheduler for execution.

\section{Multiprocessor Scheduling}

Scheduling on multiprocessors can be mainly categorized into two forms -- partitioned scheduling and global scheduling. ChronOS supports both these variants. In this section we describe the details of both these architectures, and discuss their design and implementation.

\subsection{Partitioned Scheduling}
% PG - address MD's comment here.
Partitioned scheduling can be described as uniprocessor scheduling done on multiprocessors. The key idea of partitioned scheduling is to divide the task-set using an off-line heuristic, as partitioning a set of tasks on $M$ processors has been shown to be equivalent to the bin-packing problem~\cite{binpacking} and hence NP-hard in the strong sense. Baruah \textit{et al.} present a polynomial-time algorithm to partition collection of sporadic tasks onto a $M$ processors in~\cite{baruah_part05}.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./eps/partitioned-sched}
  \caption{ChronOS partitioned scheduling approach on a multiprocessor system}
  \label{fig:partitioned-sched}
\end{figure}

%Most of the heuristics choose the criteria of schedule feasibility while assigning tasks to the processor bins.

Figure~\ref{fig:partitioned-sched} illustrates the partitioned scheduling approach used in ChronOS. The task-set is partitioned off-line using polynomial-time heuristics such as first-fit, worst-fit, and best-fit. In Figure~\ref{fig:partitioned-sched} we simulate a two processor system. The heuristic divides the task-set into two processor bins as shown. Once all the tasks have been divided, the real-time application sets the affinity of each of the tasks to the processors they have been assigned to. This is done to ensure that the tasks are added to the run-queue of their respective assigned processors. The reference to these real-time tasks is also added to the \texttt{CRT-RQ} of their respective assigned processors. As partitioned scheduling is an extension of uniprocessor scheduling, we set the partitioned scheduler as the local ChronOS scheduler on all processors using the \texttt{set\_scheduler()} system call. Each processor runs its scheduling algorithm independently. At every scheduling event, the processor enters its local scheduler, looks at the local run-queue, and using the selected scheduling algorithm (in the figure shown as \texttt{P-EDF}), picks the next task to be executed. As the tasks have already been partitioned, we disable Linux's load balancing mechanism to prevent tasks from being migrated between processors. Some of the algorithms that have been implemented using this approach in ChronOS are \texttt{P-EDF} and \texttt{P-DASA}\nomenclature{P-DASA}{Parallel Dependent Activity Scheduling Algorithm}.

\subsection{Global Scheduling}

Most of the multiprocessor scheduling algorithms, such as \texttt{G-EDF}, \texttt{G-NP-EDF}, \texttt{Pfair}, \texttt{gMUA}, \texttt{G-GUA}, and \texttt{NG-GUA} are based on global scheduling. The main idea behind global scheduling is that the tasks are assigned to a global queue instead of individual local queues. The scheduling algorithm on each processor looks at the global queue and either makes a scheduling decision for itself and every other processor in the system (such as \texttt{G-EDF}, \texttt{Pfair}, \texttt{G-GUA}, \texttt{NG-GUA}) or picks a task only for itself (such as \texttt{G-NP-EDF}).

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=0.9]{./eps/global-sched}
  \caption{ChronOS global scheduling approach on a multiprocessor system}
  \label{fig:global-sched}
\end{figure}

Figure~\ref{fig:global-sched} illustrates the global scheduling approach used in ChronOS. In order to implement global scheduling inside ChronOS, we create another level of scheduling abstraction. At the top we have the ``global scheduler" which looks at the ``global task queue". The global scheduler maps to a ``local scheduler" on individual processors which extends from the Linux \texttt{O(1)} scheduler. The global scheduler (invoked on a processor) can either pick a task for itself or decide for all the processors on the system (depending on the scheduling policy used). If the global scheduler needs to choose tasks for all available processors on the system (such as \texttt{G-EDF, G-GUA or NG-GUA}), it picks the top $M$ tasks. These tasks are given to the task mapping algorithm which maps these tasks on $M$ underlying processors. The tasks assigned by the task mapping algorithm are pushed into the ``globally assigned task" block from where the ``task puller" on each CPU picks up the task and moves it to the head of its local queue. The default local scheduling algorithm for global scheduling algorithms on each processor is \texttt{SCHED\_FIFO}, which picks the head of the \texttt{CRT-RQ} queue and gives the task to the Linux \texttt{O(1)} scheduler for execution.

In global scheduling under ChronOS, tasks can be created and assigned to any processor. The tasks continue to reside on the Linux run-queue of the processor they were created on. The global queue has a reference to all the real-time tasks from all the processors.

As mentioned earlier, there are two ways in which global scheduling can be achieved. In the first approach, the global scheduler picks a task for itself from the global queue, such as \texttt{G-NP-EDF}. We refer to this as the ``Application Concurrent Scheduling Model". In the second approach, the global scheduler picks the tasks for all $M$ available processors, such as \texttt{Pfair, NG-GUA, G-GUA}. We refer to this as the ``Stop-the-World Scheduling Model" (STW)\nomenclature{STW}{Stop-the-World architecture model}. These architecture models are described in detail in Sections~\ref{sec:concurrent} and~\ref{sec:stw}, respectively.

\subsubsection{Application Concurrent Scheduling Model}\label{sec:concurrent}

Figure~\ref{fig:arch-conc} illustrates the application concurrent scheduling model for global scheduling in ChronOS. For the sake of explanation of the model, we will assume that the scheduling algorithm picks the first task that is at the head of the queue. At the beginning, task $T_6$ is running on processor $P_0$ and task $T_8$ is running on processor $P_1$. As shown in the figure, $T_8$ finishes before  $T_6$. However, $T_6$ is not preempted on $P_0$. It continues to run. After $T_8$ finishes, it generates a scheduling event. $P_1$ enters the global scheduler, picks the first task $T_3$ from the global queue and assigns it to the ``globally assigned task" block. The local scheduler on $P_1$ pulls the task $T_3$ and starts executing it. While $P_1$ is pulling the task, $T_6$ finishes on processor $P_0$ and generates a scheduling event. It pulls $T_1$ from the global queue and starts executing it without preempting $T_3$ on $P_1$. The same procedure is repeated for other scheduling events.

\begin{figure} [htb]
  \centering
  \includegraphics[scale=1.5]{./eps/arch-conc}
  \caption{``Application Concurrent" architecture model for global scheduling algorithms}
  \label{fig:arch-conc}
\end{figure}

There might be a scenario when both processors finish their tasks at the same time. As shown in the Figure~\ref{fig:arch-conc}, when $T_2$ finishes on $P_0$, $T_4$ finishes on $P_1$ around the same time. As the global task queue is common between all the processors, while $P_0$ enters the global scheduler, $P_1$ blocks. The moment $P_0$ is done with the schedule, $P_1$ unblocks and enters the scheduler. The \texttt{G-NP-EDF} and \texttt{G-FIFO} are some of the algorithms that use such an architecture model. The downside of the application concurrent model is that it can only be used by scheduling algorithms that do not have resource dependencies (such as locks). This is because when resources are used, we need to look into more complicated scheduling mechanisms to figure out the best task to be executed that respects resource boundaries.

\subsubsection{Stop-the-World Scheduling Model}\label{sec:stw}

\begin{figure} [htb]
  \centering
  \includegraphics[scale=1.5]{./eps/arch-stw}
  \caption{``Stop-the-World" architecture model for global scheduling algorithms}
  \label{fig:arch-stw}
\end{figure}

In order to allow global scheduling algorithms with resource management, ChronOS implements the Stop-the-World scheduling model. Figure~\ref{fig:arch-stw} provides an illustration of the model. For the sake of explanation of the model we will assume that the scheduling algorithm selects the tasks for execution that are not dependent on any other tasks in the system. Let us assume that the global task queue has the tasks eligible for the final schedule. The figure shows the dependency relation of the tasks in the global task queue with each other. Task $T_4$ needs a resource which is owned by task $T_2$ which in turn requires a resource that is being held by task $T_1$. In a similar fashion, task $T_6$ needs a resource which is owned by task $T_5$. Task $T_3$, on the other hand, does not have any dependents. Let us assume that the scheduling algorithm considers the tasks that have the maximum dependents as the most eligible tasks for the final schedule.

Given all the assumptions, Figure~\ref{fig:arch-stw} shows that tasks $T_1$ and $T_5$ are the current executing tasks on processors $P_0$ and $P_1$, respectively. Task $T_5$ finishes first and generates a scheduling event. In the Stop-the-World model, once a scheduling event is generated, the schedule needs to be created for all the processors. This requires a processor to be able to force a scheduling event on all other processors. When task $T_5$ triggers the scheduling event, processor $P_1$ sends an ``Inter-processor Interrupt" (\texttt{IPI})\nomenclature{IPI}{Inter-Processor Interrupt} to all the processors on the system. In Linux, at the end of every interrupt handler, the call to the scheduler is made. This is done in order to pick up the next task for execution after the interrupt has been handled. The \texttt{IPI} used by the scheduler is a dummy interrupt. The interrupt handler for the scheduling \texttt{IPI} does not do anything but call the \texttt{schedule()} function at the end, which forces the processor to enter the scheduler.

In the example shown in Figure~\ref{fig:arch-stw}, processor $P_1$ sends an \texttt{IPI} to all the available processors on the system. After sending the \texttt{IPI}, processor $P_1$ enters its global scheduler and looks at the available tasks in the run-queue to create the schedule. In the meanwhile, processor $P_0$ receives the \texttt{IPI} and is forced into the scheduler. However, as processor $P_1$ is already in the global scheduler, processor $P_0$ blocks. The global scheduler on processor $P_1$ picks two eligible tasks (assuming a two-processor system) and hands these tasks to the mapping algorithm. The task mapper pushes these tasks into the ``globally assigned task" block of each processor. Once the mapper is done, each individual processor pulls its globally assigned task to the head of their local queue. The local scheduler (which is \texttt{SCHED\_FIFO}) on each processor, picks the task at the head of the local queue and gives it to the Linux \texttt{O(1)} scheduler for execution.

Even if the tasks do not have a dependency relationship, the Stop-the-World model works the same way as mentioned above. The scheduling algorithm looks at the global queue and picks the $M$ tasks that are eligible for final schedule and hands them to the mapping algorithm, which is explained in detail in the next section. 

\subsection{Mapping Tasks to Processors}

Figure~\ref{fig:task-mapping} illustrates the default mapping algorithm used in ChronOS for global scheduling. The job of the mapping algorithm is to take the $M$ most eligible tasks that have been selected by the scheduling algorithm and map them to the $M$ available processors on the system. The key idea is to be able to reduce task migrations, thus preserving cache coherence. The algorithm shown in Figure~\ref{fig:task-mapping} is selected as the default for all global scheduling algorithms. However, the scheduler plugin infrastructure of ChronOS allows users to override the default mapping algorithm and provide their own implementation. 

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1.3]{./eps/task-mapping}
  \caption{Task mapping for global scheduling algorithms in ChronOS}
  \label{fig:task-mapping}
\end{figure}

In ChronOS the mapping is done using a three-pass algorithm. In Figure~\ref{fig:task-mapping} tasks $RT_5$, $RT_8$, $RT_1$ and $RT_4$ represent four real-time tasks that have been selected by the global scheduling algorithm at the end of a scheduling event. In order to understand the mapping algorithm we give a snapshot of the per-processor run-queues. Each run-queue shows the tasks that belong to the individual processors. We also highlight the current running task on each of the processors before the scheduling event was triggered, which led to the creation of the new global schedule. Task $RT_2$ is the current running task on processor $P_0$, task $RT_5$ on $P_1$, task $RT_9$ on $P_3$ while task $RT_7$ is the current running task on $P_3$.

In the first pass, the algorithm goes over the final schedule and maps tasks to processors that are the current running tasks on that processor. This provides cache coherence. As shown in Figure~\ref{fig:task-mapping}, task $RT_5$ is the current running task on $P_1$. Hence, it is mapped to processor $P_1$. In the second pass, the algorithm goes over the final schedule and maps tasks to processors that belong to that processor's run-queue. This prevents tasks from being unnecessarily migrated. As shown in the figure, task $RT_4$ belongs to processor $P_0$ and hence it is mapped to processor $P_0$. In the similar fashion, task $RT_8$ belongs to processor $P_2$ and it gets mapped to the same processor. In the last pass, the mapping algorithm randomly assigns the leftover tasks to the remaining processor(s). As shown in the figure, task $RT_1$ is assigned to processor $P_3$. However, task $RT_1$ actually belongs to processor $P_0$. As a result, this step results in the migration of the mapped tasks.

The key idea of the mapping algorithm is to reduce task migrations. However, if the final schedule consists of $M$ tasks that all belong to the same processor, the worst case migration cost is $M-1$ task migrations. In such a case, cache-aware scheduling algorithms can be used to create a cache conscious schedule, and thus handle their own mapping, overriding the default mapping algorithm. Guan \textit{et al.}~\cite{guan-cache-aware} and Calandrino \textit{et al.}~\cite{calandrino-cache} present different cache-aware real-time scheduling algorithms. Stenström provides a survey of various cache coherence schemes on multiprocessors in~\cite{CCMultiproc}.

\section{Implementing Scheduling Algorithms in ChronOS}

\subsection{Single-processor Scheduling}

\begin{lstlisting}[caption=ChronOS Single-processor Scheduler Plugin, label=prog:local]
struct rt_sched_local
{
  char *name;
  int number;
  struct rt_info* (*schedule) (struct list_head *head, int flags);
};
\end{lstlisting}

The code listing~\ref{prog:local} shows the ChronOS plugin for single-processor scheduling. When implementing a new scheduler, the user needs to specify a name and a unique number for the scheduler. The \texttt{*schedule} function pointer provides the function syntax for the main scheduling function where the algorithmic logic for the scheduler needs to be implemented. The function provides the \texttt{head} pointer to the \texttt{CRT-RQ} which has the list of all the real-time tasks released and eligible for schedule.

\subsection{Multiprocessor Scheduling}

\begin{lstlisting}[caption=ChronOS Multiprocessor Scheduler Plugin, label=prog:global]
struct rt_sched_global
{
  char *name;
  int number;
  struct rt_info* (*schedule) (struct list_head *head, int flags, int cpus);
  struct rt_info* (*preschedule) (struct list_head *head, int flags);
  struct rt_sched_arch *arch;
};
\end{lstlisting}

The code listing~\ref{prog:global} shows the ChronOS plugin for multiprocessor scheduling. When implementing a new scheduler, the user needs to specify a name and a unique number for the scheduler. The \texttt{*schedule} function pointer provides the function syntax for the main scheduling function where the algorithmic logic for the scheduler needs to be implemented. The function provides the \texttt{head} pointer to the global real-time queue which has the list of all the real-time tasks released across the system and eligible for schedule. The function also provides the number of processors on which multiprocessor scheduling has been enabled. The \texttt{*preschedule} function pointer provides the function syntax for pre-scheduling. This is an architecture feature provided by ChronOS for scheduling algorithms that need to do some preprocessing before entering the main scheduler (such as checking if the tasks have missed their deadlines and in such a case aborting them). 

Appendix~\ref{appendix-sample} shows a sample implementation of the kernel modules for single-processor and multi-processor scheduling.

\chapter{Experimental Results}\label{chap:exp_res}
\markright{Piyush Garyali \hfill Chapter~\ref{chap:exp_res}.
Experimental Results
\hfill}

In order to evaluate the performance of NG-GUA and G-GUA, we implement the scheduling algorithms in ChronOS along with their state-of-the-art competitors, such as G-EDF, G-NP-EDF, G-FIFO, gMUA, P-EDF, P-DASA. We conduct experiments and evaluate the results on a two-core, four-core and an eight-core platform. In this section, we discuss the experimental setup in detail and present the result and the analysis. 

\section{Experimental Setup}\label{sec:evaluation-experimental-setup}
 
\subsection{Platform Specifications}
 
We conduct our experiments on three different platforms, each with an increasing number of processing units. Table~\ref{tab:platforms} gives the detailed specifications of each platform used.

The first platform is based on the Intel dual-core P8600 processor with a CPU frequency of 2.4 GHz and a 3 MB L2 cache. The second platform is a quad-core machine based on AMD Phenom 9650 processor with a CPU frequency of 2.3 GHz and a 2 MB L3 cache. Finally, we use an eight-core platform using two Intel Xeon E5520 quad-core processors, each having a CPU frequency of 2.8 GHz and an 8 MB L3 cache. These platforms provide a rich environment with different processing speeds and cache footprints, thus allowing us to verify the viability of multiprocessor scheduling algorithms under different platforms.

\begin{table} [htbp]
\caption{Specifications of the various platforms used for experimental evaluation}
\label{tab:platforms}
\begin{center}
\begin{tabular}{| >{\centering}p{3cm} | >{\centering}p{3cm} | >{\centering}p{3.5cm} | c |}
\hline
\textbf{Specifications} & \textbf{Two-core} & \textbf{Four-core} & \textbf{Eight-core} \\ \hline 
\textit{Processor Type} & Intel Core 2 Duo P8600 & AMD quad-core Phenom 9650 & Intel quad-core Xeon E5520\\
\hline
\textit{No of processors} & $1$ & $1$ & $2$ \\
\hline
\textit{Total physical cores} & $2$ & $4$ & $8$ \\
\hline
\textit{Total logical cores} & $2$ & $4$ & $16$ \\
\hline
\textit{CPU Frequency} & 2.4 GHz & 2.3 GHz & 2.8 GHz  \\
\hline
\textit{Memory} & 2 GB & 2 GB & 8 GB  \\
\hline
\textit{Cache} & 3 MB L2 & 128 KB L1, 512 KB L2, 2 MB L3 & 4x256 KB L2, 8 MB L3\\
\hline
\end{tabular}
\end{center}
\end{table}

\subsection{Test Application}

The NG-GUA and G-GUA algorithms are flexible about the task arrival pattern. We do not assume any specific model (such as periodic, aperiodic, sporadic). Tasks can arrive at any time in the system and create scheduling events. However, in order to evaluate our algorithms against the other state-of-the-art algorithms, which specify a particular task arrival pattern, we default to a periodic model. This helps to easily quantify the schedulability criteria of the algorithms and allows us to compare the performance with other scheduling algorithms. 

We create a real-time test application using ChronOS APIs. The test application periodically fires real-time tasks with specified time-constraints. For each task, we use a \texttt{burn\_cpu(wcet)} function, which takes the \texttt{wcet} (worst case execution time) as an input and burns processor cycles for that amount of time. This allows us to simulate a real-time task which executes until its worst case execution time. In our test application we use the ``thread-is-a-phase" model, where each periodic instance of the task is represented as a separate thread. Using the task's period as the relative deadline, we fire threads periodically.

\subsection{Performance Parameters}

We measure the Deadline Satisfaction Ratio (DSR)\nomenclature{DSR}{Deadline Satisfaction Ratio} 
and the Accrued Utility Ratio(AUR)\nomenclature{AUR}{Accrued Utility Ratio}. 
Equations~\ref{eq:dsr} and~\ref{eq:aur} give the formulas for finding the DSR and AUR.

\begin{equation}
	\label{eq:dsr}
	DSR_U = \frac{Tasks~that~met~their~deadlines~at~utilization~load~U}{Total~tasks~in~the~system}
\end{equation}

\begin{equation}
	\label{eq:aur}
	AUR_U = \frac{Accrued~utility~of~tasks~that~met~their~deadlines~at~utilization~load~U}{Total~possible~accrued~utility}
\end{equation}

At a given utilization load $U$, the DSR is measured as the ratio of the tasks that met their deadlines to the total number of tasks in the system. In the similar fashion, the AUR is measured as the total accrued utility of the tasks that met their deadlines to the total possible accrued utility in the system.

We create various task-sets using a random task-set generator. We discuss the task-sets used in detail in the individual sections. All the results are presented as an average of ten runs. We also present the standard deviation variation for each data point. Our focus is primarily on two types of experiments ---
\begin{inparaenum}[(1)]
 \item we evaluate the performance of NG-GUA and G-GUA without dependencies (locks), whose results are discussed in Section~\ref{sec:wo-dep}; and
 \item we evaluate the performance of the algorithms in the presence of dependencies (locks), whose results are discussed in Section~\ref{sec:w-dep}.
\end{inparaenum}

\section{Results Without Dependencies}\label{sec:wo-dep}

In this section we evaluate the performance of NG-GUA and G-GUA without dependencies (such as locks). We compare the results with other state-of-the-art global scheduling algorithms, such as G-EDF, G-NP-EDF and G-FIFO. As mentioned earlier, gMUA is a special case of NG-GUA without dependencies. As a result, for the non-dependent case, the implementation of gMUA in ChronOS is similar to NG-GUA (as we skip the function to create the DAG and treat all the tasks as zero in-degree). Hence, for the non-dependent case, the results for gMUA are similar to NG-GUA. In order to avoid confusion, we do not show the gMUA results on the plots but it is considered in the final summary. We also compare the results of our algorithms with partitioned algorithms, such as P-EDF and P-DASA. 

\subsection{Comparison with Global Scheduling Algorithms}

In order to compare with global scheduling algorithms, we consider downward ``step" TUF based model. We create random task-sets with three types of TUF assignment policies. Figure~\ref{fig:tuf-experiments} illustrates the model used. 

\begin{figure} [htb]
  \centering
  \includegraphics[scale=1]{./eps/tuf-experiments}
  \caption{Task-sets created with variable TUFs (a) Increasing Utility (IU); (b) Decreasing Utility (DU); (c) Random Utility(RU)}
  \label{fig:tuf-experiments}
\end{figure}

In the Increasing Utility (IU)\nomenclature{IU}{Increasing Utility model} model, the utilities assigned to the tasks are proportional to their deadlines. The task with the earliest deadline has the least utility while the task with a later deadline has the highest utility. In the Decreasing Utility (DU)\nomenclature{DU}{Decreasing Utility model} model, the utilities assigned to a task are inversely proportional to their deadlines. The task with the earliest deadline has the highest utility while the task with a later deadline has the least utility. In the Random Utility (RU)\nomenclature{RU}{Random Utility model} model, the tasks are assigned random utilities with no two tasks having the same utility. These models are used to accomplish two main goals ---
\begin{inparaenum}[(i)]
\item to ascertain whether, irrespective of the TUF ordering, our algorithms perform comparable to the competitors; and 
\item to ensure that we do not create a bias based on the TUF assignment against the deadline-based algorithms.
\end{inparaenum}
Hence, the model covers the worst-case to the best-case scenarios.

On the two-core and four-core platform, we consider three types of task-sets with an increasing number of tasks.
\begin{enumerate}
	\item The first task-set uses 5 tasks with deadlines/periods in the range of $[500ms-5000ms]$, 
		with the utilization load for each task in the range of $[0.1-0.4]$.
	\item The second task-set uses 12 tasks with deadlines/periods in the range of $[300ms-20000ms]$, 
		with the utilization load for each task in the range of $[0.01-0.4]$.
	\item The third task-set uses 27 tasks with deadlines/periods in the range of $[50ms-7500ms]$,
		with the utilization load for each task in the range of $[0.01-0.3]$. 
\end{enumerate}

On the eight-core platform, we consider two types of task-sets.
\begin{enumerate}
	\item The first task-set uses 27 tasks with deadlines/periods in the range of $[50ms-7500ms]$, with the utilization load for each task in the range of $[0.01-0.3]$.
	\item The second task-set uses 50 tasks with deadlines/periods in the range of $[50ms-10000ms]$, with the utilization load of each task in the range of $[0.001-0.3]$.
\end{enumerate}

Using these task-sets we cover a total deadline/period range from $[50ms-20s]$. The tasks are assigned utilities in the range of $[50-10000]$. In the IU model, the task with the least period is assigned a utility of $50$ and the task with the largest period is assigned a utility of $10000$, and vice-versa for the DU model. In the RU model, tasks are assigned utilities randomly. As we are using a utility based model, we ensure that we cover a wide deadline/period range in order to avoid any bias against deadline-based scheduling algorithms.

\begin{table} [htbp]
\caption{Legend used in experimental results, based on TUF-based models, for comparison with other global scheduling algorithms}
\label{tab:tuf-legend}
\begin{center}
\begin{tabular}{c c}
\hline
Symbol & Description \\ \hline
\texttt{IU} & Increasing Utility model \\
\texttt{DU} & Decreasing Utility model  \\
\texttt{RU} & Random Utility model  \\
\texttt{NL} & No locks used \\
\texttt{xT} & Task-set used with $x$ number of tasks \\
\texttt{xC} & Experiment using $x$ number of processors\\
\hline
\end{tabular}
\end{center}
\end{table}

Table~\ref{tab:tuf-legend} shows the legend used in the experimental results. All the experimental result are shown as an average of ten runs. 
The plots cover a utilization load in the range of $[0-8]$ for the two-core platform, $[0-10]$ for the four-core platform and $[0-12]$ for the eight-core platform. Each data point shows the standard deviation as a vertical error bar. 

In the subsequent sections we discuss the results on two-core, four-core and eight-core platforms.

\subsubsection{Two-core Platform Results}

On the two-core platform, we ran the experiments using the 5-task (5T), 12-task (12T) and 27-task (27T) task-sets using IU, RU and DU models. Figures~\ref{fig:2C-5T-NL-DU-AUR} and~\ref{fig:2C-5T-NL-DU-DSR}, respectively, show the AUR and DSR results for the 5T using the DU model. We observe that both NG-GUA and G-GUA outperform other deadline-based algorithms.

We observe the following:
\begin{asparaenum}[(1)]
	\item G-EDF meets all deadlines for $U \le 1 (m/2)$, as $m = 2$ for a two-core platform, which is the lower utilization bound for G-EDF. However, during overloads, G-EDF suffers from the domino effect and starts losing deadlines.
	\item NG-GUA and G-GUA provide a better deadline satisfaction ratio during overloads. The main benefit of the algorithms can be observed in Figure~\ref{fig:2C-5T-NL-DU-AUR} for the accrued utility. At 250\% utilization load we see an improvement of around 300\% in AUR over that of G-EDF, G-NP-EDF and G-FIFO. At 400\% utilization load, there is an improvement of around 350\% in AUR.
	\item Finally, the task-set uses a DU model, which gives the highest utility to the tasks that have the earliest periods/deadlines. We observe that NG-GUA and G-GUA perform better in the DU model as compared to the deadline-based algorithms.
\end{asparaenum}
When compared with each other, we see that G-GUA performs better than NG-GUA, which is an expected behavior. G-GUA is optimized to accrue more utility during overloads. On the other hand, NG-GUA performs well during underloads by trying to meet as many deadlines as possible, thus following a G-EDF behavior, but it accrues higher utility during overloads. 

We observe some variability in the results (shown as the standard deviation). This amount of variance is acceptable given the fact that it is impossible to have the same operating system environment for every test execution. Due to the \texttt{PREEMPT\_RT} patch, ChronOS is able to withstand jitter from non real-time based applications. However, there are critical operating system primitives that have higher priority in ChronOS which are required for the proper functioning of the operating system. These include (to name a few), the timer interrupts and the I/O interrupts, which are used while our test application fires periodic threads using timers and also when it writes the test results to a file after every data-point is captured. This also explains why most of the variability is observed during the overload scenarios and not during underloads. This is because during underloads, the total task utilization is still below the processing capacity of the system\footnote{Unless stated otherwise, we will assume that the variability shown by the standard deviation in all plots is due to the same reason, as mentioned above.}.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-5T-NL-DU-AUR}
  \caption{AUR vs. CPU utilization (5T, 2C, NL, DU)}
  \label{fig:2C-5T-NL-DU-AUR}
\end{figure}


\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-5T-NL-DU-DSR}
  \caption{DSR vs. CPU utilization (5T, 2C, NL, DU)}
  \label{fig:2C-5T-NL-DU-DSR}
\end{figure}
 
The results for the AUR and DSR using the IU model for 5T are shown in Figures~\ref{fig:2C-5T-NL-IU-AUR} and~\ref{fig:2C-5T-NL-IU-DSR}, respectively. We observe a performance improvement over the deadline-based scheduling algorithms. Both NG-GUA and G-GUA consistently accrue high utility during overloads with 700\% improvement in AUR for 250\% utilization load. NG-GUA performs better at meeting deadlines during underloads and its performance is comparable to G-EDF. G-NP-EDF falls behind G-EDF in meeting deadlines, which is an expected behavior~\cite{Baruah-gnpedf}. In Figure~\ref{fig:2C-5T-NL-IU-AUR}, we observe a constant utility from 450\% to 800\% utilization load for G-GUA. This is primarily because of the smaller task-set used. The task-set has only five tasks; during high overloads, G-GUA finds at least one task that is feasible. This highlights the concept of importance over urgency. For a two-processor system, 450\% utilization load is twice the normal load. We observe that none of the deadline-based scheduling algorithms consider any task eligible to be scheduled. On the other hand, the UA based scheduling algorithms find at least one ``important" task to be scheduled that can accrue total system utility.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-5T-NL-IU-AUR}
  \caption{AUR vs. CPU utilization (5T, 2C, NL, IU)}
   \label{fig:2C-5T-NL-IU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-5T-NL-IU-DSR}
  \caption{DSR vs. CPU utilization (5T, 2C, NL, IU)}
  \label{fig:2C-5T-NL-IU-DSR}
\end{figure}
 
 
Figures~\ref{fig:2C-5T-NL-RU-AUR} and~\ref{fig:2C-5T-NL-RU-DSR} show the AUR and DSR results, respectively, for the 5T task-set using the RU model. In the RU model, tasks are assigned random utilities. We continue to observe similar performance as seen in the earlier results for IU and DU.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-5T-NL-RU-AUR}
  \caption{AUR vs. CPU utilization (5T, 2C, NL, RU)}
  \label{fig:2C-5T-NL-RU-AUR}
\end{figure}

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-5T-NL-RU-DSR}
  \caption{DSR vs. CPU utilization (5T, 2C, NL, RU)}
  \label{fig:2C-5T-NL-RU-DSR}
\end{figure}


In order to see the effect of increase in the number of tasks on the performance of NG-GUA and G-GUA, we use the 12T and 27T task-sets on the two-core platform. Figures~\ref{fig:2C-12T-NL-DU-AUR}, ~\ref{fig:2C-12T-NL-DU-DSR},~\ref{fig:2C-12T-NL-IU-AUR}, ~\ref{fig:2C-12T-NL-IU-DSR},~\ref{fig:2C-12T-NL-RU-AUR} and~\ref{fig:2C-12T-NL-RU-DSR} show the DSR and AUR results for the DU, IU and RU models, respectively, for the 12T task-set. The AUR results show that both NG-GUA and G-GUA perform better during overloads even when the number of tasks in the system are increased three-fold. Figure~\ref{fig:2C-12T-NL-DU-AUR} shows the AUR result for the DU model. As the deadline-based schedulers are only able to meet task deadlines for $U \approx m/2$, there is a sharp plunge in the number of deadlines met (as seen in Figure~\ref{fig:2C-12T-NL-DU-DSR}). As a result, the AUR falls down drastically. This behavior is common among all the models under 12T.

We notice that the AUR results for G-GUA do not represent a constant line as was seen with the 5T results.  This happens because the number of tasks in the system have increased and as a result G-GUA is able to schedule more high utility tasks. Also, the average AUR accrued between 250\% utilization load and 800\% utilization load is around 85\%, which is higher than the average AUR accrued in the same range for the 5T task-set.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-12T-NL-DU-AUR}
  \caption{AUR vs. CPU utilization (12T, 2C, NL, DU)}
  \label{fig:2C-12T-NL-DU-AUR}
\end{figure}

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-12T-NL-DU-DSR}
  \caption{DSR vs. CPU utilization (12T, 2C, NL, DU)}
  \label{fig:2C-12T-NL-DU-DSR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-12T-NL-IU-AUR}
  \caption{AUR vs. CPU utilization (12T, 2C, NL, IU)}
  \label{fig:2C-12T-NL-IU-AUR}
\end{figure}
 
 \begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-12T-NL-IU-DSR}
  \caption{DSR vs. CPU utilization (12T, 2C, NL, IU)}
  \label{fig:2C-12T-NL-IU-DSR}
\end{figure}

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-12T-NL-RU-AUR}
  \caption{AUR vs. CPU utilization (12T, 2C, NL, RU)}
  \label{fig:2C-12T-NL-RU-AUR}
\end{figure}

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-12T-NL-RU-DSR}
  \caption{DSR vs. CPU utilization (12T, 2C, NL, RU)}
  \label{fig:2C-12T-NL-RU-DSR}
\end{figure}

We further increase the number of real-time tasks in the system and use the 27T task-set. The results are shown in Figures~\ref{fig:2C-27T-NL-DU-AUR},~\ref{fig:2C-27T-NL-DU-DSR},~\ref{fig:2C-27T-NL-IU-AUR},~\ref{fig:2C-27T-NL-IU-DSR},~\ref{fig:2C-27T-NL-RU-AUR}, and~\ref{fig:2C-27T-NL-RU-DSR}.

Figures~\ref{fig:2C-27T-NL-RU-AUR} and~\ref{fig:2C-27T-NL-RU-DSR} show the AUR and DSR results, respectively, for the RU model using a 27T task-set. With an increase in the number of tasks in the system, we do not see much improvement in the performance of the deadline-based scheduling algorithms. Both G-EDF and G-NP-EDF are able to meet all deadlines up until 200\% ($m=2$). During overloads, the DSR of all the deadline-based algorithms is close to zero. For 250\% utilization load ($m=2.5$), which represents a system with a light overloads, G-EDF meets around 5\% of task deadlines, while NG-GUA is able to meet around 95\% task deadlines. The improvement in AUR at 250\% CPU utilization load is around 1800\%. We notice that G-GUA performs better than NG-GUA. This is an expected behavior. However, we observe that between 250\% to 650\%, NG-GUA performs lower than expected. As we are using a RU model, this can be attributed to the way the utilities are assigned to the tasks. This is confirmed in the IU and DU models for the same task-set. Figure~\ref{fig:2C-27T-NL-IU-AUR} shows the AUR results for the IU model using 27T task-set. We observe that the performance of NG-GUA is in sync with G-GUA. The same is true for the DU model as shown in Figure~\ref{fig:2C-27T-NL-DU-AUR}.
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-27T-NL-DU-AUR}
  \caption{AUR vs. CPU utilization (27T, 2C, NL, DU)}
  \label{fig:2C-27T-NL-DU-AUR}
\end{figure}
 
  
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-27T-NL-DU-DSR}
  \caption{DSR vs. CPU utilization (27T, 2C, NL, DU)}
  \label{fig:2C-27T-NL-DU-DSR}
\end{figure}
  
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-27T-NL-IU-AUR}
  \caption{AUR vs. CPU utilization (27T, 2C, NL, IU)}
  \label{fig:2C-27T-NL-IU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-27T-NL-IU-DSR}
  \caption{DSR vs. CPU utilization (27T, 2C, NL, IU)}
  \label{fig:2C-27T-NL-IU-DSR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-27T-NL-RU-AUR}
  \caption{AUR vs. CPU utilization (27T, 2C, NL, RU)}
  \label{fig:2C-27T-NL-RU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/2C-27T-NL-RU-DSR}
  \caption{DSR vs. CPU utilization (27T, 2C, NL, RU)}
  \label{fig:2C-27T-NL-RU-DSR}
\end{figure}
 
%\clearpage
 
\subsubsection{Four-core Platform Results} 
  
In this section, we discuss the experimental results on the four-core platform. We use the 5T, 12T and 27T task-sets using all three models. Figures~\ref{fig:4C-5T-NL-DU-AUR} and~\ref{fig:4C-5T-NL-DU-DSR} show the AUR and DSR results, respectively, for the DU model using the 5T task-set. Although, the total accrued utility appears to be lower for this task-set on the four-core platform when compared to the two-core results for the same task-set in Figure~\ref{fig:2C-5T-NL-DU-AUR}, the behavior can be explained. The reason for this is the relationship between the number of cores and real-time tasks used. There are 4 processors in the system and we are using a 5T task-set. This means that a deadline-based scheduling algorithm is able to assign four out of the five tasks to processors during underloads. However, during overloads, there is a much sharper decline in the DSR (and as a result the AUR) because there are not many real-time tasks left in the system to be executed when other tasks start missing deadlines. As a result, after 350\% utilization load, the DSR for the deadline-based scheduling algorithms is zero. NG-GUA and G-GUA, on the other hand, are still able to find at least one task to execute. 

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-5T-NL-DU-AUR}
  \caption{AUR vs. CPU utilization (5T, 4C, NL, DU)}
  \label{fig:4C-5T-NL-DU-AUR}
\end{figure}
 
At 400\% utilization load, G-EDF, G-NP-EDF and G-FIFO meet zero deadlines. On the other hand, NG-GUA is able to schedule at least one task, while G-GUA schedules two. During underloads both G-GUA and NG-GUA try to meet deadlines and accrue as much utility as possible. NG-GUA is able to meet all the deadlines till 350\% and performs better than G-GUA while the latter provides better utility accrual during overloads. Figures~\ref{fig:4C-5T-NL-DU-AUR} and~\ref{fig:4C-5T-NL-DU-DSR} provide a good example of utility based scheduling during overloads and we have included the 5T results on the four-core platform for the same reason.

The DSR results for the IU and RU models for the 5T task-set are shown in Figures~\ref{fig:4C-5T-NL-IU-DSR} and~\ref{fig:4C-5T-NL-RU-DSR}, respectively, while the AUR results for the IU and RU models for the 5T task-set are shown in Figures~\ref{fig:4C-5T-NL-IU-AUR} and~\ref{fig:4C-5T-NL-RU-AUR}, respectively. As the utility assignments in IU and RU favor UA scheduling, we observe that for a similar DSR curve for IU and RU (when compared with the DU model for 5T in Figure~\ref{fig:4C-5T-NL-DU-DSR}), the system accrues better utility. This is because tasks with earlier deadlines are given smaller utilities in the IU model while the assignment of utilities in RU is totally random. This explains that given a TUF ordering such as DU, NG-GUA  and G-GUA still outperforms other deadline-based scheduling algorithms. The average AUR improvement of G-GUA between the DU and the IU model is around 250\%. G-GUA continues to perform better than NG-GUA in light overloads. In Figure~\ref{fig:4C-5T-NL-RU-AUR}, at 350\% utilization load, G-GUA performs 5\% better than NG-GUA. However at 400\% utilization load, G-GUA performs 50\% better than NG-GUA.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-5T-NL-DU-DSR}
  \caption{DSR vs. CPU utilization (5T, 4C, NL, DU)}
  \label{fig:4C-5T-NL-DU-DSR}
\end{figure}

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-5T-NL-IU-AUR}
  \caption{AUR vs. CPU utilization (5T, 4C, NL, IU)}
  \label{fig:4C-5T-NL-IU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-5T-NL-IU-DSR}
  \caption{DSR vs. CPU utilization (5T, 4C, NL, IU)}
  \label{fig:4C-5T-NL-IU-DSR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-5T-NL-RU-AUR}
  \caption{AUR vs. CPU utilization (5T, 4C, NL, RU)}
  \label{fig:4C-5T-NL-RU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-5T-NL-RU-DSR}
  \caption{DSR vs. CPU utilization (5T, 4C, NL, RU)}
  \label{fig:4C-5T-NL-RU-DSR}
\end{figure}  

We now consider the behavior of our algorithm when the number of real-time tasks in the system are increased. We use the 12T and 27T task-set with all three TUF assignment models. Figure~\ref{fig:4C-12T-NL-DU-AUR} and~\ref{fig:4C-12T-NL-DU-DSR} show the AUR and DSR results for the DU model using the 12T task-set. Both G-GUA and NG-GUA perform better than the deadline-based schedulers. In Figure~\ref{fig:4C-12T-NL-DU-AUR}, G-GUA is able to accrue 90\% total utility up until 750\% utilization load. NG-GUA is able to accrue around 80\% total utility up until 750\% utilization load. G-EDF and G-NP-EDF meet all deadlines and accrue 100\% utility during underloads, but during overloads the domino effect prevents them from both meeting deadlines and accruing utility. 

We observe a consistent performance improvement using all models with the 12T task-set. Figures~\ref{fig:4C-12T-NL-IU-AUR} and~\ref{fig:4C-12T-NL-IU-DSR} show the AUR and DSR results, respectively, for IU model using the 12T task-set. Figures~\ref{fig:4C-12T-NL-RU-AUR} and~\ref{fig:4C-12T-NL-RU-DSR} show the AUR and DSR results, respectively, for RU model using the 12T task-set. In the RU model, we observe that NG-GUA meets all deadlines similar to G-EDF at 350\%, while G-GUA is only able to meet 95\% of deadlines. However, G-GUA performs consistently better than NG-GUA from 400\% utilization load to 950\% utilization load with an average improvement of around 15\% in the total accrued utility.


\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-NL-DU-AUR}
  \caption{AUR vs. CPU utilization (12T, 4C, NL, DU)}
  \label{fig:4C-12T-NL-DU-AUR}
\end{figure}
 

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-NL-DU-DSR}
  \caption{DSR vs. CPU utilization (12T, 4C, NL, DU)}
  \label{fig:4C-12T-NL-DU-DSR}
\end{figure}
 
 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-NL-IU-AUR}
  \caption{AUR vs. CPU utilization (12T, 4C, NL, IU)}
  \label{fig:4C-12T-NL-IU-AUR}
\end{figure}
 
 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-NL-IU-DSR}
  \caption{DSR vs. CPU utilization (12T, 4C, NL, IU)}
  \label{fig:4C-12T-NL-IU-DSR}
\end{figure}
 
 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-NL-RU-AUR}
  \caption{AUR vs. CPU utilization (12T, 4C, NL, RU)}
  \label{fig:4C-12T-NL-RU-AUR}
\end{figure}
 
 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-NL-RU-DSR}
  \caption{DSR vs. CPU utilization (12T, 4C, NL, RU)}
  \label{fig:4C-12T-NL-RU-DSR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-27T-NL-DU-AUR}
  \caption{AUR vs. CPU utilization (27T, 4C, NL, DU)}
  \label{fig:4C-27T-NL-DU-AUR}
\end{figure}
 
 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-27T-NL-DU-DSR}
  \caption{DSR vs. CPU utilization (27T, 4C, NL, DU)}
  \label{fig:4C-27T-NL-DU-DSR}
\end{figure}
 
 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-27T-NL-IU-AUR}
  \caption{AUR vs. CPU utilization (27T, 4C, NL, IU)}
  \label{fig:4C-27T-NL-IU-AUR}
\end{figure}
 
 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-27T-NL-IU-DSR}
  \caption{DSR vs. CPU utilization (27T, 4C, NL, IU)}
  \label{fig:4C-27T-NL-IU-DSR}
\end{figure}
 
 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-27T-NL-RU-AUR}
  \caption{AUR vs. CPU utilization (27T, 4C, NL, RU)}
  \label{fig:4C-27T-NL-RU-AUR}
\end{figure}
 
 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-27T-NL-RU-DSR}
  \caption{DSR vs. CPU utilization (27T, 4C, NL, RU)}
  \label{fig:4C-27T-NL-RU-DSR}
\end{figure}

The performance with the 27T task-set is almost identical to the 12T results. Figures~\ref{fig:4C-27T-NL-DU-AUR} and~\ref{fig:4C-27T-NL-DU-DSR} show the AUR and DSR results, respectively, for the DU model using the 27T task-set, while Figures~\ref{fig:4C-27T-NL-IU-AUR} and~\ref{fig:4C-27T-NL-IU-DSR} show the AUR anad DSR results, respectively, for the IU model using the 27T task-set. G-GUA performs better than NG-GUA in the DU model with an average improvement of 15\% in AUR values. Figures~\ref{fig:4C-27T-NL-RU-AUR} and~\ref{fig:4C-27T-NL-RU-DSR} show the AUR and DSR results, respectively, for the RU model for the 27T task-set.  As the number of tasks increase, we observe an average standard deviation of around 6-8\%. This amount of variance is acceptable given the fact that it is impossible to have the same operating system environment for every test execution. Due to the \texttt{PREEMPT\_RT} patch, ChronOS is able to withstand jitter from non real-time based applications. However, as mentioned earlier, there are critical operating system primitives that have higher priority in ChronOS which are required for the proper functioning of the operating system, such as the timer interrupts and the I/O interrupts.

\subsubsection{Eight-core Platform Results} 

In order to establish the performance of both NG-GUA and G-GUA, we move to a higher platform. The eight-core platform uses two Intel Xeon E5520 quad-core processors which have four physical cores, thus supporting four hardware threads. The processors provide Hyper-Threading (HT)\nomenclature{HT}{Hyper-Threading} using which we can simulate eight logical processors. However, ChronOS does not support HT. As a result, we need to disable HT and use two Intel Xeon E5520 quad-core processors to create an eight-core platform with eight hardware threads.

With the increase in the number of processors, we avoid using the 5T and 12T task-sets, as the number of tasks in these task-sets do not scale up to the number of processors used. Instead, we use the 27T and 50T task-sets. Using a 50T task-set allows us to ascertain if our scheduling algorithms incur any scalability issues and also provides a better perspective to the experimental results on the eight-core platform.

Figures~\ref{fig:8C-27T-NL-DU-AUR} and~\ref{fig:8C-27T-NL-DU-DSR} show the AUR and DSR results, respectively, with the DU model using the 27T task-set. As we are using an eight-core platform, we observe that G-EDF is able to meet all deadlines up until 780\% utilization load while G-NP-EDF is able to meet all deadlines up until 750\% utilization load. These results are as expected and meet the schedulability tests for both these algorithms~\cite{Baruah-gnpedf}. G-FIFO, on the other hand, starts missing deadlines at 400\% utilization load and at full system load (800\%), it has already degraded to around 10\% deadline satisfaction ratio.

During overloads, both G-NP-EDF and G-EDF start missing deadlines rapidly and reach to a 20\% deadline satisfaction ratio during the light overload of 900\% utilization load. G-FIFO, on the other hand, does not meet any deadlines during overloads. When compared to the deadline-based algorithms, G-GUA and NG-GUA not only provide a better deadline satisfaction ratio, but also accrue greater utility in the system. In Figure~\ref{fig:8C-27T-NL-DU-AUR}, we observe that G-GUA at the CPU utilization load of 900\% provides around 99\% accrued utility. This measures to an overall improvement of around 400\% in total accrued utility. However, at 1200\% CPU utilization load, G-GUA provides a 95\% accrued utility, which measures to an overall improvement of around 1800\% in total accrued utility. NG-GUA performs better than the deadline-based algorithms. However, G-GUA outperforms NG-GUA, as expected, by an average of 5-10\% across 800-1200\% CPU utilization load. 

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-27T-NL-DU-AUR}
  \caption{ AUR vs. CPU utilization (27T, 8C, NL, DU)}
  \label{fig:8C-27T-NL-DU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-27T-NL-DU-DSR}
  \caption{ DSR vs. CPU utilization (27T, 8C, NL, DU)} 
  \label{fig:8C-27T-NL-DU-DSR}
\end{figure}
 
In Figures~\ref{fig:8C-27T-NL-IU-AUR} and~\ref{fig:8C-27T-NL-IU-DSR} we show the AUR and DSR results, respectively, for IU model using the 27T task-set. The results are similar to the DU model. However, we observe that NG-GUA is able to meet all deadlines during underloads and defaults to the G-EDF behavior. In Figures~\ref{fig:8C-27T-NL-RU-AUR} and~\ref{fig:8C-27T-NL-RU-DSR} we show the AUR and DSR results, respectively, for the RU model using 27T task-set. The standard deviation of the results on eight-core are in the range of $0.01-0.03$, which show that the results are consistent across multiple runs.
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-27T-NL-IU-AUR}
  \caption{ AUR vs. CPU utilization (27T, 8C, NL, IU)}
  \label{fig:8C-27T-NL-IU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-27T-NL-IU-DSR}
  \caption{ DSR vs. CPU utilization (27T, 8C, NL, IU) }
  \label{fig:8C-27T-NL-IU-DSR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-27T-NL-RU-AUR}
  \caption{ AUR vs. CPU utilization (27T, 8C, NL RU) }
  \label{fig:8C-27T-NL-RU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-27T-NL-RU-DSR}
  \caption{DSR vs. CPU utilization (27T, 8C, NL, RU) }
  \label{fig:8C-27T-NL-RU-DSR}
\end{figure}
 
We now consider the effect of increasing the number of tasks. We use the 50T task-set with all the three models. Figures~\ref{fig:8C-50T-NL-DU-AUR},~\ref{fig:8C-50T-NL-IU-AUR} and~\ref{fig:8C-50T-NL-RU-AUR} show the AUR results for DU, IU and RU models, respectively, using 50T task-set while, Figures~\ref{fig:8C-50T-NL-DU-DSR},~\ref{fig:8C-50T-NL-IU-DSR} and~\ref{fig:8C-50T-NL-RU-DSR} show the DSR results for DU, IU and RU models, respectively, using the 50T task-set.

We observe that the performance of NG-GUA and G-GUA is consistent with the DU model results of 27T task-set shown in Figure~\ref{fig:8C-27T-NL-DU-AUR}. However, with the increase in the number of tasks, there is a slight drop in the total accrued utility at certain CPU utilization loads. In Figure~\ref{fig:8C-50T-NL-RU-AUR} at 900\% CPU utilization load, we observe an accrued utility of 94\%. At the same load on the 27T task-set, we observe an accrued utility of around 99\%, which is a drop of around 5\%. However at 1200\% CPU utilization load, we observe an accrued utility of 85\% with the 27T task-set and around 83\% with the 50T task-set, which is a drop of around 3\%. We cover this is detail in Section~\ref{sec:overheads}, where we present the scheduling overheads for NG-GUA and G-GUA as a function of increased number of tasks and CPU utilization load.
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-50T-NL-DU-AUR}
  \caption{AUR vs. CPU utilization (50T, 8C, NL, DU) }
  \label{fig:8C-50T-NL-DU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-50T-NL-DU-DSR}
  \caption{ DSR vs. CPU utilization (50T, 8C, NL, DU) }
  \label{fig:8C-50T-NL-DU-DSR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-50T-NL-IU-AUR}
  \caption{AUR vs. CPU utilization (50T, 8C, NL, IU)}
  \label{fig:8C-50T-NL-IU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-50T-NL-IU-DSR}
  \caption{DSR vs. CPU utilization (50T, 8C, NL, IU)}
  \label{fig:8C-50T-NL-IU-DSR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-50T-NL-RU-AUR}
  \caption{AUR vs. CPU utilization (50T, 8C, NL, RU)}
  \label{fig:8C-50T-NL-RU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/8C-50T-NL-RU-DSR}
  \caption{DSR vs. CPU utilization (50T, 8C, NL, RU)}
  \label{fig:8C-50T-NL-RU-DSR}
\end{figure}
 
Overall, we observe that the performance of both NG-GUA and G-GUA outperforms that of the deadline-based scheduling algorithms, such as G-EDF and G-NP-EDF. Between the two UA scheduling algorithms, NG-GUA provides a better deadline satisfaction ratio than G-GUA during underloads. This is due to the fact that NG-GUA defaults to a G-EDF-like behavior. However during overloads, NG-GUA accrues better utility than G-EDF. As gMUA defaults to NG-GUA for the non-dependent case, its performance is similar to NG-GUA. G-GUA, on the other hand, outperforms NG-GUA (and gMUA) in accrued utility during overloads and provides an average improvement of about 15\% over NG-GUA/gMUA across CPU utilizations.

%%% Not possible due to lack of time. However, we 
%%% have captured the Baker style task utilization loads
%%% in our TUF based model.
%Baker's model~\cite{baker} for global and partitioned EDF schedulability test for multiprocessor is a widely used model for evaluation of multiprocessor scheduling algorithms and has been extensively used in~\cite{bburg-global-09}~\cite{bburg-fmlp-08}~\cite{scalabilitypfair}. The model creates task-sets based on task utilization which are distributed using three uniform and three bi-modal distributions. 
%
%The uniform distribution has tasks with utilization loads in the range of $[0.001-0.1]$ \textit{(light)}, $[0.1-0.4]$ \textit{(medium)} and $[0.5-0.9]$ \textit{(heavy)}. The bi-modal distribution has the tasks with the utilization loads in the range is either $[0.001-0.5)$ or $[0.5-0.9]$ with respective probabilities of $8/9$ and $1/9$ \textit{(light)}, $6/9$ and $3/9$ \textit{(medium)}, and $4/9$ and $5/9$ \textit{(heavy)}. We used an automatic task generator to generate the task-sets based on Baker's model. The task-sets were generated automatically using a task-set generator. The utilities (TUFs) for each task were assigned randomly in the range of $[100-5000]$ while the periods were assigned randomly in the range of $[50ms-5000ms]$.
% 
%Table~\ref{tab:baker-legend} shows the legend used in the experimental results.
% 
%\begin{table}[!htb]
%\caption{Legend used in experimental results based on Baker's~\cite{baker} model}
%\label{tab:baker-legend}
%\begin{center}
%\begin{tabular}{c c}
%\hline
%Symbol & Description \\ \hline
%\texttt{RU} & Random Utility\\
%\texttt{NL} & No locks used \\
%\texttt{xC} & Experiment using $x$ number of processors \\
%\texttt{UL} & Light task-set with uniform distribution \\
%\texttt{UM} & Medium task-set with uniform distribution \\
%\texttt{UH} & Heavy task-set with uniform distribution \\
%\texttt{BL} & Light task-set with bi-modal distribution \\
%\texttt{BM} & Medium task-set with bi-modal distribution \\
%\texttt{BH} & Heavy task-set with bi-modal distribution \\
%\hline
%\end{tabular}
%\end{center}
%\end{table} 

\subsection{Comparison with Partitioned Scheduling Algorithms}

In this section we compare NG-GUA and G-GUA with partitioned scheduling algorithms. We consider the two state-of-the-art competitors P-EDF and P-DASA. The partitioned scheduling algorithms work differently than the global scheduling algorithms. While global scheduling algorithms provide an on-line scheduler where a single ready queue is maintained for all the real-time tasks across processors; partitioned scheduling algorithms, on the other hand, use an off-line bin-packing heuristic to divide the tasks into processor bins. The tasks are then assigned to the processors, where each processor runs the single processor variant of the algorithm and schedules only the tasks that have been assigned to it. As a result, partitioned schedulers may or may-not incur less overheads than their global variants.

We compare NG-GUA and G-GUA with P-EDF and P-DASA to find if, even with global scheduling overheads, our algorithms compare in performance with the partitioned algorithms. P-EDF runs EDF on each of the processors. EDF uses the real-time tasks that have been assigned to it using the off-line partitioning heuristic. As EDF, on a single processor, is optimal for $U \le 1$, P-EDF tries to mimic EDF behavior to meet as many deadlines as possible. However, during overloads, P-EDF starts missing deadlines rapidly. In a similar fashion, P-DASA runs the UA scheduling algorithm DASA on each of the processors, wherein DASA tries to accrue greater overall utility on each of the processors.

In order to partition the tasks on to the processors, we implement Baruah's first-fit partitioning algorithm~\cite{baruah-part-06} to divide the task-sets off-line into processor bins. The algorithm uses the EDF schedulability criteria and assigns tasks to processors such that the resultant task-set is feasible on that processor. Once the partitioned task-sets are created, they are set a processor affinity.

We perform the comparisons on a four-core platform and consider two types of task-sets with an increasing number of tasks.
\begin{enumerate}
	\item The first task-set uses 12 tasks with deadlines/periods in the range of $[300ms-20000ms]$ and 
		the utilization load for each task in the range of $[0.01-0.4]$.
	\item The second task-set uses 27 tasks with deadlines/periods in the range of $[50ms-7500ms]$ and
		the utilization load for each task in the range of $[0.01-0.3]$. 
\end{enumerate}

The task-sets do not use any locks. We assign random utilities to the tasks in the range of $[100-5000]$. The task-set is used ``as-is" with the global scheduling algorithms (NG-GUA and G-GUA), while it is partitioned using Baruah's first-fit algorithm for the partitioned scheduling algorithms. Table~\ref{tab:part-legend} shows the legend used in the experimental results. 

\begin{table} [htbp]
\caption{Legend used in experimental results for comparison with other partitioned scheduling algorithms}
\label{tab:part-legend}
\begin{center}
\begin{tabular}{c c}
\hline
Symbol & Description \\ \hline
\texttt{RU} & Random Utility\\
\texttt{NL} & No locks used \\
\texttt{BF} & Baruah's first-fit partition~\cite{baruah-part-06} \\
\texttt{xC} & Experiment using $x$ number of processors \\
\texttt{xT} & Experiment using $x$ number of tasks \\
\hline
\end{tabular}
\end{center}
\end{table}

Figures~\ref{fig:4C-12T-P-NL-RU-AUR} and~\ref{fig:4C-12T-P-NL-RU-DSR} show the AUR and DSR results, respectively, for the RU model using a partitioned 12T task-set for partitioned algorithms and the ``as-is" 12T task-set for global scheduling algorithms. From Figure~\ref{fig:4C-12T-P-NL-RU-DSR}, we observe that P-EDF is able to meet all deadlines till 375\% utilization load. As we are using a four-core platform, the result is in accordance with the schedulability criteria of P-EDF~\cite{anderson_pedf}. However, during overloads, P-EDF starts missing deadlines and by 550\% utilization load, we observe that P-EDF meets only around 5\% deadlines. This is primarily due to the domino effect of EDF based algorithms during overloads. 

P-DASA, on the other hand, does not meet all its deadlines during underloads, as expected~\cite{DASA}. DASA is a utility accrual scheduling algorithm that does not default to EDF during underloads. As a result, we observe that P-DASA starts missing deadlines at around 300\% utilization load. On the other hand, P-DASA performs better than P-EDF during overloads and it not only meets more deadlines that P-EDF, but also provides better accrued utility.

However, when compared with NG-GUA and G-GUA, the total accrued utility of P-DASA is lower. At 400\% utilization load, P-DASA provide a total accrued utility of around 70\%, while both NG-GUA and G-GUA provide a 100\% accrued utility, which is a performance improvement of around 40\%. For higher utilization loads, both NG-GUA and G-GUA accrue higher utilities with G-GUA outperforming every other scheduler. At 700\% utilization load, G-GUA has around 150\% improvement in total accrued utility. The vertical errors bars show the variance in the results, the reason for which has been discussed in the earlier sections and remains the same.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-P-NL-RU-AUR}
  \caption{AUR vs. CPU utilization (12T, 4C, NL, RU, BF)}
  \label{fig:4C-12T-P-NL-RU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-P-NL-RU-DSR}
  \caption{DSR vs. CPU utilization (12T, 4C, NL, RU, BF) }
\label{fig:4C-12T-P-NL-RU-DSR}
\end{figure}

Figures~\ref{fig:4C-27T-P-NL-RU-AUR} and~\ref{fig:4C-27T-P-NL-RU-DSR} show the AUR and DSR results, respectively, for RU model using the 27T partitioned task-set for the partitioned algorithms and ``as-is" 27T task-set for the global scheduling algorithms. P-EDF behaves as expected and starts missing deadlines during overloads. P-DASA accrues utility during overloads and has a better AUR compared to P-EDF. NG-GUA and G-GUA perform better than P-DASA during overloads. At 450\% utilization load, NG-GUA has an improvement of around 50\% in accrued utility over P-DASA. Between 550\% to 800\% utilization load, both NG-GUA and G-GUA have an average improvement of 60\% in accrued utility over P-DASA. The results show some variability in the total accrued utility of NG-GUA and G-GUA with a standard deviation of around 6-8\%. As mentioned earlier, this amount of variability is expected due to the various operating system primitives. Between 400\% and 600\% utilization loads, we observe that NG-GUA performs better than G-GUA by around 4\%. This can be attributed to issues with cache-warm up or other I/O interruptions inside ChronOS.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-27T-P-NL-RU-AUR}
  \caption{AUR vs. CPU utilization (27T, 4C, NL, RU, BF) }
\label{fig:4C-27T-P-NL-RU-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-27T-P-NL-RU-DSR}
  \caption{DSR vs. CPU utilization (27T, 4C, NL, RU, BF)}
\label{fig:4C-27T-P-NL-RU-DSR}
\end{figure}

Overall, we observe that the deadline-based partitioned scheduling (such as P-EDF) do not perform well during overload conditions. On the other hand, the partitioned UA based scheduling algorithms (such as P-DASA) perform better than the deadline variant. However, G-GUA and NG-GUA outperform the partitioned algorithms in total accrued utility during overloads.

\pagebreak
\section{Results With Dependencies}\label{sec:w-dep}

In this section we present the experimental results of our evaluation of NG-GUA and G-GUA in the presence of dependencies. We compare the results with PIP based algorithms, such as G-FIFO-PIP, GNP-EDF-PIP. 

We use locks as a means of creating contention between tasks and use the following models:
\begin{itemize}
	\item Fixing the number of locks per task and the critical section length for each lock but varying the total utilization load.
	\item Fixing the total utilization load and the number of locks per task but varying the critical section length for each lock.
	\item Fixing the total utilization load and the critical section length for each lock but varying the number of locks per task. 
\end{itemize}

In ChronOS, we implement locks as \texttt{futexes}, which allows us to share a context from the kernel-space to the user-space. The test application uses the ChronOS system call to request for a lock. This is done using the 
\texttt{do\_vt\_rt\_mutex(struct mutex\_data \_\_user *mutexreq, int operation)}
system call. The \texttt{operation} can be a \texttt{MUTEX\_REQUEST} or \texttt{MUTEX\_RELEASE}. The application provides the \texttt{futex} information using the \texttt{mutexreq} data-structure.

We compare NG-GUA and G-GUA with the other PIP enabled scheduling algorithms on the four-core platform. We consider a 12T base task-set that creates 12 tasks with deadlines/periods in the range of $[150ms - 3000ms]$; with the utilization load for each task in the range of $[0.01-0.4]$. We consider the RU model and assign random utilities to the tasks in the range of $[100-5000]$.

The base task-set creates a total of 12 locks in the system which are distributed amongst individual tasks in the task-set in order to create four different variants.
\begin{description}
\item \textbf{1 lock per task} - We distribute the locks in the 12T task-set such that each task gets to request for a single lock.
\item \textbf{2 locks per task} - We distribute the locks in the 12T task-set such that each task gets to request two locks. \item \textbf{3 locks per task} - We distribute the locks in the 12T task-set such that each task gets to request three locks.
\item \textbf{4 locks per task} - We distribute the locks in the 12T task-set such that each task gets  to request four locks.
\end{description}

Note that more than one task can request the same lock. The assignment of locks in the task-set is done randomly using an automatic task-set generator application. Table~\ref{tab:depend-legend} shows the legend used in experimental result.

\begin{table} [!htb]
\caption{Legend used in experimental results for comparison with other global scheduling algorithms in the presence of dependencies}
\label{tab:depend-legend}
\begin{center}
\begin{tabular}{>{\centering}p{3cm} p{10cm}}
\hline
Symbol & Description \\ \hline
\texttt{RU} & Random Utility\\
\texttt{xL} & Experiment using $x$ number of locks per task \\
\texttt{xCS} & Experiment using critical section length equal to $x$ percent of total task execution cost \\
\texttt{xUt} & Experiment using $x$ utilization load \\
\texttt{xC} & Experiment using $x$ number of processors \\
\texttt{xT} & Experiment using $x$ number of tasks \\
\hline
\end{tabular}
\end{center}
\end{table}

\subsection{Varying CPU utilization Load}\label{sec:vary-cpu}

In this section we discuss the experimental results of running NG-GUA and G-GUA in the presence of dependencies. The results are compared with other deadline-based scheduling algorithms that handle resource using the priority inheritance protocol. Using PIP, if the task $J_a$ with higher priority is blocked on a resource $R_i$, which is being owned by a task $J_b$ that has a lower priority, the scheduler bumps the priority of task $J_b$ to that of task $J_a$. This is done to allow $J_b$ to finish execution and release the resource. For the deadline-based scheduler, the priorities can be mapped to the deadlines. A task with an earlier deadline is the most eligible task in the system. If that task is blocked on a resource owned by another task that has a later deadline, the scheduler allows the latter task to be executed such that the resource is released and made available.

In this experiment, we desire to find the effect of increasing CPU utilization load on the accrued utility in the presence of locks. We consider the following combinations:

\begin{enumerate}
\item We use the 12T task-set with 1 lock per task and fix the critical section length of the lock to 5\% of the task's worst case execution cost, while varying the CPU utilization load from 100-1000\%.
\item We use the 12T task-set with 1 lock per task and fix the critical section length of the lock to 25\% of the task's worst case execution cost, while varying the CPU utilization load from 100-1000\%.
\item We use the 12T task-set with 4 locks per tasks and fix the total critical section length of the locks to 5\% of the task's worst case execution, while varying the CPU utilization load from 100-1000\%.
\item We use the 12T task-set with 4 locks per tasks and fix the total critical section length of the locks to 25\% of the task's worst case execution, while varying the CPU utilization load from 100-1000\%.
\end{enumerate}

Figures~\ref{fig:4C-12T-1L-RU-5CS-AUR} and~\ref{fig:4C-12T-1L-RU-5CS-DSR} show the AUR and DSR results, respectively, for the RU model with 12T task-set with one lock and 5\% critical section length. Even with a 5\% critical section length and a single lock, we observe that both G-NP-EDF and G-FIFO are not able to meet most of their deadlines during underloads. During overloads, they continue to miss deadlines and as a result the overall accrued utility of the system comes down. Both NG-GUA and G-GUA perform much better than the deadline-based scheduler, with an average improvement of around 120\% in the total accrued utility of the system. As we increase the critical section length to 25\%, we observe in Figures~\ref{fig:4C-12T-1L-RU-25CS-AUR} and~\ref{fig:4C-12T-1L-RU-25CS-DSR} that total accrued utility of NG-GUA and G-GUA falls downs. However, the AUR is still higher than the deadline-based scheduling algorithms. GNP-EDF starts losing deadlines as early as 200\% CPU utilization load. On the other hand, between 200\% to 400\% utilization load, G-GUA shows an improvement in AUR by around 40\%.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-1L-RU-5CS-AUR}
  \caption{AUR vs. CPU utilization (12T, 4C, 1L, RU, 5\% CS)}
    \label{fig:4C-12T-1L-RU-5CS-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-1L-RU-5CS-DSR}
  \caption{DSR vs. CPU utilization (12T, 4C, 1L, RU, 5\% CS)}
    \label{fig:4C-12T-1L-RU-5CS-DSR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-1L-RU-25CS-AUR}
  \caption{AUR vs. CPU utilization (12T, 4C, 1L, RU, 25\% CS)}
    \label{fig:4C-12T-1L-RU-25CS-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-1L-RU-25CS-DSR}
  \caption{DSR vs. CPU utilization (12T, 4C, 1L, RU, 25\% CS)}
    \label{fig:4C-12T-1L-RU-25CS-DSR}    
\end{figure}

In Figures~\ref{fig:4C-12T-4L-RU-5CS-AUR} and~\ref{fig:4C-12T-4L-RU-5CS-DSR}, which shows the results with 4 locks per task, with the critical section length as 5\% of the WCET. We observe that by increasing the number of locks for the same critical section length, the performance of NG-GUA and G-GUA remains consistent. In Figure~\ref{fig:4C-12T-4L-RU-5CS-AUR}, NG-GUA is able to meet all deadlines till 350\% utilization load. After 350\% utilization load, G-NP-EDF's DSR falls down drastically and as a result its overall AUR is reduced. NG-GUA, on the other hand, provides an average of 75\% AUR from 300\% utilization load, all the way up to 1000\% utilization load. 

At 25\% critical section length, the AUR results, as shown in Figures~\ref{fig:4C-12T-4L-RU-25CS-AUR}, indicates that, although the overall accrued utility of the system is low, G-GUA and NG-GUA still provide the highest utility accrual, especially during light overloads, ranging from 350\% utilization load to 500\% utilization load. 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-4L-RU-5CS-AUR}
  \caption{AUR vs. CPU utilization (12T, 4C, 4L, RU, 5\% CS)}
    \label{fig:4C-12T-4L-RU-5CS-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-4L-RU-5CS-DSR}
  \caption{DSR vs. CPU utilization (12T, 4C, 4L, RU, 5\% CS) }
    \label{fig:4C-12T-4L-RU-5CS-DSR}
\end{figure}


\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-4L-RU-25CS-AUR}
  \caption{AUR vs. CPU utilization (12T, 4C, 4L, RU, 25\% CS)}
    \label{fig:4C-12T-4L-RU-25CS-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-4L-RU-25CS-DSR}
  \caption{DSR vs. CPU utilization (12T, 4C, 4L, RU, 25\% CS)}
    \label{fig:4C-12T-4L-RU-25CS-DSR}
\end{figure}

\pagebreak

\subsection{Varying Lock Critical Section Length}\label{sec:vary-cslen}

In this section, we consider the effects of varying the critical section length of locks while keeping the number of locks and the utilization load fixed. We consider the utilization loads of 400\% and 800\% that show a light-overload and a heavy-overload scenarios.

We consider the following combinations:
\begin{enumerate}
\item We use the 12T task-set with 1 lock per task and fix the utilization load at 400\%; while varying the critical section length from 5\% to 25\%
\item We use the 12T task-set with 1 lock per task and fix the utilization load at 800\%; while varying the critical section length from 5\% to 25\%
\item We use the 12T task-set with 4 locks per task and fix the utilization load at 400\%; while varying the critical section length from 5\% to 25\%
\item We use the 12T task-set with 4 locks per task and fix the utilization load at 800\%; while varying the critical section length from 5\% to 25\%
\end{enumerate}

Figure~\ref{fig:4C-12T-1L-RU-400UT-AUR} shows the AUR values across various scheduling algorithms for critical section lengths equal to 5\%, 10\% and 25\% of the total worst case execution time. We observe that G-GUA provides a consistent average accrued utility of around 80\% across all critical section lengths when a single lock is used. This is at 400\% utilization load which, on a four-core platform, is light-overload as the system reaches its full utilization potential. Figure~\ref{fig:4C-12T-1L-RU-800UT-AUR} provides the same comparison at 800\% utilization load, which is a heavy-overload, considering a four-core system. We observe that G-GUA still provides an average of 60\% accrued utility, even when the system has a heavy-overload. NG-GUA performs equally as G-GUA. On the other hand, G-GUA performs better than NG-GUA by around 5\%. This behavior is consistent with the increase in critical section lengths. At 25\% critical section length, G-GUA has an AUR of 50\%, which is an improvement of 150\% over G-NP-EDF with PIP for the same point.

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-1L-RU-400UT-AUR}
  \caption{AUR vs. Critical section length (12T, 4C, 1L, RU, 400\% CPU utilization) }
    \label{fig:4C-12T-1L-RU-400UT-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-1L-RU-800UT-AUR}
  \caption{AUR vs. Critical section length (12T, 4C, 1L, RU, 800\% CPU utilization) }
    \label{fig:4C-12T-1L-RU-800UT-AUR}
\end{figure}
 
Figure~\ref{fig:4C-12T-4L-RU-400UT-AUR} shows the AUR results when 4 locks are used at 400\% utilization load. We observe that G-GUA outperforms every other algorithm and provides a consistent average AUR of 80\% across critical section lengths. NG-GUA is seen to provide a similar behavior, with G-GUA performing better by an average of 10\%. G-GUA shows around 90\% improvement in AUR for a critical section length of 5\%. Figure~\ref{fig:4C-12T-4L-RU-800UT-AUR} shows the same results at 800\% utilization load. We observe that with 4 locks, the performance of deadline-based algorithm has degraded. G-GUA and N-GUA consistently perform better. Both G-GUA and NG-GUA provide an average AUR of around 60\% across all critical section lengths.
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-4L-RU-400UT-AUR}
  \caption{AUR vs. Critical section length (12T, 4C, 4L, RU, 400\% CPU utilization) }
    \label{fig:4C-12T-4L-RU-400UT-AUR}
\end{figure} 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-4L-RU-800UT-AUR}
  \caption{AUR vs. Critical section length (12T, 4C, 4L, RU, 800\% CPU utilization) }
    \label{fig:4C-12T-4L-RU-800UT-AUR}
\end{figure}

\pagebreak

\subsection{Varying Number of Locks per Task}\label{sec:vary-numlocks}
 
In this section, we consider the effects of varying the number of locks per task, while keeping the critical section length and the utilization load fixed. We consider the utilization loads of 400\% and 800\% that show light-overload and heavy-overload scenarios.

We consider the following combinations:
\begin{enumerate}
\item We fix the critical section length at 5\% and the utilization load at 400\%; while varying the total number of locks per task
\item We fix the critical section length at 5\% and the utilization load at 800\%; while varying the total number of locks per task
\item We fix the critical section length at 25\% and the utilization load at 400\%; while varying the total number of locks per task
\item We fix the critical section length at 25\% and the utilization load at 800\%; while varying the total number of locks per task
\end{enumerate}
 
Figure~\ref{fig:4C-12T-RU-400UT-5CS-AUR} shows the total accrued utility as a function of the number of locks, with a fixed critical section length of 5\% and a utilization load of 400\%. This is a light-overload scenario. We observe that increasing the number of locks does not have an impact on the overall accrued utility for all the algorithms. G-GUA consistently outperforms other scheduling algorithms by providing an average AUR of around 85\% across all locks. NG-GUA performs equally better with G-GUA providing an average 6\% better performance. The deadline-based schedulers provide around 50\% AUR across all locks. Figure~\ref{fig:4C-12T-RU-400UT-25CS-AUR} considers the same scenario with 25\% critical section length and we observe a similar behavior. 
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-RU-400UT-5CS-AUR}
  \caption{AUR vs. Number of locks (12T, 4C, RU, 5\% CS, 400\% CPU utilization) }
    \label{fig:4C-12T-RU-400UT-5CS-AUR}
\end{figure}


\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-RU-400UT-25CS-AUR}
  \caption{AUR vs. Number of locks (12T, 4C, RU, 25\% CS, 400\% CPU utilization) }
    \label{fig:4C-12T-RU-400UT-25CS-AUR}
\end{figure}

However, during heavy-overloads, the performance of the UA scheduling algorithms is better than the deadline-based algorithms. This is shown in Figure~\ref{fig:4C-12T-RU-800UT-5CS-AUR} for an 800\% utilization load with 5\% critical section length and in Figure~\ref{fig:4C-12T-RU-800UT-25CS-AUR} for the same load with 25\% critical section length. We consider the worst-case scenario with 25\% critical section length and a heavy-overload at 800\% utilization load. G-GUA provides an average 50\% utility accrual across varying number of locks, while NG-GUA provides an average 45\% utility accrual. G-GUA provides an average improvement of 120\% in AUR over GNP-EDF.
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-RU-800UT-5CS-AUR}
  \caption{AUR vs. Number of locks (12T, 4C, RU, 5\% CS, 800\% CPU utilization) }
    \label{fig:4C-12T-RU-800UT-5CS-AUR}
\end{figure}
 
\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./results/4C-12T-RU-800UT-25CS-AUR}
  \caption{AUR vs. Number of locks (12T, 4C, RU, 25\% CS, 800\% CPU utilization)}
    \label{fig:4C-12T-RU-800UT-25CS-AUR}
\end{figure}
 
\pagebreak

\section{Overhead Measurements}\label{sec:overheads}

In this section, we measure and compare the scheduling overheads for G-GUA and NG-GUA on ChronOS. We consider a four-core platform and use three task-sets. The details of the task-sets follow:

\begin{enumerate}
	\item The first task-set uses 5 tasks, with deadline/periods in the range of $[50000 \mu s - 5000000 \mu s]$; and a utilization load of each task in the range of $[0.1 - 0.4]$.
	\item The second task-set uses 12 tasks, with deadlines/periods in the range of $[300000 \mu s - 20000000 \mu s]$; and a utilization load of each task in the range of $[0.01 - 0.4]$.
	\item The third task-set uses 27 tasks, with deadlines/periods in the range of $[50000 \mu s - 7500000 \mu s]$; and a utilization load of each task in the range of $[0.01 - 0,3]$.
\end{enumerate}

These task-set are the same that were used in the earlier experimental evaluation. Instead of representing the deadline range in millisecond ($ms$), we present the values in microseconds ($\mu s$). This has been done so that the overhead numbers can be matched with the total task execution costs for a fairer comparison.

In order to measure the overheads in ChronOS, we instrument the Linux kernel and capture various triggers such as, task migration and global scheduling; and use the \texttt{read\_tsc()} call to get the time with a nanosecond granularity. We measure the overheads for each task-set over an increasing utilization load. We find that that average task migration overhead in ChronOS is $8 \mu s$, with a standard deviation of $3 \mu s$.

Figure~\ref{fig:4C-OH-GGUA-VARU} shows the scheduling overheads for G-GUA under a variable utilization load for task-sets with 5, 12 and 27 tasks, respectively. The time is presented in microseconds within a $[0-40]\mu sec$ range. We observe that with increasing number of tasks, the total scheduling overhead of G-GUA increases. At a 400\% utilization load, we observe that when the number of tasks are increased from 5 to 27, the average scheduling overhead increases from $10 \mu s$ to $17 \mu s$. Similarly at 800\%, we observe that the average scheduling overhead increases from $11 \mu s$ to $30 \mu s$. 

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./overhead/4C-OH-GGUA-VARU}
  \caption{Scheduling overheads for G-GUA under variable utilization load}
  \label{fig:4C-OH-GGUA-VARU}
\end{figure}

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./overhead/4C-OH-NGGUA-VARU}
  \caption{Scheduling overheads for NG-GUA under variable utilization load}
  \label{fig:4C-OH-NGGUA-VARU}
\end{figure}

On the other hand, we observe that the non-greedy-GUA has a lesser overhead than the greedy variant. Figure~\ref{fig:4C-OH-NGGUA-VARU} shows the results for NG-GUA. The average scheduling overhead increases as the number of tasks in the system are increased but the overhead is lower than that of G-GUA. At 100\% utilization load, NG-GUA has around $5 \mu s$ scheduler overhead as compared to $10 \mu s$ for G-GUA. However, at 800\% utilization load, we observe that the average scheduler overhead increases to around $15 \mu s$ for the 27 task-set as compared to $30 \mu s$ for G-GUA. The high overhead of G-GUA is expected as it is more aggressive while trying to maximize the accrued utility when compared to NG-GUA.

%\begin{figure} [htbp]
%  \centering
%  \includegraphics[scale=1]{./overhead/4C-OH-GGUA-NGGUA-5T}
%  \caption{G-GUA vs. NG-GUA, Scheduling Overhead Comparison, 5T, Variable Utilization Load}
%  \label{fig:4C-OH-GGUA-NGGUA-5T}
%\end{figure}
%
%\begin{figure} [htbp]
%  \centering
%  \includegraphics[scale=1]{./overhead/4C-OH-GGUA-NGGUA-27T}
%  \caption{G-GUA vs. NG-GUA, Scheduling Overhead Comparison, 27T, Variable Utilization Load}
%  \label{fig:4C-OH-GGUA-NGGUA-27T}
%\end{figure}

\begin{figure} [htbp]
  \centering
  \includegraphics[scale=1]{./overhead/4C-OH-GGUA-NGGUA-VART}
  \caption{G-GUA vs. NG-GUA, scheduling overheads with variable number of tasks}
  \label{fig:4C-OH-GGUA-NGGUA-VART}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1]{./overhead/4C-OH-100U-VART}
  \caption{Comparison of scheduling overheads at 100\% utilization load}
  \label{fig:4C-OH-100U-VART}
\end{figure}

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1]{./overhead/4C-OH-800U-VART}
  \caption{Comparison of scheduling overheads at 800\% utilization load}
  \label{fig:4C-OH-800U-VART}
\end{figure}

Figure~\ref{fig:4C-OH-GGUA-NGGUA-VART} compares both NG-GUA and G-GUA overheads at 100\% and 800\% utilization loads, with an increasing number of tasks. As the number of tasks in the system increase, the average scheduling overhead for NG-GUA and G-GUA increases. As mentioned earlier, NG-GUA observes lesser overhead as compared to G-GUA. In Figures~\ref{fig:4C-OH-100U-VART} and~\ref{fig:4C-OH-800U-VART}, we compare the scheduling overheads of NG-GUA and G-GUA with G-EDF and G-NP-EDF. It can be seen that during 100\% utilization loads, G-EDF has similar overheads like our algorithms. G-NP-EDF, on the other hand, has a lower scheduler overhead when compared with the other algorithms. However, we observe that during 800\% utilization load, G-NP-EDF's overhead shoots up from around $1 \mu s$ during 100\% utilization load to around $35 \mu s$ under 800\% utilization load.

NG-GUA and G-GUA perform sorting of the \textit{zero in-degree} tasks based on the PIP deadlines and GVD, respectively. In our implementation of these algorithms in ChronOS, we have used a quicksort-based sorting algorithms, which has a worst-case performance cost of $O(n^2)$. As we measured the overheads using task-sets that do not use any locks, all the tasks in the ready queue are \textit{zero in-degree} and hence eligible for schedule. We observe that the total cost of sorting can be reduced if we use more optimized data structures (e.g., binomial heap has a worst case cost of $O(\log n)$ and $O(1)$ for lookup of the minimum key).

\section{Conclusions}

In this chapter, we performed a number of experiments to compare the performance of the GUA class of algorithms with other global and partitioned scheduling algorithms in the absence and presence of dependencies. 

The results indicate that G-GUA and NG-GUA perform better than other algorithms during overloads in accruing total utility. We also observe that G-GUA and NG-GUA meet more deadlines during overloads than the various deadline-based scheduling algorithms, such as G-EDF, G-NP-EDF and P-EDF.

We also measure the average scheduling overheads of the algorithms and find that for 27 tasks with periods in the range of $[50000 \mu s - 7500000 \mu s]$, NG-GUA has an average scheduling overhead of $15 \mu s$, while that of G-GUA is around $30 \mu s$. 

%%%%%%%%%PG: Old START %%%%%%%%%
%In this thesis we addressed the problem of scheduling real-time tasks on multiprocessors. Specifically, we investigated the possibility of providing best-effort utility accrual real-time scheduling in the presence of dependencies (such as locks). Our primary focus was scheduling on multiprocessor systems where the total task utilization demand, $U$, is greater than $m$, the number of processors in the system, with such a system referred to as overloaded; otherwise, the system is said to be underloaded.
%
%We realized that most of the past research in real-time scheduling has been focused on providing real-time assurances during underloads, where the total task utilization is below the full system processing capacity. The deadline-based algorithms, such as G-EDF, P-EDF, or fixed priority-based algorithms, such as RMA, DMA, provide utilization bounds of $\approx m/2$, which performs well for real-time applications that utilize such system restrictions. All of these works exclude any run-time exigencies and consequent transient/permanent overloads---i.e., they presume that it is possible to determine the worst-case execution-time behaviors of applications (e.g., task arrival behaviors, task worst-case execution times), determine the total task utilization demands, and thus conduct off-line task schedulability. However, there are some applications~\cite{Wishper,Clark_anadaptive,multimedia} and systems, such as those which perform resource management,  where it is difficult to determine such worst-case  execution-time behaviors \textit{a priori}, as they are subject to run-time exigencies, such as execution time overruns and unpredictable thread arrival patterns, causing transient and permanent overloads. 
%
%Our research indicates that it is possible to create polynomial-time heuristic algorithms that provide a graceful timeliness degradation and best-effort timing assurances for dependent tasks during overloads. Our research contributes in providing a set of such scheduling algorithms that provide better utility accrual when compared to other algorithms in their class. They key idea is to ensure mutual exclusion while maximizing the total accrued utility. To achieve this, we represent the real-time tasks, that are eligible for schedule, as a directed acyclic graph, with edges between nodes representing resource dependencies, and only consider the \textit{zero in-degree} tasks for the final schedule. Our experimental evaluation of these algorithms indicates a performance improvement in the overall accrued utility during overloads, in the presence of dependencies. This is the first time any utility accrual multiprocessor real-time scheduling algorithm has been designed which provides better-effort utility accrual with dependent tasks.
%
%However, the improved utility accrual of such an approach comes with a price of higher scheduling overheads. We realize an asymptotic cost of $O(mn^2)$ that might restrict the use of these algorithms on systems that tolerate higher overheads. However, as mentioned earlier, such systems and applications have been seen to have huge execution timescales, from several milliseconds to seconds. This allows them to tolerate scheduling algorithms with higher overheads.
%
%\section{Contributions}
%
%In this thesis, we have studied the problem of multiprocessor real-time scheduling for overloaded systems in the presence of dependencies. The main contribution of our research has been the design of the GUA class of algorithms -- NG-GUA and G-GUA. These algorithms ensure mutual exclusion, deadlock detection/resolution through a cycle-detection algorithm and scheduling heuristics to provide best-effort utility accrual with or without dependencies. NG-GUA and G-GUA are differentiated by the amount of utility that each of these algorithm accrue during an overload. We create NG-GUA (Non-Greedy-GUA),  such that it respects deadline assignment during underloads, by defaulting to G-EDF, while providing a best-effort utility accrual. On the other hand, G-GUA tries to accrue higher utility at all times and hence is called Greedy-GUA.
%
%Another contribution of this thesis has been the design and implementation of the ChronOS real-time Linux kernel, which has been used to implement and evaluate all the scheduling algorithms considered in this thesis. ChronOS is based on the \texttt{PREEMPT\_RT} patch and provides a scheduling framework for implementation and evaluation of a broad range of real-time scheduling algorithms including utility accrual-, non-utility accrual-, global and partitioned algorithms.

%%%%%%%%%PG: Old END %%%%%%%%%

\chapter{Conclusions and Future Work}\label{chap:conclusion}
\markright{Piyush Garyali \hfill Chapter~\ref{chap:conclusion}.
Conclusions and Future Work
\hfill}

%%BR: First a summary of the work:
In this thesis, we addressed the problem of real-time scheduling on multiprocessors, focusing on applications that are subject to run-time uncertainties causing overloads, and task dependencies --- a previously open problem. The thesis presents the GUA class of algorithms for this problem. Since the problem is NP-hard, the algorithms are polynomial-time heuristics. The algorithms construct a directed acyclic graph representation of the task dependency relationship, and build a global multiprocessor schedule of the zero in-degree tasks to heuristically maximize the total accrued utility and ensure mutual exclusion. Deadlocks are detected through a cycle-detection algorithm, and resolved by aborting a task in the deadlock cycle. The GUA class of algorithms include the NG-GUA and G-GUA algorithms. The two algorithms differ in the way schedules are constructed towards meeting all task deadlines, when possible to do so. We establish several properties of the algorithms including conditions under which all task deadlines are met, satisfaction of mutual exclusion constraints, and deadlock-freedom. 

We also create a Linux-based real-time kernel for multiprocessors called ChronOS, which is extended from the \texttt{PREEMPT\_RT} real-time Linux patch. ChronOS provides optimized interrupt service latencies and real-time locking primitives (by virtue of the \texttt{PREEMPT\_RT} patch), and provides a scheduling framework for the implementation of a broad range of real-time scheduling algorithms, including utility accrual, non-utility accrual, global, and partitioned scheduling algorithms. 

We implement the GUA class of algorithms and their competitors in ChronOS and conduct experimental studies. Our study reveals that ---
\begin{asparaenum}[(1)]
	\item In the absence of dependencies, the GUA class of algorithms accrue higher 
	utility and satisfy greater number of deadlines than the deadline-based algorithms 
	(G-EDF, G-NP-EDF) by as much as 750\% and 600\%, respectively.
	\item In the absence of dependencies, the GUA class of algorithms accrue higher
	utility and satisfy greater number of deadlines compared to the partitioned algorithms
	by as much as 90\% and 75\%, respectively for P-DASA; and 450\% and 600\%,
	respectively for P-EDF.
	\item As gMUA defaults to NG-GUA without dependencies, the performance of NG-GUA
	and gMUA is similar.
	\item G-GUA outperforms NG-GUA and gMUA by accruing 25\% more utility, 
	while both NG-GUA and gMUA satisfy 5\% more deadlines during underloads than G-GUA.
	\item In the presence of dependencies, both NG-GUA and G-GUA accrue higher utility and
	satisfy greater number of deadlines than G-NP-EDF-PIP by as much as 250\% and 150\%, respectively.

\end{asparaenum}

%%BR: Now on to real conclusions:
Our research demonstrates that it is possible to design scheduling algorithms for the dynamic, multiprocessor real-time scheduling problem space (i.e., those characterized by execution overruns, unpredictable task arrivals, etc.), such that they yield an optimal timeliness behavior (e.g., meeting all deadlines; obtaining maximum total utility), when total utilization demand does not exceed the algorithms' utilization bound, and a best-effort timeliness behavior at all other times.

This approach was pioneered in the Alpha OS kernel~\cite{jn90}, which included two generations of TUF/UA scheduling algorithms for scheduling single-processor systems~\cite{loc86, DASA}. At its core, this thesis demonstrates that a similar approach can also be successfully extended for multiprocessors. The key challenge in doing so is the construction of $m$-processor schedules with best-effort timeliness behavior during overloads ($U > m$) with or without dependencies, that seamlessly yield optimal timeliness behavior during underloads ($U \leq m$) without dependencies. This is a difficult problem because, deadline scheduling is non-optimal for multiprocessors, unlike that for single-processors (for which deadline scheduling is optimal). In particular, global EDF has a utilization bound of $\approx m/2$ (without dependencies). Thus, using deadline schedulers as the basis for multiprocessor TUF/UA scheduling, as done in Alpha's TUF/UA schedulers~\cite{loc86, DASA} for the single-processor case, will result in loss of utilization---e.g., with global EDF as the basis, as is the case with NG-GUA, ``overloads" start at $\approx m/2$. Optimal multiprocessor real-time schedulers are either quantum-based (e.g., the Pfair class of algorithms)~\cite{pfair1} or are strongly dependent upon presumptions made about task arrival and task execution-time behaviors  (e.g., periodic/sporadic arrivals, WCETs)~\cite{cho_llref, chen08, Funaoka08}. Thus, it is very difficult to seamlessly extend them to have best-effort timeliness behaviors for the dynamic problem space, where tasks may have execution overruns and unpredictable arrivals. The thesis therefore designs NG-GUA with global EDF as its basis (suffering from this utilization loss), and G-GUA as an alternative solution without global EDF as its basis and one that greedily constructs schedules at all times. Designing multiprocessor TUF/UA scheduling algorithms with utilization bounds that are greater than $\approx m/2$ is a direction for future work.

In addition, the presence of task dependencies can result in many task dependency chains, similar to the single-processor case. But unlike the single-processor case, since there are $m > 1$ processors, for the multiprocessor case, up to $m$ of these chains (or tasks at the head of those chains) can potentially be executed. In~\cite{DASA}, the dependency chains are computed at the per task level. This works well for the single-processor case as only one task needs to be selected at the end of schedule. However, we can not take this method and apply it to the multiprocessor case because to ensure mutual exclusion we can not execute tasks on processors that depend on each other. Hence, we need to find the dependency relationship of all the tasks. The challenge is to find out the most effective way in which this can be done. In the design of the GUA algorithms, we solve this problem by creating a directed acyclic graph to represent the dependency relationship between tasks. Thus, at the end of the graph creation, we can consider the zero in-degree nodes, which are not dependent on other tasks, as eligible for the final schedule.

However, which $m$ head tasks (or zero in-degree tasks) should have the highest execution eligibility? The potential utility density (or PUD) metric pioneered in~\cite{DASA} is shown to be highly effective in determining task execution eligibility for the single-processor case. But how can we determine task potential utility densities when similar tasks can appear in the dependency chains of several tasks? Unlike the single processor case, here, many tasks can be concurrently dispatched for execution. The PUD metric works in~\cite{DASA} for the single-processor case as a single task needs to be selected at the end of the schedule. However, on the multiprocessor case we can not use the PUD metric alone in order to pick one task over another. This is because there could be a zero in-degree task $T_i$ that owns a resource $R_j$ and blocks other tasks in the system, but has a low PUD value. As a result, (due to the low PUD value), $T_i$ would always be pushed to the back of the queue, thus preventing other tasks that are currently blocked on it from executing. The challenge here is to find a metric that provides a way to represent the overall benefit the system can accrue if a particular task, say $T_i$, is selected for execution. We answer this question in the design of the GUA class of algorithms by defining a metric called the Global Value Density (or GVD). The GVD for a zero in-degree task represents the aggregate value density for the entire dependency chain, which gives a fair representation of the dependency chain and thus provides the highest execution eligibility for a task that is currently blocking other tasks.

The GUA class of algorithms have higher scheduling costs than past multiprocessor real-time scheduling algorithms. The asymptotic cost of G-GUA is $O(m n\log n)$ and NG-GUA is $O(m n\log n)$ for $n$ tasks on $m$ processors. In contrast, the asymptotic cost of gMUA is $O(m n \log n)$, G-EDF is $O(n \log n)$ and P-EDF is $O(n \log n)$. On our four-core platform, the worst-case and average-case scheduling overheads of G-GUA for 27 tasks at 800\% utilization load were $80 \mu s$ and $30 \mu s$, respectively, while those for NG-GUA were $45 \mu s$ and $15 \mu s$, respectively. We observe an average $8 \mu s$ migration cost. Thus, the GUA class of algorithms are effective only if the application can tolerate their higher scheduling overheads. Designing multiprocessor TUF/UA scheduling algorithms with smaller scheduling costs is another important direction for future work.

\section{Contributions}

To summarize, the research contributions of the thesis include:
\begin{enumerate}
	\item the GUA class of multiprocessor real-time scheduling algorithms that allow tasks to be subject to run-time uncertainties, overloads, and dependencies, and yield optimal total utility when possible and best-effort timeliness behavior otherwise --- the first such multiprocessor real-time scheduling algorithms to do so.
	\item the ChronOS multiprocessor real-time Linux kernel that provides optimized interrupt service latencies and real-time locking primitives (by virtue of \texttt{PREEMPT\_RT} patch) and a scheduling framework that allows the implementation of a broad range of real-time scheduling algorithms, including utility accrual, non-utility accrual, global, and partitioned scheduling algorithms -- the first such multiprocessor real-time Linux kernel.
\end{enumerate}

%%%%%%%%% BR stopped here on 7/13 %%%%%%%%%%%%%%%%%%%%%%%%%

\section{Future Work}

Although, our results in this thesis show that NG-GUA and G-GUA provide improvements in the overall accrued utility, there are some open research problems that can be used to optimize this performance further. Below, we enumerate some of these.

\subsection{Parallelizing Schedule Creation}
	
		The current approach used by the GUA class of algorithms is to create a global schedule for all available
		processors in the system at every scheduling event. This has been implemented in ChronOS
		as the ``Stop-the-World" model. In this architecture model, the processor creating the 
		global schedule sends an \texttt{IPI} to all the other processors to stop what they are doing
		and enter the scheduler. 
		
		For global scheduling algorithms, such as NG-GUA and G-GUA, it is necessary to 
		have all the processors wait until the creation of the new schedule to avoid 
		schedule complications. This is primarily because the GUA class of algorithms use the 
		heuristic of Global Value Density which is calculated based on a task's remaining execution
		cost. However, while all the processors are blocked before the final schedule is available, we
		can optimize the GUA class of algorithms such that the creation of the final schedule 
		uses all the available processors. One approach of doing this is for the scheduling algorithm to
		create jobs that can be assigned to worker threads dedicated for scheduling on each of the processors.
		
		At this point, it is not known if this approach would provide any additional optimization benefits
		to the overall performance of the GUA class of algorithms; or if the parallel approach
		would scale with the increase in the number of processors. We propose the future work to
		consider the design of a parallel versions of the GUA class of algorithms.
		
\subsection{Reducing Scheduling Overheads}
		
		The current asymptotic cost of the GUA class of algorithms is $O(m n\log n)$. This is primarily 
		because the algorithms require the list of \textit{zero in-degree} tasks to be sorted either
		by deadline or by the GVD. In the current design and implementation of the algorithms, we
		have used quicksort-based sort which suffers from a worst-case performance penalty of $O(n^2)$,
		thus contributing to the main overhead cost of the algorithms. We propose the future work to 
		design TUF/UA scheduling algorithms with a lesser scheduling overheads.
		
\subsection{Cache-Aware Algorithms}
		
		One of the most important aspects of global scheduling algorithms is to be able to assign
		tasks to processors such that cache warm-up issues and task migrations 
		from one processor run-queue to another are avoided. This happens when the final schedule created by the 
		algorithms have tasks that belong to the same processor.
		
		We implement a default mapping algorithm in ChronOS that assigns tasks from the final schedule to processors 
		based on their origin. However, if the final schedule has tasks that belong to the same
		processor, the mapping algorithm suffers a worst-case task migration cost
		of $m-1$, for a $m$ processor system. 
		
		We propose the future work to look at two ways in which this problem can be solved --
		\begin{inparaenum}[(i)]
			\item provide a better mapping algorithm in ChronOS; or
			\item ensure that the scheduling algorithm is cache-aware~\cite{guan-cache-aware, calandrino-cache}. 
		\end{inparaenum}
		Stenstr\"om provides a survey of various cache coherence schemes on multiprocessors in~\cite{CCMultiproc}.
		

\subsection{Approximate Algorithms}
		
		As mentioned earlier, the problem of scheduling real-time dependent tasks on multiprocessors is NP-Hard.
		In this thesis, we present polynomial-time real-time scheduling heuristics algorithms (NG-GUA and G-GUA)
		that yield optimal total utility when possible and best-effort timeliness behavior otherwise.
		
		Another	approach of solving this problem is to consider the design of approximate
		algorithms instead of a heuristic approach by defining it as an optimization problem. We believe that
		the results presented in this thesis can provide a useful insight to the overall performance and can
		be used as an input while designing an approximate algorithm. We propose this as a future work.
 
\appendix
%\appendixpage
%\addappheadtotoc

\chapter{ChronOS System Calls}\label{appendix-cos-sys}
\markright{Piyush Garyali \hfill Appendix~\ref{appendix-cos-sys}.
ChronOS System Calls
\hfill}


In code listing~\ref{code:cos-syscalls}, we show the ChronOS system calls related to the real-time scheduling that were added to 2.6.31.12 Linux kernel. The system calls related to Distributed Threads have been omitted due to the lack of context with the research contributions of this thesis.
~\\

\begin{lstlisting}[caption=The ChronOS system calls added to the Linux 2.6.31.12 kernel, label=code:cos-syscalls]
/* Set the real-time scheduler */
long sys_set_scheduler(int rt_sched,
					   int prio,
				  	   unsigned int len,
					   unsigned long __user *user_mask_ptr);

/* Begin a real-time segment */
long sys_begin_rt_seg(struct rt_data __user * data,
					  struct timespec __user *deadline,
					  struct timespec __user *period);

/* End a real-time segment */			  
long sys_end_rt_seg(int tid, int newprio);

/* Request/Release locks */
long sys_do_vt_rt_mutex(struct mutex_data __user *mutexreq, int op)

/* Add an abort handler to a real-time task */
long sys_add_abort_handler(int tid,
						   int max_util,
						   struct timespec __user *deadline,
						   unsigned long exec_time)

/* Perform atomic operations */
long sys_atomic_int_op(int __user *resource, int op, int val)
\end{lstlisting}

\chapter{ChronOS Kernel Data Structures}\label{appendix-cos-ds}
\markright{Piyush Garyali \hfill Appendix~\ref{appendix-cos-ds}.
ChronOS Kernel Data Structures
\hfill}

In this section. we show the data structure that were added to the 2.6.31.12 Linux kernel for real-time scheduling. The data structures related to Distributed Threads have been omitted due to the lack of context with the research contributions of this thesis.
~\\

\begin{lstlisting}[caption= Data structure used to define locks, label=code:mutex-data]
struct mutex_data {
	atomic_t val;
	int owner;
};
\end{lstlisting}

\begin{lstlisting}[caption=Data structure used for abort handlers, label=code:abort]
struct abort_info {
	struct timespec deadline;
	unsigned long exec_time;
	int max_util;
	struct sigqueue *abort_sig;
};
\end{lstlisting}

\begin{lstlisting}[caption=Data structure for the DAG representation of the dependency chain, label=code:dag]
struct rt_graph {
	struct timespec agg_left;
	unsigned long 	agg_util;
	long global_ivd;
	long in_degree;
	long out_degree;
	struct rt_info *neighbor_list;
	struct rt_info *next_neighbor;
	struct rt_info *parent;
	struct rt_info *depchain;
};
\end{lstlisting}

\begin{lstlisting}[caption=The ChronOS main real-time data structure, label=code:rtinfo]
/* Structure attached to struct task_struct */
struct rt_info {
	/* Real-Time information 
	 * 
	 * start_time is the start time of the rt segment, not to be confused
	 * with struct task_struct.start_time, which is the creation time
	 * of the thread.
	 */
	struct timespec start_time;		/* monotonic time */
	struct timespec deadline;		/* monotonic time */
	struct timespec temp_deadline;		/* monotonic time */
	struct timespec period;			/* relative time */
	struct timespec left;			/* relative time */
	unsigned long exec_time;		/* WCET, us */
	int max_util;
	long inv_val_den;

	/* Lists */
	struct list_head g_task_list;
	struct list_head local_task_list;
	struct list_entry list[SCHED_LISTS];

	/* DAG used by x-GUA class of algorthims */
	struct rt_graph graph;	

	/* Lock information */
	struct mutex_data *requested_resource;
	struct rt_info *dep;
	int lock_count;

	/* Abort information */
	struct abort_info abortinfo;

	/* Task state information */
	unsigned char flags;
	int cpu;
};
\end{lstlisting}

\pagebreak

\begin{lstlisting}[caption=Scheduler plugin for single-processor schedulers, label=code:localplug]
struct rt_sched_local {
	struct list_head list;
	/* Scheduler Name */
	char *name;
	/* Scheduling number and flags */
	int number;
	int flags;
	/* Scheduling function */
	struct rt_info* (*schedule) (struct list_head *head, int flags);
};
\end{lstlisting}

\begin{lstlisting}[caption=Scheduler plugin for multiprocessor schedulers, label=code:globalplug]
struct rt_sched_global {
	struct list_head list;
	/* Scheduler Name */
	char *name;
	/* Scheduling number and flags */
	int number;
	int flags;
	/* Scheduling functions */
	struct rt_info* (*schedule) (struct list_head *head, int flags, int cpus);
	struct rt_info* (*preschedule) (struct list_head *head, int flags);
	int (*arch_init) (void);
	void (*arch_release) (void);
	void (*block) (void);
	int (*map_tasks) (struct rt_info *head);
	/* The local scheduler to be used with this global */
	int local;
};
\end{lstlisting}

%\chapter{Pseudo-code for Auxiliary Functions}\label{appendix-aux}

\chapter{Sample ChronOS Scheduling Kernel Modules}\label{appendix-sample}
\markright{Piyush Garyali \hfill Appendix~\ref{appendix-sample}.
Sample ChronOS Scheduling Kernel Modules
\hfill}

In code listing~\ref{code:sample-edf}, we show a sample kernel module used to implement the EDF scheduling algorithm in ChronOS. EDF is a uniprocessor scheduling algorithm. Hence, we use the scheduling plugin for local schedulers in ChronOS.
~\\

\begin{lstlisting}[caption=Sample kernel module for EDF, label=code:sample-edf]
#include <linux/module.h>
#include <linux/list.h>

struct rt_info* sched_edf(struct list_head *head, int flags)
{
	/* Scheduling logic here */
	return task;
}

struct rt_sched_local rt_sched_edf = {
	.name = ``EDF'',
	.number = SCHED_RT_EDF,
	.flags = 0,
	.schedule = sched_edf
};

struct rt_sched_local *edf = &rt_sched_edf;

static int __init edf_init(void)
{
	return add_local_scheduler(edf);
}
module_init(edf_init);

static void __exit edf_exit(void)
{
	remove_local_scheduler(edf);
}
module_exit(edf_exit);

MODULE_DESCRIPTION(``description'');
MODULE_AUTHOR(``name'');
MODULE_LICENSE(``GPL'');
\end{lstlisting}

In code listing~\ref{code:sample-nggua}, we show a sample kernel module used to implement the NG-GUA scheduling algorithm in ChronOS. NG-GUA is a multiprocessor, global scheduling algorithm which uses the Stop-the-World architecture model. Hence, we use the scheduling plugin for global schedulers in ChronOS.
~\\
\begin{lstlisting}[caption=Sample kernel module for NG-GUA, label=code:sample-nggua]
#include <linux/module.h>
#include <linux/list.h>

struct rt_info * presched_nggua(struct list_head *head, int flags)
{
	/* Pre-scheduling logic here */
	return NULL;
}

struct rt_info * sched_nggua(struct list_head *head, int flags, int cpus)
{
	/* Scheduling logic here */
	return NULL;
}

struct rt_sched_global rt_sched_nggua = {
	.name = ``NG_GUA'',
	.number = SCHED_RT_NGGUA,
	.flags = 0,
	.schedule = sched_nggua,
	.preschedule = presched_nggua,
	.arch = &rt_sched_arch_stw,
	.local = SCHED_RT_FIFO_RA
};

struct rt_sched_global *nggua = &rt_sched_nggua;

static int __init nggua_init(void)
{
	return add_global_scheduler(nggua);
}
module_init(nggua_init);

static void __exit nggua_exit(void)
{
	remove_global_scheduler(nggua);
}
module_exit(nggua_exit);

MODULE_DESCRIPTION(``description'');
MODULE_AUTHOR(``name'');
MODULE_LICENSE(``GPL'');
\end{lstlisting}

\newpage
\markright{Piyush Garyali \hfill Bibliography \hfill}

\bibliographystyle{abbrv}
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{DistSys}

\end{document}
