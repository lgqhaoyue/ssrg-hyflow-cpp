\documentclass[12pt,english]{report}

\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.5in}
\setlength{\evensidemargin}{0in}
\setlength{\oddsidemargin}{0in}
\setlength{\topmargin}{0in}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0.1in}

\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

%% A simple dot to overcome graphicx limitations
\newcommand{\lyxdot}{.}

% Uncomment for double-spaced document.
\renewcommand{\baselinestretch}{1}

% \usepackage{epsf}
\usepackage{graphicx}
\usepackage{listings}\lstset{
language=C++,                   % choose the language of the code
basicstyle=\footnotesize,       % the size of the fonts that are used for the code
numbers=left,                   % where to put the line-numbers
numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
stepnumber=1,                   % the step between two line-numbers. If it's 1 each line will be numbered
numbersep=5pt,                  % how far the line-numbers are from the code
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
%frame=single,	                % adds a frame around the code
tabsize=4,		                % sets default tabsize to 2 spaces
captionpos=b,                   % sets the caption-position to bottom
breaklines=true,                % sets automatic line breaking
breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
xleftmargin=0.7cm			    % sets to stop code cut into the margin
}
\usepackage{subfigure}

\makeatother
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{babel}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,		% false: boxed links; true: colored links
	linkcolor=black,          % color of internal links
    citecolor=black,        % color of links to bibliography
    filecolor=black,      % color of file links
    urlcolor=black           % color of external links
}
\usepackage{rotating}
\usepackage{comment}
\usepackage{bbding}
\usepackage{float}
\usepackage{threeparttable}
\usepackage{amsthm}
\newtheorem{definition}{Definition}[section]



\begin{document}

\thispagestyle{empty}
\pagenumbering{roman}
\begin{center}

% TITLE
{\Large 
HyflowCPP : A Distributed Transactional Memory framework for C++
}

\vfill

Sudhanshu Mishra

\vfill

Thesis submitted to the Faculty of the \\
Virginia Polytechnic Institute and State University \\
in partial fulfillment of the requirements for the degree of

\vfill

Master of Science \\
in \\
Computer Engineering


\vfill

Binoy Ravindran, Chair \\
Robert P. Broadwater \\
Mark Jones


\vfill

January 28, 2013 \\
Blacksburg, Virginia

\vfill

Keywords: Distributed Software Transactional Memory, Transactional Framework, C++, Concurrency
\\
Copyright 2012, Sudhanshu Mishra

\end{center}

\pagebreak

\thispagestyle{empty}
\begin{center}

{\large
HyflowCPP : A Distributed Transactional Memory framework for C++
}

\vfill

Sudhanshu Mishra

\vfill

(ABSTRACT)

\vfill

\end{center}

To Be Added




\vfill

% GRANT INFORMATION

% This work was partially supported by the US National Science Foundation.


\pagebreak

% Dedication and Acknowledgments are both optional
\chapter*{Dedication}

\begin{center}
I dedicate this thesis to my family and friends.

\textit{Without their support this would not have been possible}

\end{center}


\chapter*{Acknowledgments}

I would like to thank my advisor, Dr. Binoy Ravindran, for his 
help and guidance on both technical and personal 
topics. It has been an honor to work under him and I am highly thankful
to him for his trust in me.

I would also like to thank Dr. Robert Broadwater and Dr. Mark Jones,
for serving on my committee and providing their valuable feedback
and direction. In addition, I would like to thank all of my colleagues
at the Systems Software Research lab. I would particularly like to thank
Alex Turcu, Mohd. Saad and Aditya Dhoke for their support and encouragement.
It was a pleasure to work with them and perform interesting research in area 
of Distributed Transactional Memory.

Finally, I would like to thank my family and friends for all the
love and support they have given me, without which this thesis would 
not have been possible.

\tableofcontents
\pagebreak

\listoffigures
\pagebreak

%\listofalgorithms
%\pagebreak

\listoftables
\pagebreak

%\printnomenclature
%\pagebreak

\pagenumbering{arabic}
\pagestyle{myheadings}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%																									%
%							CHAPTER 1	:	INTRODUCTION						%
%																									%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}\label{chap:intro}
\markright{Chapter~\ref{chap:intro}.
Introduction
\hfill}

In current digital age, as Moore's law~\cite{schaller1997moore} is approaching towards scaling limit, and processor clocks are hitting the power wall, chip manufacturers are progressively endowing the multi-core CPU architecture. Augment in computation performance by increasing processor clock rate and transistor scaling is no more a feasible options. Experts believe further performance improvements can be achieved through, writing the software to explicitly exploit the hardware parallelism. 

Writing the concurrent software code is a daunting task a ordinary programmer. Such code requires a proper synchronization and co-ordination different parallel parts. Lock based synchronization is often used synchronization abstraction. Coarse grain locking is simple to implement, protects the concurrent code by locking over large critical section, permits the little concurrency. On other hand the fine grain locking is efficient and reduce the large critical section is various small parts to provide to maximum concurrency. However, implementing such fine grained locks is highly complex and prone to programmer errors. Such lock based implementations have inherent problems such as deadlocks, livelocks, lock convoying, and priority inversion. Additionally, lock based synchronization does not support code composability. For instance, a thread safe data structure may support atomic insertion or removal of elements using some internal lock mechanism. However, a user might require to remove a element from one collection and insertion in another. Such operations can not be performed atomically using providing lock mechanism in data structure and will require to implement additional locking support to lock multiple data structure at same time. These issues with locks make concurrent code difficult to understand, program and maintain.

Complications with lock based systems increase manifold in case of distributed systems where multi-core processors are connected to each other over network. All locked based issues like deadlocks and livelocks become more severe as resolving such issue becomes more costly and error prone over network. In addition, lack of composability makes it difficult to support any replication or backup mechanism for failure  prone links.    

Transactional Memory is a alternative abstraction to lock based synchronization. It aims to simplify the development of concurrent programs by alleviating the inherent issues with locks. Transaction Memory liberates the programmer from arduous task of maintaining the locks. It allows the programmer to identify the  sequence of instruction required to executed in isolation and executes that atomically as a transaction. This approach have been very successful in databases and slowly getting accepted in concurrent programming. Transactions are executed in transparent manner and commit atomically based on consistency constrain defined by system. Transactions generally maintain a set of read and write objects to verify the consistency constrain at commit time. In case of conflict at commit time, transaction is abort and retried later.      
%stopped

To overcome the distributed concurrency synchronization challenges the a transactional memory interfaces are enhanced to support transactions over network. Distributed Transactional Memory(DTM) is a promising model to extract the high performance from multiple core connected over network. Objective of DTM is not only to resolve the concurrency issues related to distributed concurrency, but also to support scalability and decentralization of resources to improve overall reliability of systems. From programmers prospect DTM follows the traditional validation and commit approach used in Transactional Memory. In addition to that it provides the user various methods to access the distributed object over the network. 

\section{Transactional Memory Properties}

Before describing the Distributed Transaction Memory(DTM) in more details, we introduce various transactional memory properties. Knowledge of these transactional memory properties are essential to understand various research works in DTM area.

\subsection{Memory Consistency Models}

A \textit{memory consistency} model is an agreement between the framework and programmer that specifies the memory access rules. It ensures that memory remain consistent and predictable after different memory operations. If programmer follows these rules, memory consistency is guaranteed by framework. These operation are generally provided in low level semantics like read and write data or compare and swap. Now we describe few memory consistency model which are often used in DTM frameworks.

\textit{Serializability} is a strong consistency requirement and requires all transactions to execute in a complete isolation i.e., all transactions in the system should execute in a way, which is equivalent to a serial order. Two or more transactions can execute at the same time only if the equivalence to a serial execution can be maintained. For achieving high performances, many times supporting the serializability proves a very strong guarantee to provide. In recent years many researchers have focused on weaker consistency models, like Snapshot Isolation, Extended Update Serializability and Eventual Consistency etc.

In \textit{Snapshot Isolation} a transaction takes a personal snapshot of the database at the start of the transaction. When the transaction finish, it commits only if the values of the items in its personal snapshot have not been updated by other committed transactions. \textit{Extended Update Serializability} unlike 1-Copy Serialization allows concurrent read-only transactions to observe snapshots generated from different linear extensions of the history of update transactions. \textit{Eventual Consistency} guarantees that if no new updates are made to system for a period of time, all values in the system will be updated to most recent values.

Even though weaker consistency models provide high performance by relaxing the serializability, it forces programmers to embrace such relaxed consistency models. Such models typically come as a big challenge for ordinary programmers, as they are required to understand all the subtleties of complicated consistency properties, to avoid any sanity failure.

\subsection{Concurrency Control} 

\textit{Concurrency Control} ensures that concurrent changes made by transaction do not violate the consistency model supported by system. It protects the correctness of results generated through concurrent operations with respect to consistency model. These concurrency control mechanisms often require to take to locks for a period of time. Mainly there are two types of concurrency control mechanism: Pessimistic concurrency control and optimistic concurrency control.

\textit{Pessimistic Concurrency Control}(PCC) assumes that all the data access will result in conflicts, therefore as soon as any object access is made in a transaction, locks are acquired on the object. Depending on the lock types(shared/exclusive) object may be shared with other transactions. Two phase Locking protocol~\cite{2PL:lin1983basic} is a good example of such concurrency control mechanism.  

\textit{Optimistic Concurrency Control}(OCC) assumes that although conflict are possible, but their occurrence is very rare, therefore no locks are required at time of access of data. Data manipulation is performed without acquiring any lock. Before commit a validation step is performed to check for any conflicting transaction. If any conflict is found, the current transaction is aborted and retried. OCC generally contains the four steps:

\begin{enumerate}
\item Begin: It marks the start of transaction.
\item Modify: In this step read and write operations are performed on data.
\item Validate: This step verifies whether any conflicting updates are made on accessed data.
\item Commit/Abort: Based on validation result, in this step transaction is committed or aborted.
\end{enumerate}   

\subsection{Replication}

\textit{Replication} is very common in databases and mostly used for backup and load balancing purposes. In DTM, classical replication solution can be viewed as primary/backup model, where primary have authoritative object copy and used to update all backup copies. In case of primary copy failure the backup copies are used to service the transactions. This switch from primary to backup copies creates many problems for the transactions in progress, at the time failure. Many systems send log updates to backup copies, to allow in-progress transactions, to continue from certain logged state. Many times Replication is also viewed as tool for DTM to increase performance through localization.

\subsection{Strong Atomicity}

\textit{Strong atomicity} is a transactional semantics, which hides any inconsistent state of system from non-transactional code. In essence, the strong atomicity treats the non-transactional code executing in its own singleton atomic transaction. This behavior stops the user code to access any unprotected shared variables outsides the transactional code. In comparison to strong atomicity \textit{ Weak atomicity} executes the transactional code atomically with reference to other transactional code only. The non-transactional code can still access the shared variables in inconsistent state. Stronger atomicity help the programmer by removing any potentially buggy interleavings. HyflowCpp framework provides strong atomicity for user code.     

\section{Transactional Models}

In DTM, various transactional models are available, which provide different mechanisms to improve performance . ~\emph{Nesting} is one of the famous model to perform partial aborts, and to add composability to user code. A transaction is nested when it encloses some other transaction. There are different transactional  models, which are studied: ~\emph{Flat}, ~\emph{Checkpointing} ~\emph{Closed}, and ~\emph{Open}. 

\textit{Flat} nesting is the simplest form of nesting, which simply ignores the existence of transactions in inner code. All operations are executed in context of the outermost transaction. Aborting any of inner transaction cause the parent transaction to abort. Therefore no partial rollback can be performed. Flat nesting does not provide any performance incentive over non-nested transactions.

\textit{Closed} nesting allows the inner transactions to abort individually. Abort of inner transaction does not lead to abort of parent transactions. But, commit by inner transaction are not allowed to write on share memory. Inner transaction commit to internal memory of parent transaction and there commit is not visible out side of parent transaction.

\textit{Open} nesting uses the higher level of abstraction for memory access to avoid any false conflicts occurring at memory levels. It allows the inner transactions to commit or abort individually and their commits are visible globally, to all other transactions. In case of abort of outermost transaction, due to any fundamental conflict at higher abstractions, all the inner transactions are roll-backed via a predefined compensating actions for each inner transactions.

\begin{figure}
\subfigure[Flat nesting] {
\includegraphics[scale=0.6]{\string"eps/nesting-example-flat".pdf}
}
\subfigure[Closed nesting] {
\includegraphics[scale=0.6]{\string"eps/nesting-example-closed".pdf}
}
\subfigure[Open nesting] {
\includegraphics[scale=0.6]{\string"eps/nesting-example-open".pdf}
}
\subfigure[Checkpointing] {
\includegraphics[scale=0.22]{\string"eps/checkpointing-example".pdf}
}
\caption{Simple example showing the execution time-line for two transactions under different transactional model.}
\label{Fig:Nesting_example}
\end{figure}

\textit{Checkpointing} does not view a transaction as composition of multiple inner transaction, but as a process containing various states. It saves the transaction execution states at various points and uses them to partially rollback, to a valid Checkpointed state, in case of a conflict. This allows the transaction to redo the work, only for the part of transaction in which the conflict occurs. The transactions execution state is generally saved using continuation~\cite{flanagan1993essence}. In HyflowCpp we use \textit{setcontext} and \textit{getcontext} functions to save the execution states.     

Figure~\ref{Fig:Nesting_example}~\cite{Alex:ONTFA2367601} depicts the difference between various transaction models using two transactions $T1$ and $T2$. In flat nesting, on conflict at a shared data between transactions $T1$ and $T2$, $T2$ have to fully abort. $T2$ can restart later and commit, when shared data is freed at the end of $T1$'s execution. In case of closed nesting, $T2$'s inner transaction incurs an abort. But, it saves all other previously committed inner transactions from getting aborted. Inner transaction can continue as soon as the shared object is freed by $T1$. With open nesting, the aborted inner transaction of $T2$ does not require to wait till the end of $T1$ executions, as in close nesting. Instead, it can continue as soon as $T1$'s inner transaction using the shared data commits and frees the shared data. With Checkpointing, in case of conflict the transaction $T2$ can resumed from last valid Checkpoint and keep retrying until the $T1$ frees the conflicting data at end of its execution. In this way by aborting on minimum amount of conflicting work, the transaction models allow to extract high performance. 

\section{Distributed Transactional Memory}

To be added: Provide Problem statement in it.

\section{Thesis Contribution}

To be added

\section{Thesis Organization}

The rest of the thesis is organized as follows: Chapter~\ref{chap:relWork} overviews past and related work in the DTM space, and contrasts them with the thesis's problem space. Chapter~\ref{chap:progInterface} illustrates the programming model required to develop benchmarks in our framework. Chapter~\ref{chap:sysArch} describes our framework architecture and interaction between different components. Chapter~\ref{chap:algorithm} explains the TFA algorithm and its adoption in different transactional models.We report our experimental results in Chapter~\ref{chap:expResults}. Finally, we conclude the thesis in Chapter~\ref{chap:conclusion}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%																									%
%							CHAPTER 2	:	Related work						%
%																									%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Related Work}\label{chap:relWork}
\markright{Chapter~\ref{chap:relWork}.
Related Work
\hfill}

In this chapter we survey the past and related work focusing on the problem of distributed transactional memory. For our discussion purpose, we classify the past and current work in DTM based on different transactional properties:

\begin{enumerate}
\item Serializability
\item Non-Serializability 
\item Replication 
\item Strong Atomicity
\item Transaction Models
\end{enumerate}

In each section we describe the various research works and related transactional property definitions. In last section we also describe recent developed various unconventional systems.

\section{Serializable DTM implementations}

In previous chapter~\ref{chap:intro}, we have intuitively described \textit{Serializability} property. Here we provide a formal definition of Serializability. 

\begin{definition}[\textbf{Serializability}]
A set of transactions executes serially if each transaction executes its write operation before the next transaction executes its read operation. That is, the transactions are in no way interleaved. A serial execution of transactions preserves database consistency because each individual transaction preserves
database consistency. If an interleaved execution of transactions produces the same effect as a serial execution of those same transactions, then the execution is called serializable. Since a serial execution preserves consistency, a serializable execution also preserves consistency.~\cite{serializabilityFormal}
\end{definition}

In lock-based concurrency control implementation, serializability requires that locks to be acquired in certain range of execution. While in non-lock concurrency control, no lock is acquired, but if the system detects a concurrent transaction in progress it rollbacks.

One of the first work in DTM by Manassiev~\cite{Manassiev:2006:EDV:1122971.1123002}, supported the serializability. It introduced a novel page-level distributed concurrency control algorithm, called Distributed Multiversioning(DMV). DMV allows each node to keep a single local copy of the data items to read or write. At commit time page differences are broadcasted to all other replicas, and a transaction commits successfully upon receiving acknowledgments from all nodes. A central timestamp is employed, which allows only a single update transaction to commit at a time. Unfortunately, this requirement of transaction to acquire a cluster-wide unique token, which globally serializes the commit phases of transactions imposes considerable overhead and seriously hampers performance as later described by Kotselidis et. al.~\cite{Kotselidis08distm:a}.

Cluster-STM~\cite{Bocchino:2008:STM:1345206.1345242} work based on PGAS~\cite{PGAS:Programmin:Model} programming model supported serializibility. It also supported strong atomicity by imposing the programming restriction that each memory location must be accessed always within transactions or always outside transactions. In Cluster-STM, the dataset is partitioned across the nodes and each data item is assigned a home node. Home node maintains the authoritative version of data item and synchronizes the accesses of conflicting remote transactions. Being based on PGAS~\cite{PGAS:Programmin:Model} programming model Cluster-STM does not distinguish transaction that execute in the same node from the transaction that execute on a different node and pays a heavy performance penalty for not exploiting shared memory for intra-node communication.

DiSTM ~\cite{Kotselidis08distm:a} work published in 2008 uses a distributed mutual exclusion mechanism to coordinate the commit of transactions. This mechanism ensures that no two conflicting transactions try to commit simultaneously. To provide distributed mutual exclusion this protocol grants lease to nodes on datasets, based on the their data access pattern, for each transaction commit. It allows transaction to escape performance penalty incurred by serialization cost in commit phase. However, it may still become a bottleneck in contention intensive workloads. Also DiSTM suffers the scalability issues due to the single coordinating node performing lease establishment mechanism as the number of nodes increases. Due to this bottle neck DiSTM provides a dedicated node to perform lease establishment mechanism.

In 2009 Dependable Distributed Software Transactional Memory(D2STM)~\cite{D2STM:5368778} followed which utilized the Atomic Broadcast~\cite{Defago:2004:TOB:1041680.1041682} and Bloom Filter~\cite{Bloom:1970:STH:362686.362692} Certification to achieve good performance in a replicated cluster. Replication of objects allows it to execute all Read-only transactions locally without incurring in any network communication overhead. For write transactions D2STM first validates it locally and aborts if required on basis of locally available information. After validating locally, Replication Manager encodes the transaction read-set in a Bloom Filter and Atomically broadcasts it along with the transaction write-set. Even though Atomic Broadcast allowed the D2STM to support serializibility, it incurs high performance cost with increase in the number of nodes in cluster. Also, use of Bloom filter requires the prior knowledge of transaction read-set to fine tune for reduced false positives. Same research group later came up with AGGRessively Optimistic concurrency control scheme(AGGRO)~\cite{AGGRO:5598236} to address dependability issue in DTM utilizing the replication. AGGRO propagates dependencies across uncommitted transactions in a serialization order compliant with the optimistic message delivery order provided by the Optimistic Atomic Broadcast(OAB)~\cite{OAB:Pedone200379} service. Even though OAB allowed to improve performance, it also make it prone to saturation issue with the OAB group communication subsystem.  

In 2009 another work, namely, Sinfonia~\cite{Aguilera:2009:SNP:1629087.1629088} service came out which utilized the mini-transactions. The idea behind the mini-transactions was to send the transaction itself as a piggyback in first phase of two phase commit. All the transactions for which conditional value and update object exist on same node can be convert to a mini-transaction. Utilizing the mini-transaction Aguilera et. al. were able to reduce the network communication to a large extent and achieve good performance. Drawback of this approach is that we need to know the data accessed by transaction beforehand.

Cloud-TM~\cite{Romano:2010:CHC:1773912.1773914} work published in 2010 enumerated the features which can be useful to make DTM successful in providing concurrency solution over network cloud. They suggested to make DTM easily graspable by hiding Complexities and make it capable to cope up with Workload Heterogeneity. They also make a point to maximizing locality and automatic resource provisioning for a high performance and adaptability of system. They asked DTM community to support durability to survive in failure prone cloud environment. 

In 2011, based on D2STM and AGGRO work Romano et. al. came up with A Generic Framework for Replicated Software Transactional Memories(GenRSTM) ~\cite{GenRSTM:6038614}. Goals of this framework was to simplify the development and testing of new replication protocols and STMs, provide high decoupling between the architecture building blocks, and support multiple implementations of the architecture building block. This framework enabled system administrators to seek optimal performance as a function of the workload/deployment scenario by reconfiguring the replicated STM middle-ware platform, in a transparent fashion for the
user level application. It simplified the development and evaluation of alternative replication protocols

In same year Srinivas et. al. from Oak Ridge National Laboratory published a technical report~\cite{sridharan2011scalable} on Language-Based Software Transactional Memory for Distributed Memory Systems. In Chapel~\cite{chapel:Language}, a general-purpose parallel language, they provided atomic semantics and pluggable compiler support for multiple DTM implementations. They also provided a prototype distributed STM implementation Global Transactional Memory 2 (GTM2) a enhancement over GTM~\cite{sridharan2009scalable} work published in 2009 based on Remote Procedure Call(RPC) to provide DTM  support. In GTM2 simple RPC was improved with read versioning, deferred update, and eager acquire scheme.

Similar to GenRSTM, in 2011 Hyflow a Java framework~\cite{Saad:2011:HHP:1996130.1996167} for DTM was released for non-replication based systems. Later in 2012 a DTM framework in Scala language ~\cite{turcuhyflow2}  was released which showed improvement over previous framework. Both of these frameworks utilized TFA algorithm for there prototype implementation, which uses an asynchronous clockbased validation technique to ensure DTM transactional properties. HyflowCPP framework also uses TFA as its base transactional algorithm. We will describe TFA algorithm later in detail in Chapter~\ref{chap:algorithm}.

Recently in 2012 Granola~\cite{cowling2012granola} work from MIT provided the support for the serializability. It divides the transactions in three different categories: Single-repository transactions executing using objects within a repository, Coordinated distributed transactions executing using objects from more than one repositories, independent distributed transactions executing atomically across a set of repositories and commit independently. Coordinated distributed transactions follow the traditional two phase commit voting protocal and provide the current state of art performance. Meanwhile, single-repository transactions and independent distributed transactions using timestamp synchronization and no locking provide a high throughput.   

\section{Non-Serializable DTM implementations}

Many researchers have contented the serializability as a very strong criteria and used the weaker criteria to provide the high performance for DTM. Here, we describe some famous Non-serializable consistency criteria and  related work in DTM. 

\textit{Snapshot Isolation} is very famous consistency criteria often used in the database systems. Some researchers have developed the DTM systems based on this criteria. Snapshot Isolation can be formally described as following:

\begin{definition}[\textbf{Snapshot Isolation}]
SI is defined by two properties: \textit{Snapshot-Read} requires that a transaction T reads data from a snapshot which contains all updates committed before T starts (plus its own updates). \textit{Snapshot-Write} requires that no two concurrent transactions may write the same object; that is, if two concurrent transactions both want to write the same data item only one of them will be allowed to commit.
\end{definition}

Snapshot-Read is typically implemented via a multiversion system where read operations access previously committed versions. Multi-Versioning is often used in databases to provides the concurrent access. It can be defined as following:
\begin{definition}[\textbf{Multi-Versioning}]
In Multi-Version concurrency control(MVCC), each write on an object $x$ creates a new copy of it. All copies of same object are given proper version based on history value. MVCC provides time-consistence views for the system. It allows the delayed read operations to execute successfully by providing the object version relevant to transaction's time-stamp. 
\end{definition}

Conflict detection for Snapshot-Write can be implemented via locking or via validation. In SI read and write skew anomalies can occur, which happens when two transactions concurrently read an overlapping data set, make disjoint updates, and finally concurrently commit. Neither of transaction see update performed by the other.

One of the first paper on weaker consistency Model SI was DecentSTM~\cite{DecentSTM:5470446} in 2010.  DecentSTM algorithm keeps limited list of committed versions of all shared data and obtains lazily a consistent memory snapshot during a transaction’s execution. By choosing a version upon read, a transaction determines on which versions it depends. In fact with unlimited version history, a read only transaction would never have to abort, because it could always read a previous version that does not conflict with the data read so far. For coincidental commits DTM uses a voting based randomized consensus protocol. Using snapshot isolation do provide the higher performance in Decent STM, but also adds up additional memory overhead of maintaining versioned objects.  

In 2011 Nuno et. al. in DiasSTM~\cite{dias2011efficient} came up with approach of static analysis of transactional code to provide serializable correctness to the snapshot consistency model based database systems. They suggested the methods to avoid read-write anomalies by automatically modifying the transaction code.

Genuine Multiversion Update-Serializable Partial Data Replication(GMU)~\cite{GMU:peluso2012scalability} work published in 2012 provided high performance using the consistency criterion Extended Update Serializability(EUS). Update serializability is a weaker consistency criteria and can be defines as follows:

\begin{definition}[\textbf{Update Serializability}]
A schedule $s$ over a set $T$ of transactions is update serializable (USR) iff each schedule $s'$ obtained from $s$ after deleting all but one read-only transaction is serializable. If there are no read-only transactions , then no transactions need be deleted.
\end{definition}

Extended Update Serializability (EUS)~\cite{EUS:HansdahPatnaik} allows concurrent read-only transactions to observe snapshots generated from different linear extensions of the history of update transactions.

At its heart GMU uses a distributed multiversion concurrency control scheme, a vector clock based synchronization algorithm, to track down data and causal dependency relations. It uses the partial replication to reduce the amount of network communication. 


\section{Replication}
Replication have been heavily used by DTM community extract the transaction localization and boost performance. For replication based transactional systems, consistency is generally defined using 1-Copy serialization, which can be defined as described below:

\begin{definition}[\textbf{1-Copy Serializability}]
A concurrent execution of transactions in a replicated database is one-copy-serializable if it is equivalent  to an ordering obtained when the transactions are performed sequentially in a single centralized database.~\cite{bornea2011one}
\end{definition}

First paper in DTM by Manassiev~\cite{Manassiev:2006:EDV:1122971.1123002} based on DMV algorithm, as described earlier, used data replication. For providing 1-Copy serialization DMV used the global serialization time-stamp token, which proved costly approach to support 1-Copy serialization in replication based systems. Later Dependable Distributed Software Transactional Memory(D2STM) system~\cite{D2STM:5368778} and AGGRO scheme~\cite{AGGRO:5598236} improved performance by replacing global time-stamp with Atomic broadcast messages.  

Sinfonia~\cite{Aguilera:2009:SNP:1629087.1629088} service also supported replication. But it did not design the concurrency algorithm taking the replication in consideration, instead it used the primary-copy replication to recover in case of failure. 

DecentSTM~\cite{DecentSTM:5470446} used the full replication with random consensus concurrency protocol and provided the  Snapshot consistency. It showed improvement using replication and Snapshot consistency but lacked any innovation in concurrency protocol. Later GMU~\cite{GMU:peluso2012scalability} presented a innovative concurrency protocol based on partial replication supporting Extended updated serializability and showed good performance improvement. 

\section{Strong Atomicity}
We have already introduced the strong atomicity informally in chapter~\ref{chap:intro}. Formally Strong Atomicity can be described as below:

\begin{definition}[\textbf{1-Copy Serializability}] 
Strong Atomicity is a transactional semantics that guarantees the atomicity between transactional and non-transactional code.
\end{definition}

Cluster-STM~\cite{Bocchino:2008:STM:1345206.1345242} supported the Strong Atomicity by implementing a programming restriction on user. DecentSTM~\cite{DecentSTM:5470446} programming model guaranteed Strong Atomicity and helped users to stop careless atomicity mistakes. HyflowScala~\cite{turcuhyflow2} and HyflowCpp also have en-build the strong atomicity using programming model.

\section{Transaction Models}

For performance improvement Nesting techniques are widely used in database systems. In 1981 Moss~\cite{moss1981nested} first time described the nesting concept in a distributed transaction. He extended two phase commit protocal~\cite{TwoPC:weikum1991principles} to support the nesting and proposed algorithms for distributed transaction management, object state restoration, and distributed deadlock detection. Later in 1983 Gracia~\cite{garcia1983using} et. al. extensive analyzed it in open nesting context using undo-logs transactions. 

Transaction nesting was first time introduced to STM in 2006 by  Moss and Hosking in ~\cite{moss2006nested}.They provided the semantics of transactional operations in terms of system states as a tuple of a transaction ID, a memory location, a read/write flag, and the value read or written. Later Moss ~\cite{moss2006open} further described the open-nesting as method to overcome false conflicts and improve concurrency. 

In same year Moravan et al. implemented nesting in logTM~\cite{moravan2006supporting} and demonstrated the speed-up 100\% for few benchmarks. In 2009 Agrawal et. al. ~\cite{agrawal2009safe} introduced the concept of transaction ownership by combining the close and open nesting. Herlihy and Koskinen propose transactional boosting~\cite{herlihy2008transactional} for implementing highly concurrent transactional data structures, which internally implemented the open-nesting. Later Koskinen and Herlihy~\cite{koskinen2008checkpoints} suggested the Checkpointing as an alternative to nesting.

\section{Unconventional Database Systems}
In recent times there have been lot of work on designing unconventional database system. With explosion in amount of data processed and stored in data warehouse, system administers are understanding the limitation of current database systems. Many works ~\cite{Stonebraker:2007:EAE:1325851.1325981}~\cite{harizopoulos2008oltp} have argued that current DBMS perform a poor job of CPU utilization and might require whole redesign. Works like HStore~\cite{HSTORE:kallman2008h} and Google Spanner~\cite{corbett2012spanner} have achieve high performance using new architectures based on replication and multi-versioning for database systems. 

\section{Summary}

\begin{table}[htbp]
\centering%
\begin{threeparttable}[b]
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline 
\begin{sideways} Implementation \end{sideways} & \begin{sideways} Serializability \end{sideways} & \begin{sideways} Replication \end{sideways} & \begin{sideways} MultiVersioning \end{sideways} & \begin{sideways} Strong Atomicity \end{sideways}  & \begin{sideways} checkpointing \end{sideways} & \begin{sideways} Close-Nesting \end{sideways} & \begin{sideways} Open-Nesting \end{sideways} &  Target Language \tabularnewline
\hline
DMV ~\cite{Manassiev:2006:EDV:1122971.1123002} & \CheckmarkBold{} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & C/C++ \tabularnewline
\hline 
Cluster-STM ~\cite{Bocchino:2008:STM:1345206.1345242} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \CheckmarkBold{} \tnote{1}& \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & C/C++ \& SQL \tabularnewline
\hline 
DiSTM ~\cite{Kotselidis08distm:a} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & Java \tabularnewline
\hline 
D2STM ~\cite{D2STM:5368778} & \CheckmarkBold{} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & Java \tabularnewline
\hline 
AGGRO ~\cite{AGGRO:5598236} & \CheckmarkBold{} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & Java \tabularnewline
\hline 
Sinfonia\tnote{2} ~\cite{Aguilera:2009:SNP:1629087.1629088} & \CheckmarkBold{} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & C/C++ \tabularnewline
\hline  
GenRSTM ~\cite{GenRSTM:6038614} & \CheckmarkBold{} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & Java \tabularnewline
\hline 
GTM ~\cite{sridharan2011scalable} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & Chapel \tabularnewline
\hline
HyflowJava ~\cite{Saad:2011:HHP:1996130.1996167} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \CheckmarkBold{} & \CheckmarkBold{} & Java \tabularnewline
\hline
HyflowScala ~\cite{turcuhyflow2} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \CheckmarkBold{} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & Scala \tabularnewline
\hline
Granola ~\cite{cowling2012granola} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{}  & \XSolidBold{} & Java \tabularnewline
\hline
HyflowCpp & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \CheckmarkBold{} & \CheckmarkBold{} & \CheckmarkBold{} & \CheckmarkBold{} & C/C++ \tabularnewline
\hline
Decent RSTM ~\cite{DecentSTM:5470446} & \XSolidBold{} & \CheckmarkBold{} & \CheckmarkBold{} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & Java \tabularnewline
\hline
GMU ~\cite{GMU:peluso2012scalability} & \XSolidBold{} & \CheckmarkBold{} & \CheckmarkBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & \XSolidBold{} & Java \tabularnewline
\hline
\end{tabular}
\begin{tablenotes}
\item [1] Supported via programming restriction
\item [2] Developed as service for backup and restore

\end{tablenotes}
\end{threeparttable}
\caption{Comparison of DTM implementations.}
\label{tbl:stmComp}
\end{table}
HyflowCpp framework is implemented in C++ at API-level and focuses on non-replicated peer to peer distributed systems. Current default algorithm implementation, Transaction Forwarding Algorithm(TFA), provides the strong memory consistency. Using distributed clock, TFA is able to overcome any global serialization overhead. Single version objects without any replication helps TFA to reduce the amount of network messaging and enables it to scale without any network bottleneck. In Table~\ref{tbl:stmComp}, we summarize our comparison of HyflowCpp. Each row of the table describes an DTM implementation, and each column describes a feature. The table entries describe the features supported by the different DTMs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%																									%
%							CHAPTER 3	:	Programming Interface						%
%																									%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Programming Interface}\label{chap:progInterface}
\markright{Chapter~\ref{chap:progInterface}.
Programming Interface
\hfill}

In this chapter, we introduce the programming interface provided by HyflowCpp to execute the distributed atomic transactions. First we describe the basics of interface and then explain it by developing the list benchmark. HyflowCpp allows user to configure the benchmark and execution setting using a configuration file. User can also pass all these configuration variables as environment variables.

In a networked system objects are distributed over different nodes, therefore normal object reference can not be used. User is required to use a unique key to address a particular object anywhere in network. We provide a base class name ~\emph{HyflowObject} for every distributed object. Every distributed object must inherit this class. HyflowObject provides the getId() method which returns as unique key to access the object from anywhere in the network.

HyflowCpp performs object serialization using boost serialization library. User is required to follow it for proper packing and unpacking of object over the network. Objects created by user needs to register itself as inherited class of HyflowObject and register all the object field in boost serialize function to which it wish to be serializable over network.

For development of DTM applications HyflowCpp provides two transactional interfaces: 
\begin{enumerate}
\item Transaction Support using Macros
\item Transaction Support using Atomic class 
\end{enumerate}

\section{Transaction Support using Macros}

HyflowCpp provides standard atomic semantics using macros \emph{HYFLOW{\_}ATOMIC{\_}START} and \emph{HYFLOW{\_}ATOMIC{\_}END}. Figure~\ref{Fig:atomicConstr} shows how to utilize the these macro to execute any given part of code atomically and compares it to standard STM atomic semantics. 

\begin{figure}
\centering 
\begin{footnotesize}
\begin{minipage}[b]{0.45\linewidth}\centering
HyflowCpp atomic construct 
\begin{lstlisting}
HYFLOW_ATOMIC_START{
// Example of simple compare
// and swap operation
   value = Read(Address);
   if( value==myValue )
       Write(Address, myValue)
}HYFLOW_ATOMIC_END;
\end{lstlisting} 
\end{minipage} 
\begin{minipage}[b]{0.45\linewidth}\centering
Standard STM atomic construct
\begin{lstlisting}   					   
atomic{
// Example of simple compare
// and swap operation
   value = Read(Address);
   if( value==myValue )
       Write(Address, myValue)
}
\end{lstlisting}			  
\end{minipage}
\end{footnotesize}
\label{Fig:atomicConstr}\caption{Atomic Construct for Hyflow vs. Standard STM implementations}
\end{figure}

Any object in the network can be opened either in \emph{Read} or \emph{Write} mode. Once user requests the object, HyflowCpp fetches the object from its current location and copies to transactions read or write set depending of access type. For accessing any object user should macro \emph{HYFLOW{\_}FETCH(ID, IS{\_}READ)}. First argument to this macro is \emph{objectId} and second argument is access type \emph{true/false}, true for read, otherwise false.

For reading or writing the fetched object we provide two more macros \emph{HYFLOW{\_}ON{\_}READ(ID)} and \emph{HYFLOW{\_}ON{\_}WRITE(ID)}. \emph{HYFLOW{\_}ON{\_}READ} returns the user the constant reference pointer to HyflowObject, which can be used for read-only operations. For manipulating the object user again require to call \emph{HYFLOW{\_}ON{\_}WRITE}, which returns a normal reference pointer to object. User can also pass the object reference pointer itself in place of unique object key to retrieve the object.   

\emph{HYFLOW{\_}PUBLISH{\_}OBJECT(OBJ)} allows user to publish any locally created object on the network. But, such objects must inherit the HyflowObject class as a base type as discussed earlier. Similarly, \emph{HYFLOW{\_}PUBLISH{\_}DELETE(OBJ)} allows user to delete any object from the network.

Now using these macro's we can write the list benchmark as described in figure~\ref{Fig:listMacro}. In this figure we illustrate the list node addition and deletion atomically using HyflowCpp Macros. 
\begin{figure}
\centering
\begin{lstlisting}
class ListNode::HyflowObject {

void ListNode::addNode(int value) {
  HYFLOW_ATOMIC_START{
	std::string head="HEAD";
	HYFLOW_FETCH(head, false);

	ListNode* headNodeRead =  (ListNode*)HYFLOW_ON_READ(head);
	std::string oldNext = headNodeRead->getNextId();
	ListNode* newNode = new ListNode(value, ListBenchmark::getId());
	newNode->setNextId(oldNext);
	HYFLOW_PUBLISH_OBJECT(newNode);

	ListNode* headNodeWrite = (ListNode*)HYFLOW_ON_WRITE(head);
	headNodeWrite->setNextId(newNode->getId());
  } HYFLOW_ATOMIC_END;
}

void ListNode::deleteNode(int value) {
  HYFLOW_ATOMIC_START{
	ListNode* targetNode = NULL;
	std::string head("HEAD");
	std::string prev = head, next;

	HYFLOW_FETCH(head, true);
	targetNode = (ListNode*)HYFLOW_ON_READ(head);
	next = targetNode->getNextId();

	while(next.compare("NULL") != 0) {
	  HYFLOW_FETCH(next, true);
	  targetNode = (ListNode*)HYFLOW_ON_READ(next);
	  int nodeValue = targetNode->getValue();
	  if (nodeValue == value) {
		ListNode* prevNode = (ListNode*)HYFLOW_ON_WRITE(prev);
		ListNode* currentNode = (ListNode*)HYFLOW_ON_WRITE(next);
		prevNode->setNextId(currentNode->getNextId());
		HYFLOW_DELETE_OBJECT(currentNode);
		break;
	  }
	  prev = next;
	  next = targetNode->getNextId();
	}
  } HYFLOW_ATOMIC_END;
}

}
\end{lstlisting}
\caption{list Benchmark using HyflowCpp Macros}
\label{Fig:listMacro}
\end{figure}

HyflowCpp also support the transaction \emph{Checkpointing} using macros. For minimum Checkpointing overhead we support it in outermost transaction call. We allow user to checkpoint at any place using ~\emph{HYFLOW{\_}CHECKPOINT{\_}HERE}. User is also required to initiate the Checkpointing at start of transaction using ~\emph{HYFLOW{\_}CHECKPOINT{\_}INIT}. Figure~\ref{Fig:bankCP} illustrates how Checkpointing can be implemented in a simple bank transfer function. Note that how user is required to pass the current context instance to withdraw function. This requirement exist for all the functions which are called within atomic block and are require to be executed atomically. This additional argument passing will be removed once the compiler support is added to atomic block. 

\begin{figure}
\begin{minipage}[b]{0.9\linewidth}\centering
\begin{lstlisting}
void BankAccount::transfer(string Account1, string Account2, Money) {
	HYFLOW_ATOMIC_START {
		HYFLOW_CHECKPOINT_INIT;

		withdraw(Account1, Money, __context__);

		HYFLOW_CHECKPOINT_HERE;
	
		deposit(Account2, Money, __context__);
	}HYFLOW_ATOMIC_END;
}
\end{lstlisting}
\end{minipage}
\caption{Checkpointing in bank transfer function}
\label{Fig:bankCP}
\end{figure}

\section{Transaction Support using Atomic class}

Atomic class interface is more involved and allows users to directly program against the HyflowCpp framework. Using the Atomic class interface user can directly interact with transaction context. Atomic class is template type class which must be Type defined based on atomic function class return type. Atomic class function pointer ~\emph{atomically} is initialized by user with desired function, which is to be executed atomically. After initializing the function pointer value user can call the ~\emph{execute} method from atomic class to run the desired function atomically.

Atomic class also provides the function pointers to support advance nesting features like open-nesting. User can specify the ~\emph{onCommit} and ~\emph{onAbort} function for  ~\emph{HyflowObject} requiring the open nesting support. All these function pointers requires to follow a define argument set similar to libraries like pthread. Only hind side of using atomic class is that, Checkpointing can not be performed on transaction using atomic class. Checkpoints are required to be created in outermost transactions and Atomic class executes the function pointer as an inner transaction. 

User can also write the benchmark directly without using any of Atomic class or Macros. This will require the user to directory manipulate the DirectoryManager for remote object access and ContextManager for transaction atomicity. It can be some time useful for debugging some internal framework issues, otherwise it is not a recommended method.

In Figure~\ref{Fig:listClassDelete} we re-write the same List benchmark functions using the atomic class. 

\begin{figure}
\centering
\begin{lstlisting}
class ListNode::HyflowObject {

void* deleteNodeAtomically(HyflowObject* self, void* args,
	HyflowContext* c, uint64_t* balance)
{
	int value = *((int*)args);
	ListNode* targetNode = NULL;
	std::string head("HEAD");
	std::string prev = head, next;

	HYFLOW_FETCH(head, true);
	
	targetNode = (ListNode*)HYFLOW_ON_READ(head);
	next = targetNode->getNextId();

	while(next.compare("NULL") != 0) {
		HYFLOW_FETCH(next, true);
		
		targetNode = (ListNode*)HYFLOW_ON_READ(next);
		
		int nodeValue = targetNode->getValue();
		if (nodeValue == value) {
		
			ListNode* prevNode = (ListNode*)HYFLOW_ON_WRITE(prev);
			
			ListNode* currentNode = (ListNode*)HYFLOW_ON_WRITE(next);
			
			prevNode->setNextId(currentNode->getNextId());
			
			HYFLOW_DELETE_OBJECT(currentNode);
			
			break;
		}
		prev = next;
		next = targetNode->getNextId();
	}
}

void ListNode::deleteNode(int value) {
	Atomic<uint64_t> atomiDelete;	
	
	atomicDelete.atomically = ListNode::deleteNodeAtomically;
	
	atomicDelete.execute(NULL, &value, NULL);
}

}
\end{lstlisting}
\caption{list Benchmark using HyflowCpp Atomic Class}
\label{Fig:listClassDelete}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%																									%
%							CHAPTER 4	:	System Architecture						%
%																									%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{System Architecture}\label{chap:sysArch}
\markright{Chapter~\ref{chap:sysArch}.
System Architecture
\hfill}

HyflowCpp is a distributed software transaction memory system at API level. It written in C++ using object oriented programming paradigm. It is carefully design to provide pluggable support for different DTM, cache-coherency protocols, and network libraries. All components are developed independent of each other and connected through well defined interfaces. Any individual component can be easily replaced or modified by writing a implementation compliant to the given component interface. 

Figure~\ref{Fig:HyflowCppArch} shows the architecture of a node in HyflowCpp. It it made of six modules: Transaction Interface Module, Transaction Validation Module, Object Access Module, Object serialization Module, Network Module, and Message Processing Module. We have already discussed by Transaction Interface Module in detail in chapter~\ref{chap:progInterface}. Now we will describe rest of modules in details in following sections.

\begin{figure}
\begin{minipage}[b]{0.9\linewidth}\centering
\centering \includegraphics[scale=0.46]{\string"eps/HyflowCppArch".pdf}
\caption{HyflowCpp Architecture}
\label{Fig:HyflowCppArch}
\end{minipage}
\end{figure}

\section{Transaction Validation Module}

The purpose of Transaction Validation Module is to provide the transactional consistency and achieve system wide progress. All the DTM logic is performed in this module by extending base class ~\emph{HyflowContext}. Currently by default ~\emph{HyflowContext} is extended as ~\emph{DTLContext} which implements the TFA algorithm. This module validates memory locations and retries the transactional code as needed on commit failure. This module can be configured based on the transaction model used like Checkpointing and Closed nesting etc. 

To support the DTM protocols this module also provides the ~\emph{LockTable} for object level or word level locking. This table is implemented using high perform concurrent hashMaps of Thread Building Block(TBB)~\cite{willhalm2008putting} library. This module also provides the ~\emph{ContextMap} to access the context instance using transaction Id. It enable the contention Managers to collect meta data and make updates to different transactional contexts.

This module interfaces with Transaction Interface Module to create the transactional contexts for user applications and provides the object access to user through object Access Module. It also usages the Message interface to perform context specific messaging for commit and validation requests to the remote nodes.

\section{Object Access Module}

Object Access Module serves multiple purpose in HyflowCpp framework. It provides the copy of distributed objects, object owner information, and performs object version validation and object directory updates. Objects are located using the unique object Id. This module encapsulates a directory lookup protocol to access distributed objects. Currently by default it implements the efficient Tracker Directory Protocol. Tracker directory moves the object across nodes and maintains the current owner information on specific tracker node. To access any object this module first finds out the current owner information using object directory, then, it sends the object request to owner node. Owner node replies current copy of object or a null value, in case it got deleted by some other transaction. Tracker directory updates the owner information in tracker node object directory as object moves from one node to another node. Also on object creation or deletion it updates the object directory with owner information. 

Similar to Transaction Validation Module, Object Access Module contains two efficient object Maps to support any object access protocol. It provides the ~\emph{Local Cache} and ~\emph{Object Directory}. The purpose of Local Cache is to maintain the authoritative copy of objects owned by current node. Meanwhile, directory is utilized by tracker nodes to keep the meta data information, like in case of Tracker Directory, the object owner information. 

Object Access Module interfaces with two other Modules ~\emph{Object Validation Module} and ~\emph{Message Interface Module}. To provide ~\emph{Strong Atomicity} HyflowCpp directs all the access to objects through transaction context. Therefore all object requests to Object Access Module come through Transaction Validation module. Object deletion or publication requests are also made by Transaction Validation Module. In addition to that Object Access Module handles also the object validation request. For all remote object and request serialization and de-serialization Object Access Module interacts with the Message Interface Modules.

\section{Object Serialization Module}

Message serialization and de-serialization is a big challenge in distributed computing using C++. To free user from this cumbersome process HyflowCpp provides a Messaging interface and allows developer to add pluggable validation and distribution protocols without worrying about serialization and de-serialization of messages. HyflowCpp provides ~\emph{HyflowMessage} and ~\emph{BaseMessage} for this purpose. BaseMessage acts a parents class for any Message in HyflowCpp. User can create any new type to perform any protocol specific task, just by extend BaseMessage. HyflowMessage class acts as wrapper class for all BaseMessages and its extensions. HyflowMessage contains the information about the BaseMessage wrapped around by it and provides the required information to de-serialize any message.

HyflowMessage provides a standard interface towards network library. All the HyflowMessages are converted in a binary blob and provided to network library communicate over network. In this way network implementation is totally independent of ~\emph{Transaction Validation Module} and ~\emph{Object Access Module}. For serialization and de-serialization of HyflowMessage we use the ~\emph{Boost serialization}~\cite{karlsson2005beyond}. It provides the support for serialize of any type of complex message or object.  

Object Serialization Module is central part of HyflowCpp framework. It is accessed by all other modules except Transactional Interface Module. Object Validation Module and Object Access Module use this interface to send transactional messages and object requests, while Network Manager and Message Handling interface utilize it to process incoming message and provide responses to upper layer modules.

\section{Network Module}

Network module plays a very vital role in performance of a DTM protocol. A poor implementation and scalability of Network Module can lead to a poor performance even for an efficient DTM algorithm. In HyflowCpp we provide pluggable support for any network library through a well defined network interface. Currently in HyflowCpp we support two networking libraies: MsgConnect~\cite{MsgConnect:2012} and ZeroMQ~\cite{hintjens2011omq}.  

\begin{figure}
\begin{minipage}[b]{0.9\linewidth}\centering
\centering \includegraphics[scale=0.47]{\string"eps/HyflowCppNetwork".pdf}
\caption{ZeroMQ Network Architecture}
\label{Fig:HyflowCppNetwork}
\end{minipage}
\end{figure}

MsgConnect is a open source library for linux platforms. It provides a high level messaging interface for users. It frees user from socket level message handling and provides a reliable way of communication using TCP protocol~\cite{forouzan2002tcp}. Unfortunately we found some scalability issues in open source implementation. Still, for basic prototyping it can be reliable networking library.

To design a fast and scalable networking solution we use industry standard ZeroMQ library. ZeroMQ is socket level library, but provides very efficient solutions for in-process communication between threads, which makes zeroMQ very suitable for any multi-threaded networking requirement. In Figure~\ref{Fig:HyflowCppNetwork}, we describe our networking architecture designed using ZeroMQ library. This architecture design allows configuring architecture variable to fine tune for desired workload. 

As described in Figure~\ref{Fig:HyflowCppNetwork} the any transactional node A and B communicates with each other using ~\emph{Forwarder} and ~\emph{Catcher} threads. These dedicated threads are responsible for connecting with different nodes using zeroMQ Router~\cite{hintjens2011omq} socket. ZeroMQ router sockets are very useful to communicate with multiple nodes simultaneously. Forwarder threads are responsible for receiving message request from transactional threads and forward it to Catcher thread of desired nodes. On other side Catcher threads are responsible for receiving message work-load from forwarder thread and assign it to available ~\emph{Worker} thread. Worker threads process the message send back reply to catcher thread if required. Catcher thread in turn returns message back to Forwarder thread, which conveys it to original requester transactional thread.

ZeroMQ provides four to five times better performance in comparison to MsgConnect. Using Multipart messaging of ZeroMQ, we are able to reduce the amount of polling between threads to bare minimum at two sockets. With experiments we found that one forwarder if enough for six to seven transactional threads. On contrast, even one worker per catcher can be sufficient for message processing in some situations. To fine tune these values, we define two ratios ~\emph{zeroMQTFR} i. e., zeroMQ Transactional thread to Forwarder thread ratio and ~\emph{zeroMQWFR} i. e., zeroMQ Worker thread to Forwarder thread ratio. It is worth noting that Forwarder to catch ratio is always one, therefore zeroMQWFR also defines the Catcher threads to worker thread ration. By fine tuning these values user extract a very high messaging throughput.

\section{Message Processing Module}

Message Processing Module provides message handling capability to any network library. The major task to this interface is to find a proper handler for any message and support asynchronous messaging. When a user create a new type of message, he/she also creates a proper message handler of this message type. All message handlers are registered by Message handler interface, at network initiation time. Later, when network library receives a request message using the message handler it creates a proper response and replies back as required.

Another important task performed by this module is to support the asynchronous messaging. This module defines a class ~\emph{HyflowMessageFuture}, which allows a transactional thread to send a message asynchronously. A transactional thread can send a message with a HyflowMessageFuture object and proceed with other tasks. Later transaction thread can come to message specific HyflowMessageFuture to wait on the message response. 

This module directly interface with Network Module and Object Serialization Module. All the Messages and there handling is defined in Object Serialization Module. Message and there handler mapping is defined in the Message Processing Module. Network Module utilizes this module to find the appropriate handler and provide the asynchronous message response notification to requesting transactional threads.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%																									%
%							CHAPTER 5	:	Algorithms						%
%																									%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Transactional Forwarding Algorithm}\label{chap:algorithm}
\markright{Chapter~\ref{chap:algorithm}.
Transactional Forwarding Algorithm
\hfill}

In this chapter we describe Transaction Forwarding Algorithm(TFA) in detail for different transactional models. TFA is a lock-based algorithm with lazy acquisition scheme. It usages an innovative asynchronous distributed clock mechanism to validate the transactions. TFA supports the opacity property~\cite{guerraoui2009semantics} and guarantees  strong progress~\cite{guerraoui2009semantics}. Opacity is a stronger property in comparison to serialization and informally can be described as an extension of the classical database serializability property with the additional requirement that even non-committed transactions are prevented from accessing inconsistent states. Strong progressiveness promises that all non-conflicting transactions will commit and at least one of all conflicting transactions will commit.  
 
Now we present the TFA algorithm in different transactional models and define its main procedures for transaction validation.
 
\section{Flat Nesting}
TFA uses a synchronization variant similar to Lamport~\cite{lamport1978time} mechanism to keep the clocks synchronized. In TFA each distributed node has a local clock $lc$. Each node increases its local clock atomically on a write transaction commit. All the communication between nodes piggyback the nodes local clock. On receiving the messages of remote node, each nodes compares the piggybacked remote node clock with its local clock. Node updates its clock to remote node clock if it is higher than its local clock, otherwise it ignore it. This way all the nodes are kept in synchronization and are able to establish the happens before relationship between object reads. 

Asynchronous distributed clocking enables the TFA to detect any early conflicts in the transaction. Early conflicts in the transaction are detected through a process called Transaction Forwarding, which is performed at the time of object access(read/write). 

\begin{figure}
\begin{minipage}[b]{0.9\linewidth}\centering
\begin{lstlisting}
Context::TransactionForwarding(senderNodeClock) {
	if senderNodeClock > transaction.timeStamp {
		forAll obj in readSet {
			if (currentVersion(obj)>transaction.timeStamp) { 
				transaction.rollback();
				return ;		
			}
		}
		transaction.timeStamp = senderNodeClock ; 
	}
}
\end{lstlisting}
\end{minipage}
\caption{Transaction Forwarding in Flat Nesting}
\label{Fig:FlatTFA}
\end{figure}

\begin{figure}[H]
\begin{minipage}[b]{0.9\linewidth}\centering
\begin{lstlisting}
Context::Commit() {
	forAll obj in writeSet {
		lock = obj.acquireLock()
		if !lock
			rollback
	}
	forAll obj in readSet {
		valid = obj.readValidate();
		if !valid
			rollback
	}
	nodeClock++;
	commitWriteSet();
	forAll obj in transaction.writeSet
		obj.commitValue()
 		obj.setVersion(transaction.timeStamp)
 		obj.releaseLock()
 		if obj.remote then
 			updateOwner(obj)
	forAll obj in transaction.publishSet
		publish(obj)
	forAll obj in transaction.deleteSet
		delete(obj)
}
\end{lstlisting}
\end{minipage}
\caption{Commit in Flat Nesting}
\label{Fig:FlatCommit}
\end{figure}

On start of any transaction, node's local clock is attached to its context as a time stamp $wv$. When any object is accessed by a transaction the sender nodes clock $rc$ is compared against the transactions time stamp $wv$. If sender nodes clock $rc$ is greater than the transactions time stamp $wv$, we verify whether we can move the transaction time stamp $wv$ to $wv'$, where $wv'$ = $rc$. This validation is done by validating all read-set objects version against transaction time stamp $wv$, if they are still less than $wv$, we can safely forward transaction from $wv$ to $wv'$. Figure ~\ref{Fig:FlatTFA} illustrates the Transaction Forwarding procedure.

In Figure~\ref{Fig:FlatCommit} we illustrate the transaction commit process. Transaction commit in TFA is performed similar to two phase commit~\cite{TwoPC:weikum1991principles} protocol. At commit time the transactional node tries to acquire locks on the write-set objects in any appropriate order to avoid deadlocks. Remote object lock requests are send to object owner and if any of locks can not be acquired transaction rollbacks. After successfully acquiring the object locks, transaction tries to re-validate the read-set object. Again if read-set objects validation fails the transaction performs rollback. Once write set locks are acquired and read-set objects are validated it is safe to commit the transaction. In commit process for write transactions local clock is increased atomically. All write-set object version is updated to transaction version. For local objects the updated copies of objects is committed and for remote the change of object ownership is performed. Publish-set and delete set object entries are updated in Object Access Module. After completion of commit process all the write-set object locks are released. 
   
\section{Closed Nesting} 

In Close Nesting each transaction attempts to do individual commits, but for inner transactions the commit not visible outside of the enclosing transaction. Inner transactions are allowed to abort independently of their parents. In this way by permitting partial aborts for the inner transactions close nesting helps to improve performance. In this section we present the modified version of TFA for Close Nesting: ~\emph{Transaction Forwarding Alogrithm for Close Nesting(TFACN)}.

\begin{figure}[H]
\begin{minipage}[b]{0.9\linewidth}\centering
\begin{lstlisting}
Context::TransactionForwarding(senderNodeClock) {
	if senderNodeClock > transaction.timeStamp {
		contextList = context.fetchContextBranch()
		forAll context in contextList {
			forAll obj in context.readSet {
				if (currentVersion(obj)>transaction.timeStamp) { 
					transaction.rollback();
					return ;
				}		
			}
		}
		transaction.timeStamp = senderNodeClock ; 
	}
}
\end{lstlisting}
\end{minipage}
\caption{Transaction Forwarding in Close Nesting}
\label{Fig:CloseTFA}
\end{figure} 

To support close nesting each context maintains a reference to the parent context, for outermost context parent context reference is set to null. In transaction forwarding step we performed transaction forwarding on whole context tree branch instead on just current inner transaction. In Figure~\ref{Fig:CloseTFA} we illustrate the Transaction Forwarding step for TFACN.

In commit phase TFACN directly merges the context objects to parent context objects for inner transactions. For outermost transaction commit procedure is same as in Flat Nesting. 

\section{Checkpointing}

Transaction Checkpointing saves the transaction execution state at various points. Later on commit failure it enables a transaction to resume from previously saved valid Checkpoint. Checkpointing allows a transaction to abort only required part of transaction for which actually the conflict happens and therefore boosts the performance. Checkpointing can be consider as a extension of Close nesting, where partial aborts can be applied at any point in transaction execution state. In this section we present  the modified the TFA algorithm for Checkpointing: ~\emph{Transaction Forwarding Algorithm with Checkpointing(TFACP)}.

\begin{figure}[H]
\begin{minipage}[b]{0.9\linewidth}\centering
\begin{lstlisting}
Context::TransactionForwarding(senderNodeClock) {
	if senderNodeClock > transaction.timeStamp {
		forAll obj in readSet {
			if (currentVersion(obj)>transaction.timeStamp) { 
				if transaction.checkPointAvailable {
					removeInvalidatedObjects();
					transaction.resume();
				}else {
					transaction.rollback();
					return ;
				}		
			}
		}
		transaction.timeStamp = senderNodeClock ; 
	}
}
\end{lstlisting}
\end{minipage}
\caption{Transaction Forwarding in Checkpointing}
\label{Fig:CheckPointTFA}
\end{figure} 

To support Checkpointing in TFACP we partition read-set, write-set, publish-set and delete-set data on basis of first access Checkpoint. This allows TFACP to identity the conflicting objects and to determine the valid Checkpoint to resume. To save the transaction execution stack state we use the ~\emph{setContext()} and ~\emph{getContext()} functions. Heap objects are maintained in context read-set, write-set and publish-set. 

\begin{figure}
\begin{minipage}[b]{0.9\linewidth}\centering
\begin{lstlisting}
commit::tryResume() {
	if transaction.checkPointAvailable {
		removeInvalidatedObjects();
		releaselocks();
		transaction.resume();
	}else {
		transaction.rollback();
		return ;
	}		
}

Context::Commit() {
	forAll obj in writeSet {
		lock = obj.acquireLock()
		if !lock
			rollback()
	}
	forAll obj in readSet {
		valid = obj.readValidate()
		if !valid
			rollbock()
	}
	
	for abstractLock in abstractLockSet {
		lock = abstractLock.acquireLock()
		if !lock
			rollback();
	}
	nodeClock++
	commitWriteSet()
	forAll obj in transaction.writeSet
		obj.commitValue()
 		obj.setVersion(transaction.timeStamp)
 		obj.releaseLock()
 		if obj.remote then
 			updateOwner(obj)
	forAll obj in transaction.publishSet
		publish(obj)
	forAll obj in transaction.deleteSet
		delete(obj)
		
	if topTransaction {
		releaseAbstractLocks()
	}else {
		mergeAbstractLockToParent()
	}	
}
\end{lstlisting}
\end{minipage}
\caption{Commit in Checkpointing}
\label{Fig:CheckpointCommit}
\end{figure}

HyflowCpp provides a helper class ~\emph{CheckPointProvider} to create, iterator and maintain the transaction Checkpoints.~\emph{HYFLOW{\_}STORE(OBJECT{\_}REF, OBJECT{\_}VALUE)} macro is provided to store any stack or heap object values just before creating checkpoint. These values are automatically are restored on continuing from checkpoint after partial abort.     

In Figure~\ref{Fig:CheckPointTFA} we illustrate the Transaction Forwarding Processing for TFACP. Similar to Flat nesting we perform transaction forwarding by object validation. But on validation failure, we do not rollback instead resume the transaction from valid Checkpoint if available. Before resuming we remove all the invalidated heap objects from the context.

Commit process in TFACP is also modified similar to Transaction Forwarding. On commit failure in place of restarting transaction we resume from available valid checkpoint. Note that here we are required to release any acquired lock before resuming. Figure~\ref{Fig:CheckPointCommit} illustrate the commit procedure in TFACP. 


\section{Open Nesting}

Open nesting provides the performance improvement by reducing the false memory level conflict. In contrast to close nesting in open nesting the inner transactions commit on completion are visible globally and corresponding undo action is merged into parent transaction. In case of parent transaction abort the undo action are used to recover from the inner transaction commit. To maintain the memory consistency a inner transaction specify higher level locks are maintained.  

To support open nesting in TFA a concept of abstract locks is introduces to higher level locks. Unfortunately abstract lock mechanism suffers from the livelocks issue and uses a random back-off mechanism to overcome this issue. TFAOP allows user to define the \textit{onAbort} and \textit{onCommit} functions to be performed in case of abort or commit on parent transaction. TFAOP acquires abstract locks in inner transactions and releases them in parent transaction on commit or abort. 

\begin{figure}
\begin{minipage}[b]{0.9\linewidth}\centering
\begin{lstlisting}
Benchmark::transaction() {
	Atomic atomicTxn;
	atomicTxn.atomic = Benchmark::transactionAtomic;
	atomicTxn.onAbort = Benchmark::onAbortTxn;
}

Benchmark::transactionAtomic() {
    string txnLock;
	readOperations();
	writeOperations();
	__context__.onLockAccess(Benchmark, txnLock, false);
	
}	if (nesting == HYFLOW_OPEN_NESTING ) {
		string txnlock;

Context::Commit() {
	forAll obj in writeSet {
		lock = obj.acquireLock()
		if !lock
			tryResume()
	}
	forAll obj in readSet {
		valid = obj.readValidate()
		if !valid
			tryResume()
	}
	nodeClock++
	commitWriteSet()
	forAll obj in transaction.writeSet
		obj.commitValue()
 		obj.setVersion(transaction.timeStamp)
 		obj.releaseLock()
 		if obj.remote then
 			updateOwner(obj)
	forAll obj in transaction.publishSet
		publish(obj)
	forAll obj in transaction.deleteSet
		delete(obj)
}
\end{lstlisting}
\end{minipage}
\caption{Commit in Open Nesting}
\label{Fig:OpenNestingCommit}
\end{figure}

As described in Figure~\ref{Fig:OpenNestingCommit} Abstract locks can be created by provide unique string name for transaction. Abstract lock are registered in transaction using the \textit{onLockAcess} Function. At commit time the registered abstract locks are acquired. Later, abstract locks are either merged to parent context or released if top transaction. In case of aborts rollback is performed by using onAbort function. Once compensating action for related inner transaction is completed abstract locks are released. Compensation action run with higher priority and don't perform random back-off.   


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%																									%
%							CHAPTER 6	:	Experiments						%
%																									%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experimental Results \& Evaluation}\label{chap:expResults}
\markright{Chapter~\ref{chap:expResults}.
Experimental Results \& Evaluation
\hfill}

In this chapter, the performance of HyflowCPP is compared against other Java STMs using micro-benchmarks and macro-benchmarks. Being first DTM framework in C++, we compare this work with other competitors like HyflowScala, HyflowJava and Decent RSTM. We evaluate the performance on multiple micro benchmarks(Bank, List, Binary Search Tree, Skip-list, Hash-table) and  macro benchmarks(Loan, Vacation and Tpcc).   

\section{Test Environment}

Our all experiments are conducted on 48 core machine. Machine contains four AMD Opteron\texttrademark  Processors (6164 HE), each with 12 cores running at 1700 MHz, and 16 GB of memory. All experiment are conducted in Linux environment using Ubuntu Linux Server 10.04 LTS 64-bit.  Each core communicates with other core via network loop-back TCP connection, emulating the behavior of 48 distributed nodes. All the process instance of benchmarks are bound to specific core to stop unnecessary context-switch between different cores. Framework dependency libraries \textit{Boost} version 1.40, \textit{$\Phi$MQ} version 1.30 and \textit{Intel Thread Build Block} version 4.0 are used.  

\section{Flat Nesting}

Flat nesting does not provide any performance incentive over other transactional model like Close or Open Nesting. Still, it is very useful to understand benchmarks characteristics and compare the raw performance between different DTM frameworks. We have evaluated the performance with different read to write ratios (0.2 , 0.5 and 0.8) on nodes from 4 to 48. For concentrating focus on the distributed behavior in experiments we have limited threads on each node to one.  

For performance comparsion, we compare the HyflowCpp with various competitors like HyflowJava~\cite{Saad:2011:HHP:1996130.1996167}, HyflowScala~\cite{turcuhyflow2}, DecentRSTM~\cite{DecentSTM:5470446} and GenRSTM~\cite{GenRSTM:6038614}. We have compared the all the benchmarks already available in competitor with our benchmarks. For some HyflowCPP benchmarks, we have not found any implementation in competitors. We have not spent time in developing benchmarks in competitor frameworks, instead we devoted our time in more important research work. 

\subsection{Micro Benchmarks}

Micro benchmarks which we considered for performance evaluation are data structures List, Binary Search Tree, Skip-list and Hash-table. In each data structure we convert all coarse grain locks access in lock based implementation with transaction Block provided by \emph{HYFLOW{\_}ATOMIC{\_}START} and \emph{HYFLOW{\_}ATOMIC{\_}END}. For each experiment we ran 2000 transactions 3 times and took average of their transactional throughput.  

\subsubsection{Bank}

The Bank benchmark simulates a distributed banking system. Each distributed node is initiated with certain number of bank accounts. Each account is initiated with some initial amount. Bank benchmark support two operations: Total Balance and Transfer. At the end of experiment a sanity check is performed. Bank benchmark is distributed in nature and allows multiple Transfer operations in parallel on different accounts.

For this experiment we created 10000 accounts distributed over different nodes. In Figure~\ref{Fig:flatBank}, we can observer the performance of the HyflowCPP in comparison to various competitors for different read percents: 20\%, 50\% and 80\%. Bank being distributed in nature allows HyflowCPP performance to linearly scale with increase in numbers of nodes. As we create 10000 accounts over the nodes, increase in number of nodes does not increase contention.

HyflowCPP performs 3x to 4x better in comparison to its nearest competitor HyflowScala. In sweet spot comparison by adding lots of threads per core HyflowScala is able to achieve almost equivalent performance to HyflowCPP as showed in figure~\ref{Fig:flatBankSS}. HyflowScala uses very efficient messaging technique based on the actor model, which allows it scale quickly with increase in number of threads.

Poor performance of HyflowJava and  DecentSTM is rooted in their bad implementation. The HyflowJava and HyflowCPP use the same TFA algorithm for concurrency control. But networking support in HyflowJava is very rudimentary and one of the major reason of bad performance. Similarily the DecentSTM and GenRSTM implementation is also not optimized for network messaging. From algorithm point of view DecentSTM and GenRSTM should be able to perform better in case of reads due to local reads and writes.

\begin{figure}
\centering
\subfigure[Bank 20\% reads]{
\includegraphics[width=0.85\textwidth]{\string"eps/flat/bank/r20".pdf}
\label{Fig:flatBankR20}
}
%\end{figure}
%\begin{figure}[H]
\subfigure[Bank 50\% reads]{
\includegraphics[width=0.85\textwidth]{\string"eps/flat/bank/r50".pdf}
\label{Fig:flatBankR50}
}
\end{figure}

\begin{figure}[H]
\subfigure[Bank 80\% reads]{
\includegraphics[width=0.85\textwidth]{\string"eps/flat/bank/r80".pdf}
\label{Fig:flatBankR80}
}
\subfigure[Bank Sweetspot Comparison]{
\includegraphics[width=0.85\textwidth]{\string"eps/flat/bank/sw".pdf}
\label{Fig:flatBankSS}
}
\caption{Flat Nesting: Transactional throughput for Bank}
\label{Fig:flatBank}
\end{figure}

\subsubsection{Linked List}

In this benchmark, we have designed an ordered, singly-linked linear list data structure. It support two write operations: add and remove, and one read operation: contains. While traversal all the read objects are added to transaction readSet, which makes list prone to high contention. Any write operation on traversed node will lead to transaction abort.  

\begin{figure}[H]
\centering
\subfigure[Linked list 20\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/list/r20".pdf}
\label{Fig:flatListR20}
}
\qquad
\subfigure[Linked list 50\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/list/r50".pdf}
\label{Fig:flatListR50}
}
\end{figure}

\begin{figure}[H]
\subfigure[Linked list 80\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/list/r80".pdf}
\label{Fig:flatListR80}
}
\caption{Flat Nesting: Transactional throughput for Linked list}
\label{Fig:flatList}
\end{figure}

\subsubsection{Skip List}

To Be Added 

\begin{figure}[H]
\centering
\subfigure[Skiplist 20\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/skipList/r20".pdf}
\label{Fig:flatSkipListR20}
}
\qquad
\subfigure[Skiplist 50\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/skipList/r50".pdf}
\label{Fig:flatSkipListR50}
}
\end{figure}

\begin{figure}[H]
\subfigure[Skiplist 80\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/skipList/r80".pdf}
\label{Fig:flatSkipListR80}
}
\caption{Flat Nesting: Transactional throughput for Binary Search Tree}
\label{Fig:flatBst}
\end{figure}

\subsubsection{Binary Search Tree}
To Be Added 

\begin{figure}[H]
\centering
\subfigure[BST 20\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/bst/r20".pdf}
\label{Fig:flatBstR20}
}
\qquad
\subfigure[BST 50\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/bst/r50".pdf}
\label{Fig:flatBstR50}
}
\end{figure}

\begin{figure}[H]
\subfigure[BST 80\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/bst/r80".pdf}
\label{Fig:flatBstR80}
}
\caption{Flat Nesting: Transactional throughput for Binary Search Tree}
\label{Fig:flatBst}
\end{figure}

\subsubsection{Hash Table}
To Be Added 

\begin{figure}[H]
\centering
\subfigure[Hash table 20\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/hashTable/r20".pdf}
\label{Fig:flatHashTableR20}
}
\qquad
\subfigure[Hash table 50\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/hashTable/r50".pdf}
\label{Fig:flatHashTableR50}
}
\end{figure}

\begin{figure}[H]
\subfigure[Hash table 80\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/hashTable/r80".pdf}
\label{Fig:flatHashTableR80}
}
\caption{Flat Nesting: Transactional throughput for Hash table}
\label{Fig:flatHashTable}
\end{figure}

\subsection{Macro Benchmarks}

Macro Benchmarks are useful to verify the framework capability in real life application. Macro benchmarks perform lot of operations leading to higher messaging and transaction execution time. In this section we evaluate the performance of Macro Benchmarks Vacation, Loan and TPCC.

\subsubsection{Vacation}

The Vacation benchmark emulates a itinerary planning reservation system. It allows user to make reservations for cars, rooms and flights. If also allows administrators to manipulate the users and update the currently available offers. Each reservation request or offer update request contain 10 queries writing on the 10 distributed objects. 

Vacation executes the reservation request, a low contention operation, as read operations and delete customer and update offers, high contention operations, as write operations. For experiment, in Vacation we create 1000 customers and 3000 cars, 3000 flights and 3000 rooms. In Figure~\ref{Fig:flatVacation} we can see  that higher numbers of resources allow the throughput to scale linearly with number of nodes. Due to higher numbers of objects the read operations prove more costly as they access more objects. We compare the HyflowCpp performance with HyflowJava for different reads. Hyflow perform also 4-5 times better than HyflowJava. 

\begin{figure}[H]
\centering
\subfigure[Vacation 20\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/vacation/r20".pdf}
\label{Fig:flatVacationR20}
}
\qquad
\subfigure[Vacation 50\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/vacation/r50".pdf}
\label{Fig:flatVacationR50}
}
\end{figure}

\begin{figure}[H]
\subfigure[Vacation 80\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/vacation/r80".pdf}
\label{Fig:flatVacationR80}
}
\caption{Flat Nesting: Transactional throughput for Vacation}
\label{Fig:flatVacation}
\end{figure}

\subsubsection{Loan}

Loan benchmark simulates the banking situation where loans are provided to user based on the different set of bank accounts. Each account is access in nested fashion and a certain amount of money is borrowed based on the current amount. It also allows user to get total balance available in the all accounts.

In our experiments, we run the total balance operation as reads and loan operation as write operation. We create total 10000 account over network and access 6 accounts to provide loan or calculate the total balance.
Loan operation calls itself in nested fashion either until all the account are used to borrow a random part of total loan money.

We compare HyflowCPP performance with two other frameworks HyflowJava and DecentSTM. Its performance in 5 to 10 times better than other frameworks. Write dominated experiments shows higher throughput as they suffer from higher contention. Throughput for 80\% read is higher than 20\% reads. At very low contention level, around 2 to 4 nodes, loan performance is very similar for different read ratios as read operation and write operation access same number of objects. 

\begin{figure}[H]
\centering
\subfigure[Loan 20\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/loan/r20".pdf}
\label{Fig:flatLoanR20}
}
\qquad
\subfigure[Loan 50\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/loan/r50".pdf}
\label{Fig:flatLoanR50}
}
\end{figure}

\begin{figure}[H]
\subfigure[Loan 80\% reads]{
\includegraphics[width=0.7\textwidth]{\string"eps/flat/loan/r80".pdf}
\label{Fig:flatLoanR80}
}
\caption{Flat Nesting: Transactional throughput for Loan}
\label{Fig:flatLoan}
\end{figure}

\subsubsection{TPCC}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{\string"eps/flat/tpcc/tpcc".pdf}
\caption{Flat Nesting: Transactional throughput for TPCC with different Read Ratios}
\label{Fig:flatTPCC}
\end{figure}

\section{Checkpointing and Close Nesting}

We perform 3 types experiments to evaluate.

\subsection{Micro Benchmarks}

\subsubsection{Bank}
To Be Added

\subsubsection{Linked List}
To Be Added 

\subsubsection{Skip List}
To Be Added  

\subsubsection{BST}
To Be Added

\subsubsection{Hash Table}
To Be Added 

\subsection{Macro Benchmarks}

\subsubsection{Loan}

To Be Added

\subsubsection{Tpcc}

To Be Added

\section{Open Nesting}

To be added

\subsection{Linked List}

To Be Added 

\subsection{Skip List}

To Be Added 

\subsection{Hash Table}

To Be Added 

\subsection{BST}

To Be Added

\section{Summary}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%																									%
%							CHAPTER 7	:	Conclusion						%
%																									%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion and Future Work}\label{chap:conclusion}
\markright{Chapter~\ref{chap:conclusion}.
Conclusion and Future Work
\hfill}

To be Added

\section{Future Work}

To be added

\newpage
\markright{Bibliography \hfill}

\bibliographystyle{abbrv}
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{BibTex/all}

\end{document}
